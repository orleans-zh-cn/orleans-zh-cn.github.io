{
  "blog/announcing-orleans-2.0-tech-preview-3.html": {
    "href": "blog/announcing-orleans-2.0-tech-preview-3.html",
    "title": "Announcing Orleans 2.0 Tech Preview 3 | Microsoft Orleans Documentation",
    "keywords": "Announcing Orleans 2.0 Tech Preview 3 Julian Dominguez 9/13/2017 1:17:21 PM We just released a big update on the Orleans 2.0 tech preview train. The new binaries now target .NET Standard 2.0, so they have almost full parity with the .NET version of Orleans. This means that the current state is not only functional for people writing new applications in .NET Core, but also as an upgrade path for people with applications already running in .NET Framework. Are we done yet? This is an exciting milestone for our team, as it brings the 2.0 release a lot closer. There are a few remaining things we would like to do for this version before we release, such as: Enable build-time codegen for .NET Core apps (only runtime codegen is supported for .NET Core still) Migrate to Microsoft.Extensions.Logging for all of our logging Flesh out the silo builder APIs more Improve startup by scanning only the assemblies defined by the end user Restructure some of our types to have an Abstractions project that we don't version often Have an initial version of the Transactions feature working Provide a level of backwards compatibility for types commonly serialized and persisted to storage and some other minor things How can I try this? We just published the packages to MyGet: https://dotnet.myget.org/gallery/orleans-ci Please follow the link for instructions on how to configure NuGet to download packages from that feed. Please help us We plan to start releasing updated packages to the MyGet feed a lot more often, so please try the preview, and if there's issues, let us know, so that we can fix it and send an update your way shortly after. Is Orleans 2.0 TP3 production ready? Not yet. Big disclaimer: We do our CI testing in .NET (because our tests heavily rely on AppDomains to create an in-memory cluster of silos, and those are not supported in .NET Core, but we plan to tackle that soon). We have done some basic manual testing in .NET Core (both Windows and Linux), and we have some of our contributors using it to develop new services. Getting feedback (and PRs!) is one of the main goals of this release, and not to be used in production yet. Also, there is no guarantee that this technical preview is entirely backwards compatible with Orleans 1.5, even for the features that were fully ported. Once we are closer to a stable release, we’ll list all the breaking changes that we know of in case you are interested in upgrading your application from 1.X to 2.0. Notes If you were using an older tech preview, notice that assembly loading changed a little, and we expect to continue to change it. In the meantime, please note that in .NET Core you might be required to publish your app so that all the assemblies to scan are in the same folder (you can achieve this by calling ` dotnet publish ` on your silo host)."
  },
  "blog/announcing-orleans-2.1.html": {
    "href": "blog/announcing-orleans-2.1.html",
    "title": "Announcing Orleans 2.1 | Microsoft Orleans Documentation",
    "keywords": "Announcing Orleans 2.1 Reuben Bond 10/1/2018 7:17:59 PM Today, we announced Orleans 2.1. This release includes significant performance improvements over 2.0, a major refresh of distributed transaction support, a new code generator, and new functionality for co-hosting scenarios as well as smaller fixes & improvements. Read the release notes here . New Scheduler Starting with Orleans 2.1, we have a rewritten core scheduler which takes advantage of performance improvements to .NET Core's ThreadPool . The new scheduler uses work stealing queues with local queue affinity to reduce contention and improve throughput and latency. These improvements are available on all platforms/frameworks. Community members have reported significant responsiveness and throughput improvements in their services and our testing indicates up to 30% higher throughput. This new scheduler also exhibits much lower CPU usage during low-load periods, benefiting co-hosting scenarios and improving the CPU profiling experience. Special thanks to Dmytro Vakulenko from the community for driving this work from theory through to experimentation & completion. Distributed Transactions Orleans originated from Microsoft Research and we continue to partner with MSR and product teams to bring features such as scalable distributed transactions into production. Distributed transactions support was first introduced as an experimental feature in Orleans 2.0, and in 2.1 we are refreshing the release with a new, fully decentralized, transaction manager. Aside from the improvements to the transaction manager, the entire transactions system has continued to receive heavy investment in order to ready the code for production and a stable release in a future version of Orleans. We consider distributed transactions to be in \"release candidate\" quality in 2.1. Learn about distributed transactions in Orleans from Sergey's talk, Distributed Transactions are dead, long live distributed transactions! from J On the Beach 2018 . Read the research papers on transactions, actor-oriented database systems, and other topics from the Orleans Microsoft Research site . Direct Client Orleans 2.1 introduces a new way to interact with grains and interoperate with frameworks like ASP.NET or gRPC. The feature is called direct client and it allows co-hosting a client and silo in a way that let the client communicate more efficiently with not just the silo it's attached to, but the entire cluster. Once direct client is enabled, IClusterClient and IGrainFactory can be resolved from the silo container and used to create grain references which can be called. These calls use the local silo's knowledge of the cluster and grain placement to avoid unnecessary copying, serialization, and networking hops. In addition, because this feature shares the same internals as the silo itself, it provides a seamless experience when it comes to passing grain references between threads. In Orleans 2.1 we have made direct client an opt-in feature. Enable it by calling ISiloHostBuilder.EnableDirectClient() during silo configuration. New Code Generator This release includes a new code generation package, Microsoft.Orleans.CodeGenerator.MSBuild , an alternative to the existing package, Microsoft.Orleans.OrleansCodeGenerator.Build . The new code generator leverages Roslyn for code analysis to avoid loading application binaries. As a result, it avoids issues caused by clashing dependency versions and differing target frameworks. If you experience issues, please let us know by opening an issue on GitHub . The new code generator also improves support for incremental builds, which should result in shorter build times. Other Improvements Grain methods can return ValueTask<T> - thanks to @kutensky Removed per-call Timer allocation , reducing .NET Timer queue contention Fixes for silo shutdown behavior - thank you to @yevhen for reporting and investigating Configure grain collection idle time using [CollectionAgeLimit(Minutes = x)] - thanks to @aRajeshKumar Known Issues with .NET Core 2.1 User Sun Zhongfeng reported an issue running Orleans on .NET Core 2.1 with TieredCompilation enabled. We tracked this down to a JIT issue in CoreCLR , which the CoreCLR team quickly diagnosed and fixed. TieredCompilation is not enabled by default in .NET Core 2.1 and this fix is not expected to land in .NET Core 2.1, but will be included in .NET Core 2.2 . Do not enable TieredCompilation if you are running Orleans on .NET Core 2.1. We would like to thank everyone in the community who contributed to this release and helped testing the pre-release builds."
  },
  "blog/de-inventing-the-wheel.html": {
    "href": "blog/de-inventing-the-wheel.html",
    "title": "De-inventing the wheel | Microsoft Orleans Documentation",
    "keywords": "De-inventing the wheel Julian Dominguez 4/12/2017 2:49:11 PM The Microsoft Orleans project started many years ago in Microsoft Research, when not even the Task class existed. As the project matured, many non-core abstractions & functionality was needed to support its growth. These abstractions didn't exist as standards in .NET and .NET OSS was in its infancy. Examples of these pieces are cross-cutting concerns such as Logging, Configuration, and Dependency Injection. As time passed, some common abstractions and patterns emerged, and it reached a point where it makes sense to just adopt them. There are many reasons as to why: Developers are used to the standard patterns and abstractions, so newcomers do not need to learn these non-core abstractions just to use Orleans. Standard abstractions have an enormous level of adoption with almost every 3rd party component related to that abstraction. On the other hand, today it requires that the Orleans community builds integration packages to many 3rd party components (ie: to use Serilog, log4net, or push events to ETW), as the owners of these will just create integration packages for the common abstractions, but not for Orleans or any other non-standard abstraction. We created custom abstractions to be good enough to do the job, but we don't focus too much after that on usability, as it just goes into maintenance mode. Sometimes we find out that these abstractions were not good enough, so we must make breaking changes (for example our move to non-static clients and silos requires a non-static logging abstraction). These standard abstractions are very well thought out to do that specific job, and are generally very flexible, simple to use, and have a lot of documentation. We just stand on their shoulders. Deleting code that is not important to Orleans core functionality is always good. We already started using the Microsoft.Extensions.DependencyInjection abstractions for enabling DI, moving away for our poor man's object activation (and 2-step initialization) approach in many places. As we move forward, we plan to deprecate some of our custom abstractions in favor of standard ones. In particular we are already thinking of 2 upcoming changes: Migrate our logging abstractions to Microsoft.Extensions.Logging . Revamp our configuration and startup pattern to align with ASP.NET Core's. See dotnet/orleans#2936 for an initial design of this move. As always, we'll try to keep breaking changes to a minimum, but we don't strictly prevent breaking changes. Sometimes we make our new versions be source code compatible (meaning that developers can't simply use binding redirects on Orleans assemblies, but re-building their code might still compile) or require a few minimal fixes. Sometimes breaking changes are *bigger* if they would just affect a small feature or something that is typically not spread-out through the entire codebase of our users (such as extensibility points that do not affect grain code). Also, it seems like an appropriate time to look at these abstractions with a fresh mind, since that's what the .NET community seems to be doing when looking forward at things like ASP.NET and .NET Core."
  },
  "blog/dmitry-vakulenko.html": {
    "href": "blog/dmitry-vakulenko.html",
    "title": "Dmitry Vakulenko | Microsoft Orleans Documentation",
    "keywords": "Dmitry Vakulenko Sergey Bykov 11/19/2018 1:57:59 PM Dmitry Vakulenko joined the Orleans open source community three years ago, and started submitting pull requests that focused on improving performance of the Orleans codebase. He became the most prolific contributor outside of the current and former members of the core team. Dmitry also contributed other improvements, but his passion continued to be performance. Because of the compound nature of incremental optimizations, over time these improvements added up to a staggering aggregate factor. Our conservative estimate is that Dmitry's contributions combined increased performance of Orleans by about 2.6 times. Dmitry's latest contribution was the reimplemented Scheduler. Scheduler is the \"heart\" of the Orleans runtime that is responsible for efficient processing of incoming requests while ensuring the single-threaded execution of each of the many thousands of grain activations. The new version of the Scheduler contributed by Dmitry was 30% faster than the original one, yet simpler and much more debugging friendly. It became the key feature of the 2.1.0 release. After many months of waiting for his visa, Dmitry was finally scheduled to join the core team as a full-time Microsoft employee on October 15th. We later learned that he had passed away three days before that date. This is a big tragedy and an immense loss for us and the whole open source community around Orleans. We lost a very talented engineer who was so early in his career and had all roads open to him. We lost a colleague and a friend with whom we collaborated for years and were looking forward to work even closer. We are incredibly grateful to Dmitry for all he has done. It is still hard to believe that he is not with us anymore. He will be remember as a brilliant mind and an even-tempered human being always open to new ideas and ready to help. Thank you for everything, Dmitry!"
  },
  "blog/fix-visual-studio-2015-with-orleans-tools-for-visual-studio-1.4.0 installed.html": {
    "href": "blog/fix-visual-studio-2015-with-orleans-tools-for-visual-studio-1.4.0 installed.html",
    "title": "Fix Visual Studio 2015 with Orleans Tools for Visual Studio 1.4.0 installed | Microsoft Orleans Documentation",
    "keywords": "Fix Visual Studio 2015 with Orleans Tools for Visual Studio 1.4.0 installed Attila Hajdrik 3/10/2017 10:06:17 AM Today two community members was hit by an issue with Visual Studio 2015 if they've installed the 1.4.0 version of the Orleans VSIX package. We have an open issue to track this on GitHub . If you installed the extension on Visual Studio 2017, it will work, only 2015 has this problem. The issue we're seeing is that you cannot open the Tools & Extensions window, VS will show this error dialog: While we working on the solution we unpublished the problematic version and published an older version of the extension which does not work with Visual Studio 2017, but neither it renders Visual Studio 2015 unusable. If you were hit by this isse, here are the steps to fix it: 1) Exit all Visual Studio instances. 2) Open an Administrator Visual Studio developer command prompt. 3) cd /D \"%USERPROFILE%\\Local Settings\\Microsoft\\VisualStudio\\14.0\\Extensions\" 4) dir OrleansVSTools.dll /s You'll get a result like this: Directory of C:\\Users\\\\Local Settings\\Microsoft\\VisualStudio\\14.0\\Extensions\\pxzkggpq.50t 03/10/2017 02:36 PM 18,608 OrleansVSTools.dll 1 File(s) 18,608 bytes 5) Copy the full directory path to clipboard. 6) rmdir \"\" /q /s Make sure you're still in the Extensions directory. 7) del *.cache 8) devenv /setup This can run for a few minutes...be patient. Now you can start Visual Studio 2015 and verify that the Extensions dialog opens and everything works fine. If you've special root suffixes configured for Visual Studio 2015 then you've to execute these commands for that specific instance, so not in the 14.0, but maybe in the 14.0Exp directory. UPDATE 3/17/2017 We published an updated VSIX which works correctly with VS2013, VS2015, VS2017: Microsoft Orleans Tools for Visual Studio"
  },
  "blog/index.html": {
    "href": "blog/index.html",
    "title": "Developing a Grain | Microsoft Orleans Documentation",
    "keywords": "Solving a Transactions Performance Mystery Reuben Bond 12/7/2018 10:08:58 AM 有关更详尽的说明，请参见 项目设置 的部分 教程一–Orleans基础 。 We were seeing significant performance issues and a large number of transaction failures in the stress/load tests against our test cluster. A large fraction of transactions were stalling until timeout. Dmitry Vakulenko 以下是Orleans 1.5 Presence Service示例的摘录： Dmitry Vakulenko joined the Orleans open source community three years ago, and started submitting pull requests that focused on improving performance of the Orleans codebase. He became the most prolific contributor outside of the current and former members of the core team. Dmitry also contributed other improvements, but his passion continued to be performance. Because of the compound nature of incremental optimizations, over time these improvements added up to a staggering aggregate factor. Our conservative estimate is that Dmitry's contributions combined increased performance of Orleans by about 2.6 times. Announcing Orleans 2.1 标记为async直接返回值： Today, we announced Orleans 2.1. This release includes significant performance improvements over 2.0, a major refresh of distributed transaction support, a new code generator, and new functionality for co-hosting scenarios as well as smaller fixes & improvements. Read the release notes here ."
  },
  "blog/latest-release-1.3.1.html": {
    "href": "blog/latest-release-1.3.1.html",
    "title": "Latest release - 1.3.1 | Microsoft Orleans Documentation",
    "keywords": "Latest release - 1.3.1 Sergey Bykov 12/1/2016 5:48:39 PM On November 15th we published our latest release - 1.3.1 . It is a patch release with a number of bug fixes and improvements that have been merged into master since 1.3.0. There were two main reasons for 1.3.1. 343 Industries needed a release with a couple of improvements to streaming and the EventHub stream provider to simplify their migration from the pre-released version of the streaming stack they've been running since before Halo 5 launch. Orleankka needed a rather advanced feature that would allow them to control interleaving of requests on a per-message basis. @yevhen submitted a PR for that after a few design and implementation iterations. So, 1.3.1 isn't a pure patch release because it includes a new feature. We thought it was okay here because of how non-impactful to others the feature really is. If you are upgrading to 1.3.1 from a 1.2.x or earlier release, beware of the subtle breaking change that was made in 1.3.0. The 1.3.0 release notes called it out: NB: There is a subtle breaking change in this release, which is unfortunately easy to miss. If you are using AzureSilo.Start(ClusterConfiguration config, string deploymentId) in your code, that overload has been removed, but the new one that replaced it has the same argument signature with a different second argument: (ClusterConfiguration config, string connectionString) . Deployment ID now has to be passed as part of the config argument:config.Globals.DeploymentId. This removed the ambiguous possibility of passing two different Deployment IDs, but unfortunately at the cost of the breaking API change. 1.3.0 was a pretty big release with numerous improvements, bug fixes, and the major new feature of geo-distributed multi-clusters. Most of its content is listed in the 1.3.0-beta2 release notes . The geo-distribution functionality is described in the Multi-Cluster Support section of the docs."
  },
  "blog/orleans-1.4-and-2.0-tech-preview-2-for-.net-core-released.html": {
    "href": "blog/orleans-1.4-and-2.0-tech-preview-2-for-.net-core-released.html",
    "title": "Orleans 1.4 and 2.0 Tech Preview 2 for .NET Core released | Microsoft Orleans Documentation",
    "keywords": "Orleans 1.4 and 2.0 Tech Preview 2 for .NET Core released Julian Dominguez 3/2/2017 5:54:19 PM Orleans 1.4.0 A few weeks ago we release Orleans 1.4.0 to NuGet.org, where the main new themes were: Revamped JournaledGrain for event sourcing with support for geo-distributed log-based consistency providers. Abstraction of Grain Services with fixed-placed per-silo application components with their workload partitioned via cluster consistency ring. Support for heterogeneous silos with non-uniform distribution of available grain classes. Cluster membership provider for Service Fabric. Of course, there's a lot of other improvement and bug fixes, that you can read about here: Orleans v1.4.0 release notes Orleans 2.0 Tech Preview 2 for .NET Core In addition to our standard releases, we have been working in a vNext feature that supports .NET Standard (and .NET Core hosts). Similar to TP1, this new preview is not at complete full parity with the Orleans 1.X releases, but it's getting pretty close. We have done a lot of bug fixes since the last preview, and also this one is up to date with the latest version in our master branch (a little bit ahead of 1.4.0). Differences with Orleans 1.X Some notable differences or pending things in this pre-release: Orleans code generation Build time codegen (Microsoft.Orleans.OrleansCodeGenerator.Build nuget package) only works if building on Windows with either Visual Studio 2017 or the latest dotnet CLI. Nevertheless, runtime codegen is a viable alternative that works cross-platform (by referencing Microsoft.Orleans.OrleansCodeGenerator package in the Silo host and client projects). BinaryFormatter (built-in .NET Serialization) is not yet available in .NET Standard, and it was being used as the default fallback serializer in Orleans (and typically used mostly when serializing exceptions). Now we have a custom IL based fallback serializer that should be fast and powerful, but might behave somewhat differently if you have existing code relying on [Serializable] . System.Diagnostic.Trace.CorrelationManager.ActivityId is not supported in .NET Standard. If you were relying on this to correlate grain calls, consider using Orleans.Runtime.RequestContext.ActivityId instead. Is Orleans 2.0 TP2 production ready? Not yet. Big disclaimer: We do our CI testing in .NET (because our tests heavily rely on AppDomains to create an in-memory cluster of silos, and those are not supported in .NET Core, but we plan to tackle that soon). We have done some basic manual testing in .NET Core (both Windows and Linux), and we have some of our contributors using it to develop new services. Getting feedback (and PRs!) is one of the main goals of this release, and not to be used in production yet. Also, there is no guarantee that this technical preview is entirely backwards compatible with Orleans 1.4, even for the features that were fully ported. Once we are closer to a stable release, we’ll list all the breaking changes that we know of in case you are interested in upgrading your application from 1.X to 2.0. Where to get it Because this tech preview is not as full featured or stable as the 1.X releases is that we are only releasing in MyGet for now. You can get the NuGet packages by following the steps to configure the feed here: https://dotnet.myget.org/gallery/orleans-ci HelloWorld Sample We now have a very simple sample in our repo that you can use to try Orleans in .NET Core (whether that's in Windows, Linux or MacOS). The sample is located at https://github.com/dotnet/orleans/tree/master/Samples/HelloWorld.NetCore . Enjoy it, play with it, and lets us know what you think, either as GitHub issues, PRs or just come hang out in our Gitter channel."
  },
  "blog/orleans-2.0-tech-preview-supporting-.net-core.html": {
    "href": "blog/orleans-2.0-tech-preview-supporting-.net-core.html",
    "title": "Orleans 2.0 Tech Preview supporting .NET Core | Microsoft Orleans Documentation",
    "keywords": "Orleans 2.0 Tech Preview supporting .NET Core Julian Dominguez 12/5/2016 11:52:59 AM It's been a long migration to have Orleans be .NET Standard compatible, but we finally have a minimum viable release ready to start playing with in .NET Core! :) Orleans 2.0 Tech Preview 1 was just released to MyGet: https://dotnet.myget.org/gallery/orleans-ci (or https://dotnet.myget.org/F/orleans-ci/api/v3/index.json to configure the feed in NuGet) Differences with Orleans 1.X Orleans 2.0 Tech Preview is not as full featured as Orleans 1.X, as we ported the minimum needed to have a decent experience, and arguably the hardest/riskiest portion to port. We expect the rest of the extensions to be migrated much faster from now on. Some notable differences or pending things in this pre-release: Orleans code generation Build time codegen (Microsoft.Orleans.OrleansCodeGenerator.Build nuget package) only works if building on Windows with .NET 4.6.2 installed. It also requires .NET Core preview3 tooling or greater (VS2017 RC if building in VS). Nevertheless, runtime codegen is a viable alternative that works cross-platform (by referencing Microsoft.Orleans.OrleansCodeGenerator package in the Silo host and client projects). For reliable cluster membership, storage, and stream, only Azure Storage providers were migrated for now. The rest are coming soon (or feel free to contribute a port for them). BinaryFormatter (built-in .NET Serialization) is not yet available in .NET Standard, and it was being used as the default fallback serializer in Orleans (and typically used mostly when serializing exceptions). Now we have a custom IL based fallback serializer that should be fast and powerful, but might behave somewhat differently if you have existing code relying on [Serializable]. System.Diagnostic.Trace.CorrelationManager.ActivityId is not supported in .NET Standard. If you were relying on this to correlate grain calls, consider using Orleans.Runtime.RequestContext.ActivityId instead. Is it production ready? No. Big disclaimer: We do our CI testing in .NET (because our tests heavily rely on AppDomains to create an in-memory cluster of silos, and those are not supported in .NET Core, but we plan to tackle that soon). We have done some basic manual testing in .NET Core (both Windows and Linux), but expect some issues. Getting feedback (and PRs!) is one of the main goals of this release, and not to be used in production yet. Also, there is no guarantee that this technical preview is entirely backwards compatible with Orleans 1.3, even for the features that were fully ported. Once we are closer to a stable release, we'll list all the breaking changes that we know of in case you are interested in upgrading your application from 1.3 to 2.0. Because this tech preview is not as full featured as the 1.X releases is that we are only release in MyGet for now. Running sample I created a small Hello World sample app that runs in .NET Core, and you are welcome to use it as a starting point. The sample is located here: https://github.com/jdom/OrleansHelloWorldSample.Core Sample application running Orleans in Linux Enjoy it, play with it, and lets us know what you think, either as GitHub issues, PRs or just come hang out in our Gitter channel."
  },
  "blog/orleans-and-midori.html": {
    "href": "blog/orleans-and-midori.html",
    "title": "Orleans and Midori | Microsoft Orleans Documentation",
    "keywords": "Orleans and Midori Sergey Bykov 12/11/2016 10:56:13 PM Reading the epic Joe Duffy’s 15 Years of Concurrency post brought some old memories from the early days of Orleans. It even compelled me to dig up and try to compile the code from 2009. It was an entertaining exercise. When we were just starting the Orleans project, we would meet and talk with Midori people on a regular basis. That was natural not only because of some obvious overlap of the problem spaces, but also because Jim Larus who conceived Orleans was one of the creators of Singularity , the base from which Midori started. We immediately borrowed the promises library of Midori because we wanted to use the promise-based concurrency for safe execution and efficient RPC. We didn’t bother to try to integrate the code, and simply grabbed the binaries and checked them in into our source tree. We were at an early prototyping stage, and didn’t have to worry about the long term yet. At the time, grain interfaces looked like this: [Eventual] public interface ISimpleGrain : IEventual { [Eventual] PVoid SetA(int a); [Eventual] PVoid SetB(int b); [Eventual] PInt32 GetAxB(); } PVoid and Pint32 were moral equivalents of Task and Task<int> in TPL . Unlike Tasks, they had a bunch of static methods, with one of the simpler overloads taking two lambdas: one for success case and one to handle a thrown exception: public static PVoid When(PVoid target, Action fn, Action<Exception> catchFn); A trivial grain method looked like: public PVoid SetA(int a) { this.a = a; return PVoid.DONE; } You can see here where TaskDone.Done came from. A simple unit test method looked rather convoluted: [TestMethod] public void SimpleGrainDataFlow() { result = new ResultHandle(); Runner.Enqueue(new SimpleTodo(() => { Promise<SimpleGrainReference> clientPromise = SimpleGrainReference.GetReference(\"foo\"); PVoid.When(clientPromise, reference => { grain = reference; Assert.IsNotNull(grain); PVoid setPromise = grain.SetA(3); PVoid.When(setPromise, () => { setPromise = grain.SetB(4); PVoid.When(setPromise, () => { PInt32 intPromise = grain.GetAxB(); PVoid.When<Int32>(intPromise, x => { result.Result = x; result.Done = true; }, exc => { Assert.Fail(\"Exception thrown by GetAxB: \" + exc.Message); return PVoid.DONE; }); }, exc => { Assert.Fail(\"Exception thrown by SetB: \" + exc.Message); return PVoid.DONE; }); }, exc => { Assert.Fail(\"Exception thrown by SetA: \" + exc.Message); return PVoid.DONE; }); }, exc => { result.Exception = exc; result.Done = true; return PVoid.DONE; }); })); Assert.IsTrue(result.WaitForFinished(timeout)); Assert.IsNotNull(result.Result); Assert.AreEqual(12, result.Result); } The nested Whens were necessary to organize a data flow execution pipeline. Runner was an instance of ForeignTodoRunner , which was one of the ways of injecting asynchronous tasks ( ToDo s) into a TodoManager . TodoManager was a single-threaded execution manager a.k.a. a vat, the notion that came from E language . Initialization of the vat-based execution system was a few lines of code: todoManager = new TodoManager(); Thread t = new Thread(todoManager.Run); t.Name = \"Unit test TodoManager\"; t.Start(); runner = new ForeignTodoRunner(todoManager); Within a silo, we also used vats for managing single-threaded execution of grain turns. As part of silo startup we set up N of them to match the number of available CPU cores: for (int i = 0; i < nTodoManagers; i++) { todoManagers[i] = new TodoManager(); for (int j = 0; j < runnerFactor; j++) todoRunners[i \\* runnerFactor + j] = new ForeignTodoRunner(todoManagers[i]); Thread t = new Thread(todoManagers[i].Run); t.Name = String.Format(\"TodoManager: {0}\", i); t.Start(); } We argued with Dean Tribble at the time that using static methods on promises in our view was too inconvenient for most developers. We wanted them to be instance methods instead. A few months later we introduced our own promises, AsyncCompletion and AsyncValue . They were wrappers around Task and Task of TPL and had instance methods. This compressed the code by quite a bit: [TestMethod] public void SimpleGrainDataFlow() { ResultHandle result = new ResultHandle(); SimpleGrainReference grain = SimpleGrainReference.GetReference(\"foo\"); AsyncCompletion setPromise = grain.SetA(3); setPromise.ContinueWith(() => { setPromise = grain.SetB(4); setPromise.ContinueWith( () => { AsyncValue<int> intPromise = grain.GetAxB(); intPromise.ContinueWith( x => { result.Result = x; result.Done = true; }); }); }); Assert.IsTrue(result.WaitForFinished(timeout)); Assert.IsNotNull(result.Result); Assert.AreEqual(12, result.Result); } Initially, we allowed grain methods to be synchronous, and had grain references be their asynchronous proxies. public class SimpleGrain : GrainBase { public void SetA(int a) public void SetB(int b) public int GetAxB() } public class SimpleGrainReference : GrainReference { public AsyncCompletion SetA(int a) public AsyncCompletion SetB(int b) public AsyncValue<int> GetAxB() } We quickly realized that was a bad idea, and switched to grain methods returning AsyncCompletion / AsyncValue<T> . We went through and eventually discarded a number of other bad ideas. We supported properties on grain classes. Async setters were a problem, and in general, async properties were rather misleading and provided no benefit over explicit getter methods. We initially supported .NET events on grains. Had to scrap them because of the fundamentally synchronous nature of += and -= operations in .NET. Why didn’t we simply use Task / Task<T> instead of AsyncCompletion / AsyncValue<T> ? We needed to intercept every scheduling and continuation call in order to guarantee single-threaded execution. Task was a sealed class, and hence we couldn’t subclass it to override the key methods we needed. We didn’t have a custom TPL scheduler yet either. After we switched to using our own promises, we lost the opportunity to use some of the advanced features that Midori had for theirs. For example, they supported a three-party promise handoff protocol. If node A called node B and held a promise for that call, but B as part of processing the request made a call to C for the final value, B could hand off a reference to the promise held by A, so that C could reply directly to A instead of making an extra hop back to B. In this tradeoff between performance and complexity we chose to prioritize for simplicity. Another lesson we learned from talking to Midori people was that the source of some of the hardest to track down bugs in their codebase was interleaving of execution turns. Even though a vat had a single thread to execute all turns (synchronous pieces of code between yield points), it was totally legal for it to execute turns belonging to different requests in an arbitrary order. Imagine your component is processing a request and needs to call another component, for example, make an IO call in the middle of it. You make that IO call, receive a promise for its completion or its return value, and schedule a continuation with a When or ContinueWith call. The trap here is that when the IO call completes and the scheduled continuation starts executing, it is too easy to assume that the state of the component hasn’t changed since the IO call was issued. In fact, the component might have received and processed a number of other requests while asynchronously waiting for that IO call, and processing of those requests could have mutated the state of the component in a non-obvious way. The Midori team was very senior. At the time, the majority of them were principal and partner level engineers and architects. We wondered if interleaving was so perilous to people of that caliber and experience, it must be even worse for mere mortals like us. That lead to the later decision to make grains in Orleans non-reentrant by default. At around the same time, Niklas Gustafsson worked on project Maestro that was later renamed and released as Axum . We had an intern prototype one of the early Orleans applications on Axum to compare the programming experience with the promise-based one in spring of 2009. We concluded that the promises model was more attainable for developers. In parallel Niklas created a proposal and a prototype of what eventually, after he convinced Anders Hejlsberg and others, became the async / await keywords in C#. By now it propagated to even more languages. After .NET 4.5 with async and await was released, we finally abandoned AsyncCompletion / AsyncValue<T> in favor of Task / Task<T> to leverage the power of await. It was another tradeoff that made us rewrite our scheduler a couple of times (not a trivial task) and give up some of the nice features we had in our promises. For example, before we could easily detect if grain code tried to block the thread by calling Result or Wait() on an unresolved promise, and throw an InvalidOperationException to indicate that this was not allowed in the cooperative multi-tasking environment of a silo. We couldn’t do that anymore. But we gained the cleaner programming model that we have today: public interface ISimpleGrain : IGrainWithIntegerKey { Task SetA(int a); Task SetB(int b); Task<int> GetAxB(); } [Fact, TestCategory(\"BVT\"), TestCategory(\"Functional\")] public async Task SimpleGrainDataFlow() { var grain = GrainFactory.GetGrain<ISimpleGrain>(GetRandomGrainId()); Task setAPromise = grain.SetA(3); Task setBPromise = grain.SetB(4); await Task.WhenAll(setAPromise, setBPromise); var x = await grain.GetAxB(); Assert.Equal(12, x); } Midori was an interesting experiment of a significant scale, to try to build a ‘safe by construction’ OS with asynchrony and isolation top to bottom. It is always difficult to judge such efforts in terms of successes, failures, and missed opportunities. One thing is clear – Midori did influence early thinking and design about asynchrony and concurrency in Orleans, and helped bootstrap its initial prototypes."
  },
  "blog/refresh-of-orleans-2.0-tech-preview-with-orleanssqlutils-added.html": {
    "href": "blog/refresh-of-orleans-2.0-tech-preview-with-orleanssqlutils-added.html",
    "title": "Refresh of Orleans 2.0 Tech Preview with OrleansSQLUtils added | Microsoft Orleans Documentation",
    "keywords": "Refresh of Orleans 2.0 Tech Preview with OrleansSQLUtils added Sergey Bykov 12/15/2016 2:45:47 PM We published a refresh of the 2.0 Tech Preview, in which we added the Microsoft.Orleans.OrleansSqlUtils package. This enables using Microsoft SQL Server, MySQL, PosgreSQL, and other compatible SQL servers for cluster membership storage and grain state persistence. Big thanks to Gutemberg Ribeiro for helping with that! You can get packages from MyGet: https://dotnet.myget.org/gallery/orleans-ci (or https://dotnet.myget.org/F/orleans-ci/api/v3/index.json to configure the feed in NuGet)."
  },
  "blog/solving-a-transactions-performance-mystery.html": {
    "href": "blog/solving-a-transactions-performance-mystery.html",
    "title": "Solving a Transactions Performance Mystery | Microsoft Orleans Documentation",
    "keywords": "Solving a Transactions Performance Mystery Reuben Bond 12/7/2018 10:08:58 AM After arriving in Redmond and completing the mandatory New Employee Orientation, my first task on the Orleans team has been to assist with some ongoing performance investigations in order to ensure that Orleans' Transactions support is ready for internal users and hence release. We were seeing significant performance issues and a large number of transaction failures in the stress/load tests against our test cluster. A large fraction of transactions were stalling until timeout. Our initial investigations focused on the transaction management code. Maybe there was a deadlock somewhere. We took a divide-and-conquer approach, replacing internal transaction components with stubbed-out variants. The problem was more-or-less isolated to the ITransactionalState<T> implementation which sits on every grain. The transactional state is responsible for loading and modifying grain state and handling the various transaction phases (Start, Prepare, Abort, Commit, Confirm) as well as optimizing multiple overlapping transactions within the isolation guarantees using a reader-writer lock. You can see that it's not a small amount of code, but isolating the issue further was proving difficult for reasons not limited to the fact that taking out any one piece was not showing a dramatic improvement. Profiling data is critical for performance investigations, so after requesting obtaining permissions to directly access the machines in our test cluster, we collected ETW logs using PerfView using a command similar to this: PerfView.exe /acceptEULA /noGui /threadTime /zip /maxCollectSec:30 /dataFile:1.etl collect Analyzing the resulting .etl file locally, looking at a flame graph for the stack trace samples, the problem is immediately apparent. PerfView makes the cause of the issue apparent. The details are too small to read on that view, but by hovering the mouse over each of the bars we can see which method that stack frame represents. The arrows point to the stack frames where the CPU is waiting on a lock and in this case, that lock is on the global .NET Timer queue. The plateau towards the right is from the thread servicing the timer queue and firing the expired timers, which also needs to acquire the lock. Our load tests are running on .NET Framework 4.6.2 and therefore System.Threading.Timer is implemented using a global queue (linked list) of timers which is protected by a single lock object. Any operations on this queue must acquire that lock. This is something we were already aware of and Orleans 2.1.0 includes a PR which alleviates potential lock contention on this queue for our main source of timers (response timeout timers). The transactions code never uses Timer , so why is this a problem? Transactions makes use of Task.Delay for several kinds of tasks and it shows up in most components. This is why we couldn't narrow down the performance issues to one particular piece of code. Task.Delay uses a Timer under the hood, creating a Timer which might fire once (if it isn't canceled) and deregisters it once it's no longer needed. Our use of Task.Delay was causing this performance degradation under load. A .NET Core 3.0 user may never have seen such contention, since a good deal of work has gone into .NET Core to improve Timer and Task.Delay performance. See #14527 and #20302 . How do we fix this contention? After verifying that a fix here would actually remedy the problem (success!), I set to work implementing a hopefully simple replacement for Task.Delay . The result is in this PR . The gist of how it works is that it uses a single Timer instance to service thread-local timer collections. The firing of the timers does not need to be precise, so having a timer fire late is not a concern in these uses. Lock contention is largely avoided by using thread-local data structures, but safety is retained by using a light-weight reentrant Interlock.CompareExchange lock. See the PR for more details. The implementation is based on earlier work by @dVakulen in #2060 and resulted in an approximately 4x increase in throughput with failure rates dropping to zero. Mystery solved."
  },
  "blog/welcome-to-orleans-blog.html": {
    "href": "blog/welcome-to-orleans-blog.html",
    "title": "Welcome to Orleans Blog | Microsoft Orleans Documentation",
    "keywords": "Welcome to Orleans Blog Attila Hajdrik 12/1/2016 2:15:01 PM This post is written by Sergey Bykov. Better later than never - we finally started a blog for Orleans. Yes, it is somewhat ironic for a project that originated back in late 2008 and went open source nearly two years ago. We hope to compensate for the missed time with some quality content. We plan to share our thoughts, plans, learnings, tips and tricks, and ideas, crazy and otherwise, which don't easily fit the documentation format. We would also like to see here posts from the community members, sharing their experiences, ideas, and wisdom. So, welcome to Orleans Blog, both as a reader and as a blogger!"
  },
  "docs/benefits.html": {
    "href": "docs/benefits.html",
    "title": "Main Benefits | Microsoft Orleans Documentation",
    "keywords": "好处 Orleans的主要好处是： 开发人员生产力 ，即使对于非专业程序员也是如此， 默认情况下透明的可伸缩性 不需要程序员的特别努力。 我们在下面对这两个好处进行了扩展。 开发人员生产力 Orleans编程模型通过提供以下关键抽象、保证和系统服务，提高了专家和非专家程序员的生产率。 面向对象的编程模式 。 grains是用异步方法实现声明的.net grain接口的.net类。 因此，在程序员看来，grains是可以直接调用其方法的远程对象。 通过将方法调用转换为消息、将它们路由到正确的端点、调用目标Grain的方法以及以完全透明的方式处理失败和角落情况，这为程序员提供了熟悉的oop范例。 单线程执行Grains 。 运行时保证一个Grain一次不会在多个线程上执行。 再加上与其他Grain的隔离，程序员永远不会在Grain级别面临并发，也不需要使用锁或其他同步机制来控制对共享数据的访问。 仅此特性就使得分布式应用程序的开发对于非专家程序员来说是容易的。 透明激活 。 运行时仅当有要处理的消息时才激活Grains。 这将创建对应用程序代码可见并由其控制的grain的引用的概念与对应用程序透明的内存中grain的物理激活的概念完全分离。 在许多方面，这类似于虚拟内存，因为它决定何时“换出页”(停用)或“置入页”(激活)一个grains；应用程序可以不间断地访问逻辑创建的grains的全部“内存空间”，无论它们是否在任何特定时间点位于物理内存中。 透明激活通过在硬件资源池中存储和迁移Grain实现动态、自适应的负载平衡。 这个特性是对传统的actor模型的一个重大改进，其中actor生命周期是由应用程序管理的。 位置透明 . 程序员用来调用grain方法或传递给其他组件的grain引用(代理对象)只包含grain的逻辑标识。 Grains逻辑标识到其物理位置的转换和相应的消息路由是由orleans运行时透明完成的。 应用程序代码与grain进行通信，而不注意它们的物理位置，这可能会随着时间的推移而改变，原因是失败或资源管理，或者是grain在调用时被停用。 与持久存储的透明集成 orleans允许声明性地将grain的内存状态映射到持久化存储。 它同步更新，透明地确保调用方仅在成功更新持久状态后才能接收结果。 扩展和/或定制现有持久存储提供程序集是直截了当的。 自动传播错误 。 运行时使用异步和分布式try/catch的语义自动将未处理的错误传播到调用链上。 因此，错误不会在应用程序中丢失。 这允许程序员将错误处理逻辑放在适当的位置，而无需在每个级别手动传播错误的繁琐工作。 默认情况下透明的可伸缩性 orleans编程模型旨在引导程序员在几个数量级上成功地扩展应用程序或服务。 这是通过结合经验证的最佳实践和模式以及通过提供较低级别系统功能的有效实现来实现的。 以下是实现可伸缩性和性能的一些关键因素： 应用程序状态的隐式细分粒度 。 通过使用Grain作为直接可寻址的实体，程序员隐式地分解了应用程序的整体状态。 虽然Orleans编程模型没有规定Grains应该有多大或多小，但在大多数情况下，拥有相对较大数量的Grains(数百万或更多)是有意义的，每个Grains代表应用程序的自然实体，如用户帐户或采购订单。 由于grains是独立可寻址的，而物理位置是由运行时抽象出来的，因此Orleans在以透明和通用的方式负载均衡和热点处理方面具有极大的灵活性，而不需要应用程序开发人员关心这个问题。 Adaptive resource management . Grains与其他Grains相互作用时，不会假设它们的位置。 由于这种位置透明性，运行时可以动态地管理和调整可用硬件资源的分配。 运行时通过针对负载和通信模式在计算集群中对Grain的存储和迁移做出细Grain的决策来实现这一点，而不会使传入的请求失败。 通过创建特定Grain的多个副本，运行时可以在不更改应用程序代码的情况下提高Grain的吞吐量。 Multiplexed communication . Orleans的Grains有逻辑端点，它们之间的消息传递通过一组固定的全对所有物理连接(TCP套接字)进行多路复用。 这允许运行时对于每个grain以较低的操作系统开销托管数百万个可寻址实体。 此外，Grains的激活和停用不会产生注册/注销物理端点(如TCP端口或HTTP URL)或甚至关闭TCP连接的成本。 Efficient scheduling . 运行时计划在每个物理处理器内核一个线程的自定义线程池中执行大量单线程Grain。 使用以非阻塞、基于连续性的风格(Orleans编程模型的要求)编写的Grain代码，应用程序代码以非常高效的“协作”多线程方式运行，没有争用。 这使得系统能够达到高吞吐量，并以非常高的CPU利用率(高达90%+)运行，具有极大的稳定性。 系统中grains数量的增长和负载的增加不会导致额外的线程或其他操作系统原语，这一事实有助于单个节点和整个系统的可伸缩性。 Explicit asynchrony . orleans编程模型使分布式应用程序的异步特性变得明确，并指导程序员编写非阻塞异步代码。 结合异步消息传递和高效的调度，这使得无需显式地使用多线程就可以实现很大程度的分布式并行性和总吞吐量。"
  },
  "docs/deployment/azure_web_apps_with_azure_cloud_services.html": {
    "href": "docs/deployment/azure_web_apps_with_azure_cloud_services.html",
    "title": "Using Azure Web Apps with Azure Cloud Services | Microsoft Orleans Documentation",
    "keywords": "Using Azure Web Apps with Azure Cloud Services If you would like to connect to an Azure Cloud Services Silo from an Azure Web App rather than a Web Role hosted within the same cloud service you can. For this to work securely you will need to assign both the Azure Web App and the Worker Role hosting the Silo to an Azure Virtual Network . First we'll setup the Azure Web App, you can follow this guide which will create the virtual network and assign it to the Azure Web App. Now we can assign the cloud service to the virtual network by modifying the ServiceConfiguration file. <NetworkConfiguration> <VirtualNetworkSite name=\"virtual-network-name\" /> <AddressAssignments> <InstanceAddress roleName=\"role-name\"> <Subnets> <Subnet name=\"subnet-name\" /> </Subnets> </InstanceAddress> </AddressAssignments> </NetworkConfiguration> Also make sure the Silo endpoints are configured. <Endpoints> <InternalEndpoint name=\"OrleansSiloEndpoint\" protocol=\"tcp\" port=\"11111\" /> <InternalEndpoint name=\"OrleansProxyEndpoint\" protocol=\"tcp\" port=\"30000\" /> </Endpoints> You can now connect from the Web App to the rest of the cluster. Potential Issues If the Web App is having difficulty connecting to the Silo: Make sure you have at least two roles , or two instances of one role in your Azure Cloud Service, or the InternalEndpoint firewall rules may not be generated. Check that both the Web App and the Silo are using the same ClusterId and ServiceId . Make sure the network security group is set up to allow internal virtual network connections. If you haven't got one you can create and assign one easily using the following PowerShell : New-AzureNetworkSecurityGroup -Name \"Default\" -Location \"North Europe\" Get-AzureNetworkSecurityGroup -Name \"Default\" | Set-AzureNetworkSecurityGroupToSubnet -VirtualNetworkName \"virtual-network-name\" -SubnetName \"subnet-name\""
  },
  "docs/deployment/consul_deployment.html": {
    "href": "docs/deployment/consul_deployment.html",
    "title": "Using Consul as a Membership Provider | Microsoft Orleans Documentation",
    "keywords": "Using Consul as a Membership Provider Introduction to Consul Consul is a distributed, highly available and datacenter-aware service discovery platform which includes simple service registration, health checking, failure detection and key/value storage. It is built on the premise that every node in the datacenter is running a Consul agent which is either acting as a server or client which communicate via a scalable gossip protocol. There is a very detailed overview of Consul including comparisons with similar solutions here . Consul is written in GO and is open source ; compiled downloads are available for Mac OS X, FreeBSD, Linux, Solaris and Windows Why Choose Consul? As an Orleans Membership Provider , Consul is a good choice when you need to deliver an on-premise solution which does not require your potential customers to have existing infrastructure and a co-operative IT provider. Consul is a very lightweight single executable, has no dependencies and as such can easily be built into your own middleware solution. And when Consul is already your solution for discovering, checking and maintaining your microservices, it makes sense to fully integrate with Orleans membership for simplicity and ease of operation. We therefore implemented a membership table in Consul (also known as \"Orleans Custom System Store\"), which fully integrates with Orleans's Cluster Management . Setting up Consul There is very extensive documentation available on Consul.io about setting up a stable Consul cluster and it doesn't make sense to repeat that here; however for your convenience we include this guide so you can very quickly get Orleans running with a standalone Consul agent. 1) Create a folder to install Consul into, e.g. C:\\Consul 2) Create a subfolder: C:\\Consul\\Data (Consul will not create this if it doesn't exist) 3) Download and unzip Consul.exe into C:\\Consul\\ 4) Open a command prompt at C:\\Consul\\ 5) Enter Consul.exe agent -server -bootstrap -data-dir \"C:\\Consul\\Data\" -client=0.0.0.0 agent Instructs Consul to run the agent process that hosts the services. Without this the Consul process will attempt to use RPC to configure a running agent. -server Defines the agent as a server and not a client (A Consul client is an agent that hosts all the services and data, but does not have voting rights to decide, and cannot become, the cluster leader -bootstrap The first (and only the first!) node in a cluster must be bootstrapped so that it assumes the cluster leadership. -data-dir [path] Specifies the path where all Consul data is stored, including the cluster membership table -client=0.0.0.0 Informs Consul which IP to open the service on. There are many other parameters, and the option to use a json configuration file. Please consult the Consul documentation for a full listing of the options. 6) Verify that Consul is running and ready to accept membership requests from Orleans by opening the services endpoint in your browser. Configuration of Orleans Server There is currently a known issue with the \"Custom\" membership provider OrleansConfiguration.xml configuration file that will fail to parse correctly. For this reason you have to provide a placeholder SystemStore in the xml and then configure the provider in code before starting the Silo. OrleansConfiguration.xml <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <SystemStore SystemStoreType=\"None\" DataConnectionString=\"http://localhost:8500\" DeploymentId=\"MyOrleansDeployment\" /> </Globals> <Defaults> <Networking Address=\"localhost\" Port=\"22222\" /> <ProxyingGateway Address=\"localhost\" Port=\"30000\" /> </Defaults> </OrleansConfiguration> Code public void Start(ClusterConfiguration config) { _siloHost = new SiloHost(System.Net.Dns.GetHostName(), config); _siloHost.Config.Globals.LivenessType = GlobalConfiguration.LivenessProviderType.Custom; _siloHost.Config.Globals.MembershipTableAssembly = \"OrleansConsulUtils\"; _siloHost.Config.Globals.ReminderServiceType = GlobalConfiguration.ReminderServiceProviderType.Disabled; _siloHost.InitializeOrleansSilo(); var startedok = _siloHost.StartOrleansSilo(); if (!startedok) throw new SystemException(String.Format(\"Failed to start Orleans silo '{0}' as a {1} node\", _siloHost.Name, _siloHost.Type)); Log.Information(\"Orleans Silo is running.\\n\"); } Alternatively you could configure the silo entirely in code. Client The client configuration is much simpler ClientConfiguration.xml <ClientConfiguration xmlns=\"urn:orleans\"> <SystemStore SystemStoreType=\"Custom\" CustomGatewayProviderAssemblyName=\"OrleansConsulUtils\" DataConnectionString=\"http://192.168.1.26:8500\" DeploymentId=\"MyOrleansDeployment\" /> </ClientConfiguration> Client SDK If you are interested in using Consul for your own service discovery there are Client SDKs for most popular languages. Implementation Detail The Membership Table Provider makes use of Consul's Key/Value store functionality with CAS. When each Silo starts it registers two KV entries, one which contains the Silo details and one which holds the last time the Silo reported it was alive (the latter refers to diagnostics \"I am alive\" entries and not to failure detection hearbeats which are sent directly between the silos and are not written into the table). All writes to the table are performed with CAS to provide concurrency control, as necessitated by Orleans's Cluster Management Protocol . Once the Silo is running you can view these entries in your web browser here , this will display something like: [ \"orleans/MyOrleansDeployment/192.168.1.26:11111@191780753\", \"orleans/MyOrleansDeployment/192.168.1.26:11111@191780753/iamalive\" ] You will notice that the keys are prefixed with \"orleans/\" this is hard coded in the provider and is intended to avoid key space collision with other users of Consul. Each of these keys can be read by appending their key name (sans quotes of course) to the Consul KV root . Doing so will present you with the following: [ { \"LockIndex\": 0, \"Key\": \"orleans/MyOrleansDeployment/192.168.1.26:22222@191780753\", \"Flags\": 0, \"Value\": \"[BASE64 UTF8 Encoded String]\", \"CreateIndex\": 10, \"ModifyIndex\": 12 } ] Decoding the string will give you the actual Orleans Membership data: http://localhost:8500/v1/KV/orleans/MyOrleansDeployment/[SiloAddress] { \"Hostname\": \"[YOUR_MACHINE_NAME]\", \"ProxyPort\": 22222, \"StartTime\": \"2016-01-29T16:25:54.9538838Z\", \"Status\": 3, \"SuspectingSilos\": [] } http://localhost:8500/v1/KV/orleans/MyOrleansDeployment/[SiloAddress]/IAmAlive \"2016-01-29T16:35:58.9193803Z\" When the Clients connect, they read the KVs for all silos in the cluster in one HTTP GET by using the uri http://192.168.1.26:8500/v1/KV/orleans/MyOrleansDeployment/?recurse . Limitations Orleans Extended Membership Protocol (Table Version & ETag) Consul KV currrently does not currently support atomic updates. Therefore, the Orleans Consul Membership Provider only implements the the Orleans Basic Membership Protocol, as described here and does not support the Extended Membership Protocol. This Extended protocol was introduced as an additional, but not essential, silo connectivity validation and as a foundation to functionality that has not yet been implemented. Providing your infrastructure is correctly configured you will not experience any detrimental effect of the lack of support. Multiple Datacenters The Key Value Pairs in Consul are not currently replicated between Consul datacenters. There is a separate project to address this but it has not yet been proven to support Orleans. When running on Windows When Consul starts on Windows it logs the following message: ==> WARNING: Windows is not recommended as a Consul server. Do not use in production. This is displayed simply due to lack of focus on testing when running in a Windows environment and not because of any actual known issues. Read the discussion here before deciding if Consul is the right choice for you. Potential Future Enhanecements 1) Prove that the Consul KV replication project is able to support an Orleans cluster in a WAN environment between multiple Consul datacenters. 2) Implement the Reminder Table in Consul. 3) Implement the Extended Membership Protocol. The team behind Consul does plan on implementing atomic operations, once this functionality is available it will be possible to remove the limitations in the provider."
  },
  "docs/deployment/docker_deployment.html": {
    "href": "docs/deployment/docker_deployment.html",
    "title": "Docker Deployment | Microsoft Orleans Documentation",
    "keywords": "Docker Deployment Note : Even if you are very familiar with Docker and/or Orleans, as any other Orleans documentation, I recommend you to read it to the end in order to avoid problems you may face that we already worked around. Note : This article and its sample are a work in progress. Any feedback, PR or suggestion is very welcome. Deploying Orleans solutions to Docker Deploying Orleans to Docker can be tricky given the way Docker orchestrators and clustering stacks was designed. The most complicated thing is to understand the concept of Overlay Network from Docker Swarm and Kubernets Networking model. Docker containers and networking model were designed to run mostly stateless and immutable containers. So, spinning up a cluster running node.js or nginx applications, is pretty easy. However, if you try to use something more elaborate, like a real clustered or distributed application (like Orleans-based ones) you will eventually have trouble setting it up. It is possible, but not as simple as web-based applications. Docker clustering consists of putting together multiple hosts to work as a single pool of resources, managed using a Container Orchestrator . Docker Inc. provide Swarm as their option for Container Orchestration while Google has Kubernetes (aka K8s ). There are other Orchestrators like DC/OS , Mesos , etc., but in this document we will talk about Swarm and K8s as they are more widely used. The same grain interfaces and implementation which run anywhere Orleans is already supported, will run on Docker containers as well, so no special considerations are needed in order to be able to run your application in Docker containers. The Orleans-Docker sample provides a working example of how to run two console applications. One as Orleans Client and another as Silo, and the details are described below. The concepts discussed here, can be used on both .Net Core and .Net 4.6.1 flavors of Orleans but to ilustrate the cross-platform nature of Docker and .Net Core, we are going to focus on the example considering you are using .Net Core. Platform-specific (Windows/Linux/OSX) details may be provide along this article. Pre-requisites This article assume that you have the following prerequisites installed: Docker - Docker4X has a easy-to-use installer for the major supported platforms. It contains Docker engine and also Docker Swarm. Kubernetes (K8s) - Google's offer for Container Orchestration. It contains a guidance to install Minikube (a local deployment of K8s) and kubectl along with all its dependencies. .Net Core - Cross-platform flavor of .Net Visual Studio Code (VSCode) - You can use whatever IDE you want. VSCode is cross-platform so we are using it to ensure it works on all platforms. Once you installed VSCode, install the C# extension . Note : You are not required to have Kubernetes installed if you are not going to use it. Docker4X installer already includes Swarm so no extra installation is required to use it. Note for Windows Users : On Windows, Docker installer will enable Hyper-V at installation process. As this article and its examples are using .Net Core, the container images used are based on Windows Server NanoServer . If you don't plan to use .Net Core and will target .Net 4.6.1 full framework, the image used should be Windows Server Core and the 1.4+ version of Orleans (which supports only .net full framework). Creating Orleans Solution The following instructions show how to create a regular Orleans solution using the new dotnet tooling. Note : Please adapt the commands to whatever is appropriate in your platform. Also, the directory structure is just a suggestion. Please adapt it to your needs. mkdir Orleans-Docker cd Orleans-Docker dotnet new sln mkdir -p src/OrleansSilo mkdir -p src/OrleansClient mkdir -p src/OrleansGrains mkdir -p src/OrleansGrainInterfaces dotnet new console -o src/OrleansSilo --framework netcoreapp1.1 dotnet new console -o src/OrleansClient --framework netcoreapp1.1 dotnet new classlib -o src/OrleansGrains --framework netstandard1.5 dotnet new classlib -o src/OrleansGrainInterfaces --framework netstandard1.5 dotnet sln add src/OrleansSilo/OrleansSilo.csproj dotnet sln add src/OrleansClient/OrleansClient.csproj dotnet sln add src/OrleansGrains/OrleansGrains.csproj dotnet sln add src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj dotnet add src/OrleansClient/OrleansClient.csproj reference src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj dotnet add src/OrleansSilo/OrleansSilo.csproj reference src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj dotnet add src/OrleansGrains/OrleansGrains.csproj reference src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj dotnet add src/OrleansSilo/OrleansSilo.csproj reference src/OrleansGrains/OrleansGrains.csproj What we did so far was just boilerplate code to create the solution structure, projects, and add references between projects. Nothing different than a regular Orleans project. By the time this article was written, Orleans 2.0 (which is the only version which support .Net Core and cross-platform) is in Technology Preview so its nugets are hosted in a MyGet feed and not published to Nuget.org official feed. In order to install the preview nugets, we will use dotnet cli forcing the source feed and version from MyGet: dotnet add src/OrleansClient/OrleansClient.csproj package Microsoft.Orleans.Core -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet add src/OrleansGrainInterfaces/OrleansGrainInterfaces.csproj package Microsoft.Orleans.Core -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet add src/OrleansGrains/OrleansGrains.csproj package Microsoft.Orleans.Core -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet add src/OrleansSilo/OrleansSilo.csproj package Microsoft.Orleans.Core -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet add src/OrleansSilo/OrleansSilo.csproj package Microsoft.Orleans.OrleansRuntime -s https://dotnet.myget.org/F/orleans-prerelease/api/v3/index.json -v 2.0.0-preview2-201705020000 dotnet restore Ok, now you have all the basic dependencies to run a simple Orleans application. Note that so far, nothing changed from your regular Orleans application. Now, lets add some code so we can do something with it. Implementing your Orleans Application Assuming that you are using VSCode , from the solution directory, run code . . That will open the directory in VSCode and load the solution. This is the solution structure we just created previously. We also added Program.cs , OrleansHostWrapper , IGreetingGrain and GreetingGrain files to the interfaces and grain projects respectively and here is the code for those files: IGreetingGrain.cs : using System; using System.Threading.Tasks; using Orleans; namespace OrleansGrainInterfaces { public interface IGreetingGrain : IGrainWithGuidKey { Task<string> SayHello(string name); } } GreetingGrain.cs : using System; using System.Threading.Tasks; using OrleansGrainInterfaces; namespace OrleansGrains { public class GreetingGrain : Grain, IGreetingGrain { public Task<string> SayHello(string name) { return Task.FromResult($\"Hello from Orleans, {name}\"); } } } OrleansHostWrapper.cs : using System; using System.Net; using Orleans.Runtime; using Orleans.Runtime.Configuration; using Orleans.Runtime.Host; namespace OrleansSilo { public class OrleansHostWrapper { private readonly SiloHost siloHost; public OrleansHostWrapper(ClusterConfiguration config) { siloHost = new SiloHost(Dns.GetHostName(), config); siloHost.LoadOrleansConfig(); } public int Run() { if (siloHost == null) { return 1; } try { siloHost.InitializeOrleansSilo(); if (siloHost.StartOrleansSilo()) { Console.WriteLine($\"Successfully started Orleans silo '{siloHost.Name}' as a {siloHost.Type} node.\"); return 0; } else { throw new OrleansException($\"Failed to start Orleans silo '{siloHost.Name}' as a {siloHost.Type} node.\"); } } catch (Exception exc) { siloHost.ReportStartupError(exc); Console.Error.WriteLine(exc); return 1; } } public int Stop() { if (siloHost != null) { try { siloHost.StopOrleansSilo(); siloHost.Dispose(); Console.WriteLine($\"Orleans silo '{siloHost.Name}' shutdown.\"); } catch (Exception exc) { siloHost.ReportStartupError(exc); Console.Error.WriteLine(exc); return 1; } } return 0; } } } Program.cs (Silo): using System; using System.Collections.Generic; using System.Linq; using System.Net; using Orleans.Runtime.Configuration; namespace OrleansSilo { public class Program { private static OrleansHostWrapper hostWrapper; static int Main(string[] args) { int exitCode = InitializeOrleans(); Console.WriteLine(\"Press Enter to terminate...\"); Console.ReadLine(); exitCode += ShutdownSilo(); return exitCode; } private static int InitializeOrleans() { var config = new ClusterConfiguration(); config.Globals.DataConnectionString = \"[AZURE STORAGE CONNECTION STRING HERE]\"; config.Globals.DeploymentId = \"Orleans-Docker\"; config.Globals.LivenessType = GlobalConfiguration.LivenessProviderType.AzureTable; config.Globals.ReminderServiceType = GlobalConfiguration.ReminderServiceProviderType.AzureTable; config.Defaults.PropagateActivityId = true; config.Defaults.ProxyGatewayEndpoint = new IPEndPoint(IPAddress.Any, 10400); config.Defaults.Port = 10300; var ips = Dns.GetHostAddressesAsync(Dns.GetHostName()).Result; config.Defaults.HostNameOrIPAddress = ips.FirstOrDefault()?.ToString(); hostWrapper = new OrleansHostWrapper(config); return hostWrapper.Run(); } private static int ShutdownSilo() { if (hostWrapper != null) { return hostWrapper.Stop(); } return 0; } } } Program.cs (client): using System; using System.Net; using System.Threading; using System.Threading.Tasks; using Orleans; using Orleans.Runtime.Configuration; using OrleansGrainInterfaces; namespace OrleansClient { class Program { private static IClusterClient client; private static bool running; static void Main(string[] args) { Task.Run(() => InitializeOrleans()); Console.ReadLine(); running = false; } static async Task InitializeOrleans() { var config = new ClientConfiguration(); config.DeploymentId = \"Orleans-Docker\"; config.PropagateActivityId = true; var hostEntry = await Dns.GetHostEntryAsync(\"orleans-silo\"); var ip = hostEntry.AddressList[0]; config.Gateways.Add(new IPEndPoint(ip, 10400)); Console.WriteLine(\"Initializing...\"); client = new ClientBuilder().UseConfiguration(config).Build(); await client.Connect(); running = true; Console.WriteLine(\"Initialized!\"); var grain = client.GetGrain<IGreetingGrain>(Guid.Empty); while(running) { var response = await grain.SayHello(\"Gutemberg\"); Console.WriteLine($\"[{DateTime.UtcNow}] - {response}\"); await Task.Delay(1000); } client.Dispose(); } } } We are not going into details about the grain implementation here since it is out of the scope of this article. Please check other documents related to it. Those files are essentially a minimal Orleans application and we will start from it to move forward with the remaining of this article. Note : In this article we are using OrleansAzureUtils membership provider but you can use any other already supported by Orleans. Dockerfile In order to create your container, Docker uses images. For more details on how to create your own, you can check Docker documentation . In this article we are going to use official Microsoft images . Based on the target and development platforms, you need to pick the appropriate image. In this article, we are using microsoft/dotnet:1.1.2-sdk which is a linux-based image. You can use microsoft/dotnet:1.1.2-sdk-nanoserver for Windows for example. Pick one that suit your needs. Note for Windows users : As previously mentioned, to be cross-platform, we are using .Net Core and Orleans Technical preview 2.0 in this article. If you want to use Docker on Windows with the fully released Orleans 1.4+, you need to use the images that are based on Windows Server Core since NanoServer and Linux based images, only support .Net Core. Dockerfile.debug : FROM microsoft/dotnet:1.1.2-sdk ENV NUGET_XMLDOC_MODE skip WORKDIR /vsdbg RUN apt-get update \\ && apt-get install -y --no-install-recommends \\ unzip \\ && rm -rf /var/lib/apt/lists/* \\ && curl -sSL https://aka.ms/getvsdbgsh | bash /dev/stdin -v latest -l /vsdbg WORKDIR /app ENTRYPOINT [\"tail\", \"-f\", \"/dev/null\"] This dockerfile essentially downloads and installs the VSdbg debugger and starts an empty container, keeping it alive forever so we don't need tear down/up while debugging. Now, for production, the image is smaller since it contains only the .Net Core runtime and not the whole SDK, and the dockerfile is a bit simpler: Dockerfile : FROM microsoft/dotnet:1.1.2-runtime WORKDIR /app ENTRYPOINT [\"dotnet\", \"OrleansSilo.dll\"] COPY . /app docker-compose The docker-compose.yml file, essentially defines (within a project) a set of services and its dependencies at service level. Each service contains one or more instances of a given container, which is based on the images you selected on your Dockerfile. More details on the docker-compose can be found on docker-compose documentation . For an Orleans deployment, a common use case is to have a docker-compose.yml which contains two services. One for Orleans Silo, and other for Orleans Client. The Client would have a dependency on the Silo and that means, it will only start after the Silo service is up. Another case is to add a storage/database service/container, like for example SQL Server, which should start first before the client and the silo, so both services should take a dependency on it. Note : Before you read further (and eventually get crazy with it), please note that identation matters in docker-compose files. So pay attention to it if you have any problem. Here is how we will describe our services for this article: docker-compose.override.yml (Debug): version: '3.1' services: orleans-client: image: orleans-client:debug build: context: ./src/OrleansClient/bin/PublishOutput/ dockerfile: Dockerfile.Debug volumes: - ./src/OrleansClient/bin/PublishOutput/:/app - ~/.nuget/packages:/root/.nuget/packages:ro depends_on: - orleans-silo orleans-silo: image: orleans-silo:debug build: context: ./src/OrleansSilo/bin/PublishOutput/ dockerfile: Dockerfile.Debug volumes: - ./src/OrleansSilo/bin/PublishOutput/:/app - ~/.nuget/packages:/root/.nuget/packages:ro docker-compose.yml (production): version: '3.1' services: orleans-client: image: orleans-client depends_on: - orleans-silo orleans-silo: image: orleans-silo Note that in production, we don't map the local directory and neither we have the build: action. The reason is that in production, the images should be built and pushed to your own Docker Registry. Put everything together Now we have all the moving parts required to run your Orleans Application, we are going to put it together so we can run our Orleans solution inside Docker (Finally!). Note : The following commands should be performed from the solution directory. First, lets make sure we restore all NuGet packages from our solution. You only need to do it once. You are only required to do it again if you change any package dependency on your project. # dotnet restore Now, let's build our solution using dotnet CLI as usual and publish it to an output directory: # dotnet publish -o ./bin/PublishOutput Note : We are using publish here instead of build, to avoid problems with our dynamicaly loaded assemblied in Orleans. We are still looking for a better solution for it. With the application built and published, you need to build your Dockerfile images. This step is only required to be performed once per project and should be only performed again if you change the Dockerfile, docker-compose, or for any reason you cleaned up your local image registry. # docker-compose build All the images used in both Dockerfile and docker-compose.yml are pulled from the registry and cached on your development machine. Your images are built, and you are all set to run. Now lets run it! # docker-compose up -d Creating network \"orleansdocker_default\" with the default driver Creating orleansdocker_orleans-silo_1 ... Creating orleansdocker_orleans-silo_1 ... done Creating orleansdocker_orleans-client_1 ... Creating orleansdocker_orleans-client_1 ... done # Now if you run a docker-compose ps , you will see 2 containers running for the orleansdocker project: # docker-compose ps Name Command State Ports ------------------------------------------------------------------ orleansdocker_orleans-client_1 tail -f /dev/null Up orleansdocker_orleans-silo_1 tail -f /dev/null Up Note for Windows users : If you are on Windows, and your container is using a Windows image as base, the Command column will show you the Powershell relative command to a tail on *NIX systems so the container will keep up the same way. Now that you have your containers up, you don't need to stop it every time you want to start your Orleans application. All you need is to integrate your IDE to debug the application inside the container which was previously mapped in your docker-compose.yml . Scaling Once you have your compose project running, you can easily scale up or down your application using docker-compose scale command: # docker-compose scale orleans-silo=15 Starting orleansdocker_orleans-silo_1 ... done Creating orleansdocker_orleans-silo_2 ... Creating orleansdocker_orleans-silo_3 ... Creating orleansdocker_orleans-silo_4 ... Creating orleansdocker_orleans-silo_5 ... Creating orleansdocker_orleans-silo_6 ... Creating orleansdocker_orleans-silo_7 ... Creating orleansdocker_orleans-silo_8 ... Creating orleansdocker_orleans-silo_9 ... Creating orleansdocker_orleans-silo_10 ... Creating orleansdocker_orleans-silo_11 ... Creating orleansdocker_orleans-silo_12 ... Creating orleansdocker_orleans-silo_13 ... Creating orleansdocker_orleans-silo_14 ... Creating orleansdocker_orleans-silo_15 ... Creating orleansdocker_orleans-silo_6 Creating orleansdocker_orleans-silo_5 Creating orleansdocker_orleans-silo_3 Creating orleansdocker_orleans-silo_2 Creating orleansdocker_orleans-silo_4 Creating orleansdocker_orleans-silo_9 Creating orleansdocker_orleans-silo_7 Creating orleansdocker_orleans-silo_8 Creating orleansdocker_orleans-silo_10 Creating orleansdocker_orleans-silo_11 Creating orleansdocker_orleans-silo_15 Creating orleansdocker_orleans-silo_12 Creating orleansdocker_orleans-silo_14 Creating orleansdocker_orleans-silo_13 Few seconds later, you will see the services scaled to the specific number of instances you requested. # docker-compose ps Name Command State Ports ------------------------------------------------------------------ orleansdocker_orleans-client_1 tail -f /dev/null Up orleansdocker_orleans-silo_1 tail -f /dev/null Up orleansdocker_orleans-silo_10 tail -f /dev/null Up orleansdocker_orleans-silo_11 tail -f /dev/null Up orleansdocker_orleans-silo_12 tail -f /dev/null Up orleansdocker_orleans-silo_13 tail -f /dev/null Up orleansdocker_orleans-silo_14 tail -f /dev/null Up orleansdocker_orleans-silo_15 tail -f /dev/null Up orleansdocker_orleans-silo_2 tail -f /dev/null Up orleansdocker_orleans-silo_3 tail -f /dev/null Up orleansdocker_orleans-silo_4 tail -f /dev/null Up orleansdocker_orleans-silo_5 tail -f /dev/null Up orleansdocker_orleans-silo_6 tail -f /dev/null Up orleansdocker_orleans-silo_7 tail -f /dev/null Up orleansdocker_orleans-silo_8 tail -f /dev/null Up orleansdocker_orleans-silo_9 tail -f /dev/null Up Note : The Command column on those examples are showing the tail command just because we are using the debugger container. If we were in production, it would be showing dotnet OrleansSilo.dll for example. Docker Swarm Docker clustering stack is called Swarm and you can find more by reading its documentation here . To run this article in a Swarm cluster, you don't have any extra work. When you run docker-compose up -d in a Swarm node, it will schedule containers based on the configured rules. The same applies to other Swarm-based services like Docker Datacenter , Azure ACS (in Swarm mode), AWS ECS Container Service and so on. All you need to do is to deploy your Swarm cluster before deploy your dockerized Orleans application. Note : If you are using a Docker engine with the Swarm mode that already have support to stack , deploy and compose v3, a better approach to deploy your solution would be docker stack deploy -c docker-compose.yml <name> . Just keep in mind that it requires v3 compose file support at your Docker engine and the majority of hosted services like Azure and AWS still use v2 and older engines. Google Kubernetes (K8s) If you plan to use Kubernetes to host Orleans, there is a community-maintained clustering provider available at OrleansContrib\\Orleans.Clustering.Kubernetes and there you can find documentation and samples on how to host Orleans in Kubernetes seamlessly using the provider. [Bonus topic] Debugging Orleans inside Containers Well, now that you know how to run Orleans in a container from scratch, would be good to leverage one of the most important principles in Docker. Containers are immutable. And they should have (almost) the same image, dependencies, and runtime in development as in production. This ensures the good old statement \"It works on my machine!\" never happens again. To make that possible, you need to have a way to develop inside the container and that includes have a debugger attached to your application inside the container. There are multiple ways to achieve that using multiple tools. After evaluating several, by the time I wrote this article, I ended up choosing one that looks more simple and is less intrusive in the application. As mentioned ealier in this article, we are using VSCode to develop the sample, so here is how to get the debugger attached to your Orleans Application inside the container. First, change two files inside your .vscode directory in your solution: tasks.json : { \"version\": \"0.1.0\", \"command\": \"dotnet\", \"isShellCommand\": true, \"args\": [], \"tasks\": [ { \"taskName\": \"publish\", \"args\": [ \"${workspaceRoot}/Orleans-Docker.sln\", \"-c\", \"Debug\", \"-o\", \"./bin/PublishOutput\" ], \"isBuildCommand\": true, \"problemMatcher\": \"$msCompile\" } ] } This file essentially tells VSCode that whenever you build the project, it will actually execute the publish command as we manually did earlier. launch.json : { \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"Silo\", \"type\": \"coreclr\", \"request\": \"launch\", \"cwd\": \"/app\", \"program\": \"/app/OrleansSilo.dll\", \"sourceFileMap\": { \"/app\": \"${workspaceRoot}/src/OrleansSilo\" }, \"pipeTransport\": { \"debuggerPath\": \"/vsdbg/vsdbg\", \"pipeProgram\": \"/bin/bash\", \"pipeCwd\": \"${workspaceRoot}\", \"pipeArgs\": [ \"-c\", \"docker exec -i orleansdocker_orleans-silo_1 /vsdbg/vsdbg --interpreter=vscode\" ] } }, { \"name\": \"Client\", \"type\": \"coreclr\", \"request\": \"launch\", \"cwd\": \"/app\", \"program\": \"/app/OrleansClient.dll\", \"sourceFileMap\": { \"/app\": \"${workspaceRoot}/src/OrleansClient\" }, \"pipeTransport\": { \"debuggerPath\": \"/vsdbg/vsdbg\", \"pipeProgram\": \"/bin/bash\", \"pipeCwd\": \"${workspaceRoot}\", \"pipeArgs\": [ \"-c\", \"docker exec -i orleansdocker_orleans-client_1 /vsdbg/vsdbg --interpreter=vscode\" ] } } ] } Now you can just build the solution from VSCode (which will publish) and start both the Silo and the Client. It will send a docker exec command to the running docker-compose service instance/container to start the debugger to the application and thats it. You have the debugger attached to the container and use it as if it was a locally running Orleans application. The difference now is that it is inside the container, and once you are done, you can just publish the container to your registry and pull it on your Docker hosts in production."
  },
  "docs/deployment/handling_failures.html": {
    "href": "docs/deployment/handling_failures.html",
    "title": "Handling Failures | Microsoft Orleans Documentation",
    "keywords": "Handling Failures Note: All of the following guidance in this document is provided to serve as examples and food for thought. You should not think of them as prescriptive solutions to your problems because failure handling is a rather application-specific subject. These patterns and others are only useful if applied with a good knowledge of the concrete case being worked on. The hardest thing in programming a distributed system is handling failures. The actor model and the way it works makes it much easier to deal with different kinds of failures, but as a developer, you are responsible for dealing with the failure possibilities and handling them in an appropriate way. Types of failures When you are coding your grains, all calls are asynchronous and have the potential to go over the network. Each grain call can possibly fail due to one of the following reasons. The grain was activated on a silo which is unavailable at the moment due to a network partition crash or some other reason. If the silo has not been declared dead yet, your request might time out. The grain method call can throw an exception signaling that it failed and can not continue its job. An activation of the grain doesn't exist and cannot be created because the OnActivateAsync method throws an exception or is dead-locked. Network failures don't let you to communicate with the grain before timeout. Other potential reasons Detection of failures Getting a reference to a grain always succeeds and is a local operation. However, method calls can fail, and when they do, you get an exception. You can catch the exception at any level you need and they are propagated even across silos. Recovering from failures Part of the recovery job is automatic in Orleans and if a grain is not accessible anymore, Orleans will reactivate it in the next method call. The thing you need to handle and make sure is correct in the context of your application is the state. A grain's state can be partially updated or the operation might be something which should be done across multiple grains and is carried on partially. After you see a grain operation fail you can do one or more of the following. Simply retry your action, especially if it doesn't involve any state changes which might be half done. This is by far the most typical case. Try to fix/reset the partially changed state by calling a method which resets the state to the last known correct state or just reads it from storage by calling ReadStateAsync . Reset the state of all related activations as well to ensure a clean state for all of them. Perform multi-grain state manipulations using a Process Manager or database transaction to make sure it's either done completely or nothing is changed to avoid the state being partially updated. Depending on your application, the retry logic might follow a simple or complex pattern, and you might have to do other stuff like notifying external systems and other things, but generally you either have to retry your action, restart the grain/grains involved, or stop responding until something which is not available becomes available. If you have a grain responsible for database saves and the database is not available, you simply have to fail any request until the database comes back online. If your operation can be retried at the user's will, like failure of saving a comment in a comment grain, you can retry when the user presses the retry button (until a certain number of times in order to not saturate the network). Specific details of how to do it are application specific, but the possible strategies are the same. Strategy parameters and choosing a good strategy As described in the section above, the strategy you choose depends on the application and context. Strategies usually have parameters which have to be decided at the application level. For example, if no other processes depend on an action, then you might decide to retry that action a maximum of 5 times per minute until it eventually completes. But you would have to process a user's Login grain request before processing any other requests from that user. If the login action is not working, then you cannot continue. There is a guide in the Azure documentation about good patterns and practices for the cloud which applies to Orleans as well, in most cases. A fairly complex example Because in Orleans grains are activated and deactivated automatically and you don't handle their life-cycle, you usually only deal with making sure that grain state is correct and actions are being started and finished correctly in relation to each other. Knowing the dependencies between grains and actions they perform is a big step toward understanding how to handle failure in any complex system. If you need to store relations among grains, you can simply do it and it is a widely followed practice, too. As an example, let's say we have a GameManager grain which starts and stops Game grains and adds Player grains to the games. If my GameManager grain fails to do its action regarding starting a game, the related game belonging to it should fail to do its Start() as well and the manager can do this for the game by doing orchestration. Managing memory in Orleans is automatic and the system deals with it, you only need to make sure that the game starts and only if manager can do its Start() as well. You can achieve this by either calling the related methods in a sequential manner or by doing them in parallel and resetting the state of all involved grains if any of them fail. If one of the games receives a call, it will be reactivated automatically, so if you need the manager to manage the game grains, then all calls to the game which are related to management should go through the GameManager . If you need orchestration among grains, Orleans doesn't solve it \"automagically\" for you and you need to do your orchestration. But the fact that you are not dealing with creating/destroying grains means you don't need to worry about resource management. You don't need to answer any of these questions: Where should I create my supervision tree? which grains should I register to be addressable by name? Is grain X alive so I can send it a message? ... So, the game start example can be summarized like this: GameManager asks the Game grain to start Game grain adds the Player grains to itself Game asks Player grains to add game to themselves Game sets its state to be started. GameManager adds the game to its list of games. Now, if a player fails to add the game to itself, you don't need to kill all players and the game and start over. You simply reset the state of the other players which added the game to themselves, reset the state of the Game and GameManager (if required), and redo your work or declare a failure. If you can deal with adding the game to the player later on, you can continue and retry doing that again in a reminder or at some other game call like the Finish() method of the game."
  },
  "docs/deployment/index.html": {
    "href": "docs/deployment/index.html",
    "title": "Running the Application | Microsoft Orleans Documentation",
    "keywords": "Orleans Application A typical Orleans application consists of a cluster of server processes (silos) where grains live, and a set of client processes, usually web servers, that receive external requests, turn them into grain method calls, and return results back. Hence, the first thing one needs to do to run an Orleans application is to start a cluster of silos. For testing purposes, a cluster can consist of a single silo. For a reliable production deployment, we obviously want more than one silos in a cluster for fault tolerance and scale. Once the cluster is running, we can start one or more client processes that connect to the cluster and can send requests to the grains. Clients connect to a special TCP endpoint on silos - gateway. By default, every silo in a cluster has a client gateway enabled. So clients can connect to all silos in parallel for better performance and resilience. Configuring and Starting a Silo A silo is configured programmatically via a ClusterConfiguration object. It can be instantiated and populated directly, load settings from a file, or created with several available helper methods for different deployment environments. For local testing, the easiest way to go is to use ClusterConfiguration.LocalhostPrimarySilo() helper method. The configuration object is then passed to a new instance of SiloHost class, that can be initialized and started after that. You can create an empty console application project targeting .NET Framework 4.6.1 or higher for hosting a silo. Add the Microsoft.Orleans.Server NuGet meta-package to the project. PM> Install-Package Microsoft.Orleans.Server Here is an example of how a local silo can be started: var siloConfig = ClusterConfiguration.LocalhostPrimarySilo(); var silo = new SiloHost(\"Test Silo\", siloConfig); silo.InitializeOrleansSilo(); silo.StartOrleansSilo(); Console.WriteLine(\"Press Enter to close.\"); // wait here Console.ReadLine(); // shut the silo down after we are done. silo.ShutdownOrleansSilo(); Configuring and Connecting a Client Client for connecting to a cluster of silos and sending requests to grains is configured programmatically via a ClientConfiguration object and a ClientBuilder . ClientConfiguration object can be instantiated and populated directly, load settings from a file, or created with several available helper methods for different deployment environments. For local testing, the easiest way to go is to use ClientConfiguration.LocalhostSilo() helper method. The configuration object is then passed to a new instance of ClientBuilder class. ClientBuilder exposes more methods for configuring additional client features. After that Build method of the ClientBuilder object is called to get an implementation of IClusterClient interface. Finally, we call Connect() method on the returned object to connect to the cluster. You can create an empty console application project targeting .NET Framework 4.6.1 or higher for running a client or reuse the console application project you created for hosting a silo. Add the Microsoft.Orleans.Client NuGet meta-package to the project. PM> Install-Package Microsoft.Orleans.Client Here is an example of how a client can connect to a local silo: var config = ClientConfiguration.LocalhostSilo(); var builder = new ClientBuilder().UseConfiguration(config). var client = builder.Build(); await client.Connect(); Production Configurations The configuration examples we used here are for testing silos and clients running on the same machine as localhost . In production, silos and clients usually run on different servers and are configured with one of the reliable cluster configuration options. You can find more about that in the Configuration Guide and in the description of Cluster Management ."
  },
  "docs/deployment/kubernetes.html": {
    "href": "docs/deployment/kubernetes.html",
    "title": "Kubernetes hosting | Microsoft Orleans Documentation",
    "keywords": "Kubernetes hosting Kubernetes is a popular choice for hosting Orleans applications. Orleans will run in Kubernetes without specific configuration, however it can also take advantage of extra knowledge which the hosting platform can provide. The Microsoft.Orleans.Hosting.Kubernetes package adds integration for hosting an Orleans application in a Kubernetes cluster. The package provides an extension method, ISiloBuilder.UseKubernetesHosting , which performs the following actions: SiloOptions.SiloName is set to the pod name. EndpointOptions.AdvertisedIPAddress is set to the pod IP. EndpointOptions.SiloListeningEndpoint & EndpointOptions.GatewayListeningEndpoint are configured to listen on any address, with the configured SiloPort and GatewayPort . Defaults port values of 11111 and 30000 are used if no values are set explicitly). ClusterOptions.ServiceId is set to the value of the pod label with the name orleans/serviceId . ClusterOptions.ClusterId is set to the value of the pod label with the name orleans/clusterId . Early in the startup process, the silo will probe Kubernetes to find which silos do not have corresponding pods and mark those silos as dead. The same process will occur at runtime for a subset of all silos, in order to remove the load on Kubernetes' API server. By default, 2 silos in the cluster will watch Kubernetes. Note that the Kubernetes hosting package does not use Kubernetes for clustering. For clustering, a separate clustering provider is still needed. For more information on configuring clustering, see the Server configuration documentation. This functionality imposes some requirements on how the service is deployed: Silo names must match pod names. Pods must have an orleans/serviceId and orleans/clusterId label which corresponds to the silo's ServiceId and ClusterId . The above-mentioned method will propagate those labels into the corresponding options in Orleans from environment variables. Pods must have the following environment variables set: POD_NAME , POD_NAMESPACE , POD_IP , ORLEANS_SERVICE_ID , ORLEANS_CLUSTER_ID . The following example shows how to configure these labels and environment variables correctly: apiVersion: apps/v1 kind: Deployment metadata: name: dictionary-app labels: orleans/serviceId: dictionary-app spec: selector: matchLabels: orleans/serviceId: dictionary-app replicas: 3 template: metadata: labels: # This label is used to identify the service to Orleans orleans/serviceId: dictionary-app # This label is used to identify an instance of a cluster to Orleans. # Typically, this will be the same value as the previous label, or any # fixed value. # In cases where you are not using rolling deployments (for example, # blue/green deployments), # this value can allow for distinct clusters which do not communicate # directly with each others, # but which still share the same storage and other resources. orleans/clusterId: dictionary-app spec: containers: - name: main image: my-registry.azurecr.io/my-image imagePullPolicy: Always ports: # Define the ports which Orleans uses - containerPort: 11111 - containerPort: 30000 env: # The Azure Storage connection string for clustering is injected as an # environment variable # It must be created separately using a command such as: # > kubectl create secret generic az-storage-acct ` # --from-file=key=./az-storage-acct.txt - name: STORAGE_CONNECTION_STRING valueFrom: secretKeyRef: name: az-storage-acct key: key # Configure settings to let Orleans know which cluster it belongs to # and which pod it is running in - name: ORLEANS_SERVICE_ID valueFrom: fieldRef: fieldPath: metadata.labels['orleans/serviceId'] - name: ORLEANS_CLUSTER_ID valueFrom: fieldRef: fieldPath: metadata.labels['orleans/clusterId'] - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_IP valueFrom: fieldRef: fieldPath: status.podIP - name: DOTNET_SHUTDOWNTIMEOUTSECONDS value: \"120\" request: # Set resource requests terminationGracePeriodSeconds: 180 imagePullSecrets: - name: my-image-pull-secret minReadySeconds: 60 strategy: rollingUpdate: maxUnavailable: 0 maxSurge: 1 For RBAC-enabled clusters, the Kubernetes service account for the pods may also need to be granted the required access: kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: name: pod-reader rules: - apiGroups: [ \"\" ] resources: [\"pods\"] verbs: [\"get\", \"watch\", \"list\"] --- kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: pod-reader-binding subjects: - kind: ServiceAccount name: default apiGroup: '' roleRef: kind: Role name: pod-reader apiGroup: '' Liveness, Readiness, and Startup Probes Kubernetes is able to probe pods to determine the health of a service. For more information, see Configure Liveness, Readiness and Startup Probes in Kubernetes' documentation. Orleans uses a cluster membership protocol to promptly detect and recover from process or network failures. Each node monitors a subset of other nodes, sending periodic probes. If a node fails to respond to multiple successive probes from multiple other nodes, then it will be forcibly removed from the cluster. Once a failed node learns that is has been removed, it terminates immediately. Kubernetes will restart the terminated process and it will attempt to rejoin the cluster. Kubernetes' probes can help to determine whether a process in a pod is executing and is not stuck in a zombie state. probes do not verify inter-pod connectivity or responsiveness or perform any application-level functionality checks. If a pod fails to respond to a liveness probe, then Kubernetes may eventually terminate that pod and reschedule it. Kubernetes' probes and Orleans' probes are therefore complimentary. The recommended approach is to configure Liveness Probes in Kubernetes which perform a simple local-only check that the application is performing as intended. These probes serve to terminate the process in the event that there is a total freeze, for example due to a runtime fault or another unlikely event. Resource quotas Kubernetes works in conjunction with the operating system to implement resource quotas . This allows CPU and memory reservations and/or limits to be enforced. For a primary application which is serving interactive load, we recommend not implementing restrictive limits unless necessary. It is important to note that requests and limits are substantially different in their meaning and where they are implemented. Before setting requests or limits, take the time to gain a detailed understanding of how they are implemented and enforced. For example, memory may not be measured uniformly between Kubernetes, the Linux kernel, and your monitoring system. CPU quotas may not be enforced in the way that you expect."
  },
  "docs/deployment/multi-cluster_support/GlobalSingleInstance.html": {
    "href": "docs/deployment/multi-cluster_support/GlobalSingleInstance.html",
    "title": "Global-Single-Instance Grains | Microsoft Orleans Documentation",
    "keywords": "Grain Coordination Attributes Developers can indicate when and how clusters should coordinate their grain directories with respect to a particular grain class. The [GlobalSingleInstance] attribute means we want the same behavior as when running Orleans in a single global cluster: that is, route all calls to a single activation of the grain. Conversely, the [OneInstancePerCluster] attribute indicates that each cluster can have its own independent activation. This is appropriate if communication between clusters is undesired. The attributes are placed on grain implementations. For example: using Orleans.MultiCluster; [GlobalSingleInstance] public class MyGlobalGrain : Orleans.Grain, IMyGrain { ... } [OneInstancePerCluster] public class MyLocalGrain : Orleans.Grain, IMyGrain { ... } If a grain class does not specify either one of those attributes, it defaults to [OneInstancePerCluster] , or [GlobalSingleInstance] if the configuration parameter UseGlobalSingleInstanceByDefault is set to true. Protocol for Global-Single-Instance Grains When a global-single-instance (GSI) grain is accessed, and no activation is known to exist, a special GSI activation protocol is executed before activating a new instance. Specifically, a request is sent to all other clusters in the current multi-cluster configuration to check if they already have an activation for this grain. If all responses are negative, a new activation is created in this cluster. Otherwise, the remote activation is used (and a reference to it is cached in the local directory). Protocol for One-Instance-Per-Cluster Grains There is no inter-cluster communication for One-Instance-Per-Cluster grains. They simply use the standard Orleans mechanism independently within each cluster. Inside the Orleans framework itself, the following grain classes are marked with the [OneInstancePerCluster] attribute: ManagementGrain , GrainBasedMembershipTable , and GrainBasedReminderTable . Doubtful Activations If the GSI protocol does not receive conclusive responses from all clusters after 3 retries (or whatever number is specified by the configuration parameter GlobalSingleInstanceNumberRetries ), it creates a new local \"doubtful\" activation optimistically, favoring availability over consistency. Doubtful activations may be duplicates (because some remote cluster that did not respond during the GSI protocol activation may nevertheless have an activation of this grain). Therefore, periodically every 30 seconds (or whatever interval is specified by the configuration parameter GlobalSingleInstanceRetryInterval ) the GSI protocol is run again for all doubtful activations. This ensures that once communication between clusters is restored, duplicate activations can be detected and removed."
  },
  "docs/deployment/multi-cluster_support/GossipChannels.html": {
    "href": "docs/deployment/multi-cluster_support/GossipChannels.html",
    "title": "Multi-Cluster Communication | Microsoft Orleans Documentation",
    "keywords": "Multi-Cluster Communication The network must be configured in such a way that any Orleans silo can connect to any other Orleans silo via TCP/IP, regardless of where in the world it is located. Exactly how this is achieved is outside of the scope of Orleans, as it depends on how and where silos are deployed. For example, on Windows Azure, we can use VNETs to connect muliple deployments within a region, and gateways to connect VNETs across different regions. Cluster Id Each cluster has its own unique cluster id. The cluster id must be specified in the global configuration. Cluster ids may not be empty, nor may they contain commas. Also, if using Azure Table Storage, cluster ids may not contain the characters forbidden for row keys (/, , #, ?). We recommend using very short strings for the cluster ids, because cluster ids are transmitted frequently and may be stored in storage by some log-view providers. Cluster Gateways Each cluster automatically designates a subset of its active silos to serve as cluster gateways . Cluster gateways directly advertise their IP addresses to other clusters, and can thus serve as \"points of first contact\". By default, at most 10 silos (or whatever number is configured as MaxMultiClusterGateways ) are designated as cluster gateways. Communication between silos in different clusters does not always pass through a gateway. Once a silo has learned and cached the location of a grain activation (no matter in what cluster), it sends messages to that silo directly, even if the silo is not a cluster gateway. Gossip Gossip is a mechanism for clusters to share configuration and status information. As the name suggests, gossip is decentralized and bidirectional: each silo communicates directly with other silos, both in the same cluster and in other clusters, to exchange information in both directions. Content . Gossip contains some or all of the following information: The current time-stamped multi-cluster configuration . A dictionary that contains information about cluster gateways. The key is the silo address, and the value contains (1) a timestamp, (2) the cluster id, and (3) a status, which is either active or inactive. Fast & Slow Propagation . When a gateway changes its status, or when an operator injects a new configuration, this gossip information is immediately sent to all silos, clusters, and gossip channels. This happens fast, but is not reliable. Should the message be lost due to any reasons (e.g. races, broken sockets, silo failures), our periodic background gossip ensures that the information eventually spreads, albeit more slowly. All information is eventually propagated everywhere, and is highly resilient to occasional message loss and failures. All gossip data is timestamped, which ensures that newer information replaces older information regardless of the relative timing of messages. For example, newer multi-cluster configurations replace older ones, and newer information about a gateway replaces older information about that gateway. For more details on the representation of gossip data, see the MultiClusterData class. It has a Merge method that combines gossip data, resolving conflicts using timestamps. Gossip Channels When a silo is first started, or when it is restarted after a failure, it needs to have a way to bootstrap the gossip . This is the role of the gossip channel , which can be configured in the Silo Configuration . On startup, a silo fetches all the information from the gossip channels. After startup, a silo keeps gossiping periodically, every 30 seconds or whatever is configured as BackgroundGossipInterval . Each time it synchronizes its gossip information with a partner randomly selected from all cluster gateways and gossip channels. Notes: Though not strictly required, we recommend to always configure at least two gossip channels, in distinct regions, for better availability. Latency of communication with gossip channels is not critical. Multiple different services can use the same gossip channel without interference, as long as the ServiceId Guid (as specified by their respective configuration) is distinct. There is no strict requirement that all silos use the same gossip channels, as long as the channels are sufficient to let a silo initially connect with the \"gossiping community\" when it starts up. But if a gossip channel is not part of a silo's configuration, and that silo is a gateway, it does not push its status updates to the channel (fast propagation), so it may take longer before those reach the channel via periodic background gossip (slow propagation). Azure-Table-Based Gossip Channel We have already implemented a gossip channel based on Azure Tables. The configuration specifies standard connection strings used for Azure accounts. For example, a configuration could specify two gossip channels with separate Azure storage accounts usa and europe as follows: var silo = new SiloHostBuilder() [...] .Configure<MultiClusterOptions>(options => { [...] options.GossipChannels.Add(\"AzureTable\", \"DefaultEndpointsProtocol=https;AccountName=usa;AccountKey=...\"); options.GossipChannels.Add(\"AzureTable\", \"DefaultEndpointsProtocol=https;AccountName=europe;AccountKey=...\") [...] }) [...] Multiple different services can use the same gossip channel without interference, as long as the ServiceId guid specified by their respective configuration is distinct. Other Gossip Channel Implementations We are working on other gossip channel providers, similar to how membership and reminders are packaged for many different storage back-ends."
  },
  "docs/deployment/multi-cluster_support/MultiClusterConfiguration.html": {
    "href": "docs/deployment/multi-cluster_support/MultiClusterConfiguration.html",
    "title": "Multi-Cluster Configuration | Microsoft Orleans Documentation",
    "keywords": "Multi-Cluster Configuration The multi-cluster configuration determines which clusters are currently part of the multi-cluster. It does not change automatically, but is controlled by the operator. Thus, it is quite different from the membership mechanism used within a cluster, which automatically determines the set of silos that are part of the cluster. We use the following terminology for the clusters in a service: A cluster is active if it has at least one active silo, and inactive otherwise A cluster is joined if it is part of the current multi-cluster configuration, and non-joined otherwise Being active/inactive is independent from being joined/non-joined: all four combinations are possible. All the clusters for a particular service are connected by a gossip network . The gossip network propagates configuration and status information. Injecting a configuration An operator issues configuration changes by injecting them into the multi-cluster network. The configurations can be injected into any cluster, and spread from there to all active clusters. Each new configuration consists of a list of cluster ids that form the multi-cluster. It also has a UTC timestamp that is used to track its propagation through the gossip network. Initially, the multi-cluster configuration is null, which means the multi-cluster list is empty (contains no clusters). Thus, the operator must initially inject a multi-cluster configuration. Once injected, this configuration persists in all connected silos (while running) and in all specified gossip channels (if those channels are persistent). We pose some restrictions on the injection of new configurations that an operator must follow: Each new configuration may add a number of clusters, or remove a number of clusters (but not both at the same time). An operator should not issue a new configuration while a previous configuration change is still being processed. These restrictions ensure that protocols such as the single-instance-protocol can correctly maintain mutual exclusion of activations even under configuration changes. Via Management Grain Multi-cluster configurations can be injected on any node in any cluster, using the Orleans Management Grain. For example, to inject a multi-cluster configuration that consists of the three clusters { us1, eu1, us2 }, we can pass a string enumerable to the management grain: var clusterlist = \"us1,eu1,us2\".Split(','); var mgtGrain = client.GetGrain<IManagementGrain>(0); mgtGrain.InjectMultiClusterConfiguration(clusterlist, \"my comment here\")); The first argument to InjectMultiClusterConfiguration is an enumerable of cluster ids, which is going to define the new multi-cluster configuration. The second argument is an (optional) comment string that can be used to tag configurations with arbitrary information, such as who injected them why. There is an optional third argument, a boolean called checkForLaggingSilosFirst , which defaults to true. It means that the system performs a best-effort check to see if there are any silos anywhere that have not caught up to the current configuration yet, and rejects the change if it finds such a silo. This helps to detect violations of the restriction that only one configuration change should be pending at a time (though it cannot guarantee it under all circumstances). Via Default Configuration In situations where the multi-cluster configuration is known in advance and the deployment is fresh every time (e.g. for testing), we may want to supply a default configuration. The global configuration supports an optional attribute DefaultMultiCluster which takes a comma-separated list of cluster ids: var silo = new SiloHostBuilder() [...] .Configure<MultiClusterOptions>(options => { [...] options.DefaultMultiCluster = new[] { \"us1\", \"eu1\", \"us2\" }; [...] }) [...] After a silo is started with this setting, it checks to see if the current multi-cluster configuration is null, and if so, injects the given configuration with the current UTC timestamp. WARNING. Persistent multi-cluster gossip channels (e.g. based on AzureTable) retain the last injected configuration unless they are deleted explicitly. In that case, specifying a DefaultMulticluster has no effect when re-deploying a cluster because the configuration stored in the gossip channels is not null.> Via Gossip Channel An operator can also inject the configuration directly into the gossip channel. Changes in the channel are picked up and propagated automatically by the periodic background gossip, though possibly very slowly (using the management grain is much faster). A rough estimate on the propagation time is 30 seconds (or whatever gossip interval is specified in the global configuration) times the binary logarithm of the total number of silos in all clusters. But since the gossip pairs are selected randomly, it can be both much quicker or much slower. If using the Azure Table-Based Gossip Channel, operators can inject a new configuration simply by editing the configuration record in the OrleansGossipTable , e.g. using some tool for editing data in Azure tables. The configuration record has the following format: Name Type Value PartitionKey String the ServiceId RowKey String \"CONFIG\" Clusters String comma-separated list of cluster IDs, e.g. \"us1,eu1,us2\" Comment String optional comment GossipTimestamp DateTime UTC timestamp for the configuration NOTE . When editing this record in storage, the GossipTimestamp must also be set to a newer value than it has currently (otherwise the change is ignored). The most convenient and recommended way to do this is to delete the GossipTimestamp field - our gossip channel implementation then automatically replaces it with a correct, current Timestamp (it uses the Azure Table Timestamp). Cluster Addition/Removal Procedures Adding or removing a cluster from the multi-cluster often needs to be coordinated within some larger context. We recommend to always follow the procedures described below when adding/removing clusters from the multi-cluster. Procedure for adding a cluster Start a new Orleans cluster and wait till all silos are up and running. Inject a configuration that contains the new cluster. Start routing user requests to the new cluster. Procedure for removing a cluster Stop routing new user requests to the cluster. Inject a configuration that no longer contains the cluster. Stop all silos of the cluster. Once a cluster has been removed in this way, it can be re-added by following the procedure for adding a new cluster. Activity on Non-Joined Clusters There can be brief, temporary periods of time where a cluster is both active and non-joined: A freshly started cluster may start executing code before it is in the multicluster configuration (between steps 1 and 2 of the procedure for adding a cluster) A cluster that is being decommissioned may still execute code before the silos are shut down (between steps 2 and 3 of the procedure for removing a cluster). During those intermediate situations, the following are possible: For global-single-instance grains: A grain may have a duplicate activation on a non-joined cluster. For versioned grains: activations on non-joined clusters do not receive notifications when the grain state changes."
  },
  "docs/deployment/multi-cluster_support/Overview.html": {
    "href": "docs/deployment/multi-cluster_support/Overview.html",
    "title": "Multi-Cluster Support | Microsoft Orleans Documentation",
    "keywords": "Multi-Cluster Support Orleans v.1.3.0 added support for federating several Orleans clusters into a loosely connected multi-cluster that acts like a single service. Multi-clusters facilitate geo-distribution of a service, that is, make it easier to run an Orleans application in multiple data-centers around the world. Also, a multi-cluster can be run within a single datacenter to get better failure and performance isolation. All mechanisms are designed with particular attention to (1) minimize communication between clusters, and (2) let each cluster run autonomously even if other clusters fail or become unreachable. Configuration and Operation Below we document how to configure and operate a multi-cluster. Communication . Clusters communicate via the same silo-to-silo connections that are used within a cluster. To exchange status and configuration information, Clusters use a gossip mechanism and gossip channel implementations. Silo Configuration . Silos need to be configured so they know which cluster they belong to (each cluster is identified by a unique string). Also, each silo needs to be configured with connection strings that allow them to connect to one or more gossip channels on startup. Multi-Cluster Configuration Injection . At runtime, the service operator can specify and/or change the multi-cluster configuration , which contains a list of cluster ids, to specify which clusters are part of the current multi-cluster. This is done by calling the management grain in any one of the clusters. Multi-Cluster Grains Below we document how to use multi-cluster functionality at the application level. Global-Single-Instance Grains . Developers can indicate when and how clusters should coordinate their grain directories with respect to a particular grain class. The [GlobalSingleInstance] attribute means we want the same behavior as as when running Orleans in a single global cluster: that is, route all calls to a single activation of the grain. Conversely, the [OneInstancePerCluster] attribute indicates that each cluster can have its own independent activation. This is appropriate if communication between clusters is undesired. Log-View Grains (not in v.1.3.0) . A special type of grain that uses a new API, similar to event sourcing, for synchronizing or persisting grain state. It can be used to automatically and efficiently synchronize the state of a grain between clusters and with storage. Because its synchronization algorithms are safe to use with reentrant grains, and are optimized to use batching and replication, it can perform better than standard grains when a grain is frequently accessed in multiple clusters, and/or when it is written to storage frequently. Support for log-view grains is not part of the master branch yet. We have a prerelease including samples and a bit of documentation in the geo-orleans branch . It is currently being evaluated in production by an early adopter."
  },
  "docs/deployment/multi-cluster_support/SiloConfiguration.html": {
    "href": "docs/deployment/multi-cluster_support/SiloConfiguration.html",
    "title": "Multi-Cluster Silo Configuration | Microsoft Orleans Documentation",
    "keywords": "Orleans Silo Configuration To get a quick overview, we show all relevant configuration parameters (including optional ones) in XML syntax below: <?xml version=\"1.0\" encoding=\"utf-8\"?> <OrleansConfiguration xmlns=\"urn:orleans\"> <Globals> <MultiClusterNetwork ClusterId=\"clusterid\" DefaultMultiCluster=\"uswest,europewest,useast\" BackgroundGossipInterval=\"30s\" UseGlobalSingleInstanceByDefault=\"false\" GlobalSingleInstanceRetryInterval=\"30s\" GlobalSingleInstanceNumberRetries=\"3\" MaxMultiClusterGateways=\"10\"> <GossipChannel Type=\"...\" ConnectionString=\"...\"/> <GossipChannel Type=\"...\" ConnectionString=\"...\"/> </MultiClusterNetwork> <SystemStore ... ServiceId=\"some-guid\" .../> </Globals> </OrleansConfiguration> var silo = new SiloHostBuilder() [...] .Configure<ClusterInfo>(options => { options.ClusterId = \"us3\"; options.ServiceId = \"myawesomeservice\"; }) .Configure<MultiClusterOptions>(options => { options.HasMultiClusterNetwork = true; options.DefaultMultiCluster = new[] { \"us1\", \"eu1\", \"us2\" }; options.BackgroundGossipInterval = TimeSpan.FromSeconds(30); options.UseGlobalSingleInstanceByDefault = false; options.GlobalSingleInstanceRetryInterval = TimeSpan.FromSeconds(30); options.GlobalSingleInstanceNumberRetries = 3; options.MaxMultiClusterGateways = 10; options.GossipChannels.Add(\"AzureTable\", \"DefaultEndpointsProtocol=https;AccountName=usa;AccountKey=...\"); options.GossipChannels.Add(\"AzureTable\", \"DefaultEndpointsProtocol=https;AccountName=europe;AccountKey=...\") [...] }) [...] As usual, all configuration settings can also be read and written programmatically, via the respective members of the GlobalConfiguration class. The Service Id is an arbitrary ID for identifying this service. It must be the same for all clusters and all silos. The MultiClusterNetwork section is optional - if not present, all multi-cluster support is disabled for this silo. The required parameters ClusterId and GossipChannel are explained in the section on Multi-Cluster Communication . The optional parameters MaxMultiClusterGateways and BackgroundGossipInterval are explained in the section on Multi-Cluster Communication . The optional parameter DefaultMultiCluster is explained in the section on Multi-Cluster Configuration . The optional parameters UseGlobalSingleInstanceByDefault , GlobalSingleInstanceRetryInterval and GlobalSingleInstanceNumberRetries are explained in the section on Global-Single-Instance Grains . Orleans Client Configuration No extra configuration is required for Orleans client. The same client may not connect to silos in different clusters (the silo refuses the connection in that situation)."
  },
  "docs/deployment/service_fabric.html": {
    "href": "docs/deployment/service_fabric.html",
    "title": "Service Fabric Hosting | Microsoft Orleans Documentation",
    "keywords": "Service Fabric Hosting Orleans can be hosted on Service Fabric using the Microsoft.Orleans.Hosting.ServiceFabric package. Silos should be hosted as unpartitioned, stateless services since Orleans manages distribution of grains itself using fine-grained, dynamic distribution. Other hosting options (partitioned, stateful) are currently untested and unsupported. A sample which demonstrates hosting on Service Fabric is available at Samples/2.0/ServiceFabric . Hosting support is available in the Microsoft.Orleans.Hosting.ServiceFabric package. It allows an Orleans Silo to run as a Service Fabric ICommunicationListener . The Silo lifecycle follows the typical communication listener lifecycle: it is initialized via the ICommunicationListener.OpenAsync method and is gracefully terminated via the ICommunicationListener.CloseAsync method or abruptly terminated via the ICommunicationListener.Abort method. Official clustering support is available from various packages including: Microsoft.Orleans.Clustering.AzureStorage Microsoft.Orleans.Clustering.AdoNet Microsoft.Orleans.Clustering.DynamoDB There are also several third-party packages available for other services such as CosmosDB, Kubernetes, Redis and Aerospike. More information about cluster management can be found here . This example makes use of the Microsoft.Orleans.Clustering.AzureStorage package to utilize Azure Storage. OrleansCommunicationListener provides the ICommunicationListener implementation. The recommended approach is to create the communication listener using OrleansServiceListener.CreateStateless(Action<StatelessServiceContext, ISiloHostBuilder> configure) in the Orleans.Hosting.ServiceFabric namespace. Each time the communication listener is opened, the configure delegate passed to CreateStateless is invoked to configure the new Silo. Example: Configuring Service Fabric hosting The following example demonstrates a Service Fabric StatelessService class which hosts an Orleans silo. The full sample can be found in the Samples/2.0/ServiceFabric directory of the Orleans repository. /// <summary> /// An instance of this class is created for each service instance by the Service Fabric runtime. /// </summary> internal sealed class StatelessCalculatorService : StatelessService { public StatelessCalculatorService(StatelessServiceContext context) : base(context) { } /// <summary> /// Optional override to create listeners (e.g., TCP, HTTP) for this service replica to handle /// client or user requests. /// </summary> /// <returns>A collection of listeners.</returns> protected override IEnumerable<ServiceInstanceListener> CreateServiceInstanceListeners() { // Listeners can be opened and closed multiple times over the lifetime of a service instance. // A new Orleans silo will be both created and initialized each time the listener is opened // and will be shutdown when the listener is closed. var listener = OrleansServiceListener.CreateStateless( (fabricServiceContext, builder) => { builder.Configure<ClusterOptions>(options => { // The service id is unique for the entire service over its lifetime. This is // used to identify persistent state such as reminders and grain state. options.ServiceId = fabricServiceContext.ServiceName.ToString(); // The cluster id identifies a deployed cluster. Since Service Fabric uses rolling // upgrades, the cluster id can be kept constant. This is used to identify which // silos belong to a particular cluster. options.ClusterId = \"development\"; }); // Configure clustering. Other clustering providers are available, but for the purpose // of this sample we will use Azure Storage. // TODO: Pick a clustering provider and configure it here. builder.UseAzureStorageClustering( options => options.ConnectionString = \"UseDevelopmentStorage=true\"); // Optional: configure logging. builder.ConfigureLogging(logging => logging.AddDebug()); builder.AddStartupTask<StartupTask>(); // Service Fabric manages port allocations, so update the configuration using those // ports. // Gather configuration from Service Fabric. var activation = fabricServiceContext.CodePackageActivationContext; var endpoints = activation.GetEndpoints(); // These endpoint names correspond to TCP endpoints specified in ServiceManifest.xml var siloEndpoint = endpoints[\"OrleansSiloEndpoint\"]; var gatewayEndpoint = endpoints[\"OrleansProxyEndpoint\"]; var hostname = fabricServiceContext.NodeContext.IPAddressOrFQDN; builder.ConfigureEndpoints(hostname, siloEndpoint.Port, gatewayEndpoint.Port); // Add your application assemblies. builder.ConfigureApplicationParts(parts => { parts.AddApplicationPart(typeof(CalculatorGrain).Assembly).WithReferences(); // Alternative: add all loadable assemblies in the current base path // (see AppDomain.BaseDirectory). parts.AddFromApplicationBaseDirectory(); }); }); return new[] { listener }; } /// <summary> /// This is the main entry point for your service instance. /// </summary> /// <param name=\"cancellationToken\"> /// Canceled when Service Fabric needs to shut down this service instance. /// </param> protected override async Task RunAsync(CancellationToken cancellationToken) { while (true) { cancellationToken.ThrowIfCancellationRequested(); await Task.Delay(TimeSpan.FromSeconds(10), cancellationToken); } } }"
  },
  "docs/deployment/troubleshooting_azure_cloud_services_deployments.html": {
    "href": "docs/deployment/troubleshooting_azure_cloud_services_deployments.html",
    "title": "Troubleshooting Deployments | Microsoft Orleans Documentation",
    "keywords": "Troubleshooting Deployments This page gives some general guidelines for troubleshooting any issues that occur while deploying to Azure Cloud Services. These are very common issues to watch out for. Be sure to check the logs for more information. Getting a SiloUnavailableException First check to make sure that you are actually starting the silos before attempting to initialize the client. Sometimes the silos take a long time to start so it can be beneficial to try to initialize the client multiple times. If it still throws an exception, then there might be another issue with the silos. Check the silo configuration and make sure that the silos are starting up properly. Common Connection String Issues Using the local connection string when deploying to Azure – the website will fail to connect Using different connection strings for the silos and the front end (web and worker roles) – the website will fail to initialize the client because it cannot connect to the silos The connection string configuration can be checked in the Azure Portal. The logs may not display properly if the connection strings are not set up correctly. Modifying the Configuration Files Improperly Make sure that the proper endpoints are configured in the ServiceDefinition.csdef file or else the deployment will not work. It will give errors saying that it cannot get the endpoint information. Missing Logs Make sure that the connection strings are set up properly. It is likely that the Web.config file in the web role or the app.config file in the worker role were modified improperly. Incorrect versions in these files can cause issues with the deployment. Be careful when dealing with updates. Version Issues Make sure that the same version of Orleans is used in every project in the solution. Not doing this can lead to the worker role recycling. Check the logs for more information. Visual Studio provides some silo startup error messages in the deployment history. Role Keeps Recycling Check that all the appropriate Orleans assemblies are in the solution and have Copy Local set to True. Check the logs to see if there is an unhandled exception while initializing. Make sure that the connection strings are correct. Check the Azure Cloud Services troubleshooting pages for more information. How to Check Logs Use the cloud explorer in Visual Studio to navigate to the appropriate storage table or blob in the storage account. The WADLogsTable is a good starting point for looking at the logs. You might only be logging errors. If you want informational logs as well, you will need to modify the configuration to set the logging severity level. Programmatic configuration: When creating a ClusterConfiguration object, set config.Defaults.DefaultTraceLevel = Severity.Info . When creating a ClientConfiguration object, set config.DefaultTraceLevel = Severity.Info . Declarative configuration: Add <Tracing DefaultTraceLevel=\"Info\" /> to the OrleansConfiguration.xml and/or the ClientConfiguration.xml files. In the diagnostics.wadcfgx file for the web and worker roles, make sure to set the scheduledTransferLogLevelFilter attribute in the Logs element to Information , as this is an additional layer of trace filtering that defines which traces are sent to the WADLogsTable in Azure Storage. You can find more information about this in the Configuration Guide. Compatibility with ASP.NET The razor view engine included in ASP.NET uses the same code generation assemblies as Orleans ( Microsoft.CodeAnalysis and Microsoft.CodeAnalysis.CSharp ). This can present a version compatibility problem at runtime. To resolve this, try upgrading Microsoft.CodeDom.Providers.DotNetCompilerPlatform (this is the NuGet package ASP.NET uses to include the above assemblies) to the latest version, and setting binding redirects like this: <dependentAssembly> <assemblyIdentity name=\"Microsoft.CodeAnalysis.CSharp\" publicKeyToken=\"31bf3856ad364e35\" culture=\"neutral\" /> <bindingRedirect oldVersion=\"0.0.0.0-2.0.0.0\" newVersion=\"1.3.1.0\" /> </dependentAssembly> <dependentAssembly> <assemblyIdentity name=\"Microsoft.CodeAnalysis\" publicKeyToken=\"31bf3856ad364e35\" culture=\"neutral\" /> <bindingRedirect oldVersion=\"0.0.0.0-2.0.0.0\" newVersion=\"1.3.1.0\" /> </dependentAssembly>"
  },
  "docs/deployment/troubleshooting_deployments.html": {
    "href": "docs/deployment/troubleshooting_deployments.html",
    "title": "Troubleshooting Deployments | Microsoft Orleans Documentation",
    "keywords": "Troubleshooting Deployments This page gives some general guidelines for troubleshooting any issues that occur while deploying to Azure Cloud Services. These are very common issues to watch out for. Be sure to check the logs for more information. Getting a SiloUnavailableException First, check to make sure that you are actually starting the silos before attempting to initialize the client. Sometimes the silos take a long time to start so it can be beneficial to try to initialize the client multiple times. If it still throws an exception, then there might be another issue with the silos. Check the silo configuration and make sure that the silos are starting up properly. Common Connection String Issues Using the local connection string when deploying to Azure – the website will fail to connect Using different connection strings for the silos and the front end (web and worker roles) – the website will fail to initialize the client because it cannot connect to the silos The connection string configuration can be checked in the Azure Portal. The logs may not display properly if the connection strings are not set up correctly. Modifying the Configuration Files Improperly Make sure that the proper endpoints are configured in the ServiceDefinition.csdef file or else the deployment will not work. It will give errors saying that it cannot get the endpoint information. Missing Logs Make sure that the connection strings are set up properly. It is likely that the Web.config file in the web role or the app.config file in the worker role were modified improperly. Incorrect versions in these files can cause issues with the deployment. Be careful when dealing with updates. Version Issues Make sure that the same version of Orleans is used in every project in the solution. Not doing this can lead to the worker role recycling. Check the logs for more information. Visual Studio provides some silo startup error messages in the deployment history. Role Keeps Recycling Check that all the appropriate Orleans assemblies are in the solution and have Copy Local set to True . Check the logs to see if there is an unhandled exception while initializing. Make sure that the connection strings are correct. Check the Azure Cloud Services troubleshooting pages for more information. How to Check Logs Use the cloud explorer in Visual Studio to navigate to the appropriate storage table or blob in the storage account. The WADLogsTable is a good starting point for looking at the logs. You might only be logging errors. If you want informational logs as well, you will need to modify the configuration to set the logging severity level. Programmatic configuration: When creating a ClusterConfiguration object, set config.Defaults.DefaultTraceLevel = Severity.Info . When creating a ClientConfiguration object, set config.DefaultTraceLevel = Severity.Info . Declarative configuration: Add <Tracing DefaultTraceLevel=\"Info\" /> to the OrleansConfiguration.xml and/or the ClientConfiguration.xml files. In the diagnostics.wadcfgx file for the web and worker roles, make sure to set the scheduledTransferLogLevelFilter attribute in the Logs element to Information , as this is an additional layer of trace filtering that defines which traces are sent to the WADLogsTable in Azure Storage. You can find more information about this in the Configuration Guide . Compatibility with ASP.NET The razor view engine included in ASP.NET uses the same code generation assemblies as Orleans ( Microsoft.CodeAnalysis and Microsoft.CodeAnalysis.CSharp ). This can present a version compatibility problem at runtime. To resolve this, try upgrading Microsoft.CodeDom.Providers.DotNetCompilerPlatform (this is the NuGet package ASP.NET uses to include the above assemblies) to the latest version, and setting binding redirects like this: <dependentAssembly> <assemblyIdentity name=\"Microsoft.CodeAnalysis.CSharp\" publicKeyToken=\"31bf3856ad364e35\" culture=\"neutral\" /> <bindingRedirect oldVersion=\"0.0.0.0-2.0.0.0\" newVersion=\"1.3.1.0\" /> </dependentAssembly> <dependentAssembly> <assemblyIdentity name=\"Microsoft.CodeAnalysis\" publicKeyToken=\"31bf3856ad364e35\" culture=\"neutral\" /> <bindingRedirect oldVersion=\"0.0.0.0-2.0.0.0\" newVersion=\"1.3.1.0\" /> </dependentAssembly>"
  },
  "docs/grains/cancellation_tokens.html": {
    "href": "docs/grains/cancellation_tokens.html",
    "title": "Grain cancellation tokens | Microsoft Orleans Documentation",
    "keywords": "Grain cancellation tokens orleans运行时提供了一种称为grain cancellation token的机制，使开发人员能够取消正在执行的grain操作。 说明 GrainCancellationToken 是标准的包装 .NET System.Threading.CancellationToken ，它启用线程、线程池工作项或任务对象之间的协作取消，并且可以作为grain方法参数传递。 一个 GrainCancellationTokenSource 是通过其token属性提供取消令牌并通过调用 取消 方法。 用法 实例化CancellationTokenSource对象，该对象管理并向各个取消令牌发送取消通知。 var tcs = new GrainCancellationTokenSource(); 将GrainCancellationTokenSource.Token属性返回的令牌传递给侦听取消的每个Grain方法。 var waitTask = grain.LongIoWork(tcs.Token, TimeSpan.FromSeconds(10)); 可取消的Grains操作需要处理底层 GrainCancellationToken 属性的 CancellationToken 就像在其他.NET代码中一样。 public async Task LongIoWork(GrainCancellationToken tc, TimeSpan delay) { while(!tc.CancellationToken.IsCancellationRequested) { await IoOperation(tc.CancellationToken); } } 调用给 GrainCancellationTokenSource.Cancel 方法启动取消。 await tcs.Cancel(); 当使用完 GrainCancellationTokenSource 对象调用 Dispose 方法。 tcs.Dispose(); 重要注意事项： 这个 GrainCancellationTokenSource.Cancel 方法返回 Task ，并且为了确保取消，必须在短暂通信失败的情况下重试取消调用。 在基础中注册的回调 System.Threading.CancellationToken 在注册它们的grain 激活中受单线程执行保证的约束。 每个 GrainCancellationToken 可以通过多个方法调用传递。"
  },
  "docs/grains/code_generation.html": {
    "href": "docs/grains/code_generation.html",
    "title": "Code Generation | Microsoft Orleans Documentation",
    "keywords": "Code Generation orleans运行时使用生成的代码，以确保跨集群使用的类型的正确序列化，并生成样板文件，该样板文件抽象出方法传送、异常传播和其他内部运行时概念的实现细节。 启用代码生成 代码生成可以在项目生成或应用程序初始化时执行。 在构建期间 执行代码生成的首选方法是在生成时。 可以使用以下包之一启用生成时代码生成： Microsoft.Orleans.OrleansCodeGenerator.Build 是的。 使用Roslyn生成代码并使用.NET反射进行分析的包。 Microsoft.Orleans.CodeGenerator.MSBuild 是的。 一个新的代码生成包，它利用roslyn进行代码生成和代码分析。 它不加载应用程序二进制文件，因此避免了由相互冲突的依赖项版本和不同的目标框架引起的问题。 新的代码生成器还改进了对增量构建的支持，这将缩短构建时间。 这些包中的一个应该安装到所有包含Grain、Grain接口、自定义序列化程序或在Grain之间发送的类型的项目中。 安装包会将目标插入到项目中，该项目将在生成时生成代码。 两个包( Microsoft.Orleans.CodeGenerator.MSBuild 和 Microsoft.Orleans.OrleansCodeGenerator.Build )只支持C项目。 使用 Microsoft.Orleans.Orleanscodegenerator 下面描述的包，或者通过创建一个c项目，该项目可以作为用其他语言编写的程序集生成的代码的目标。 通过指定 奥尔兰斯科德格勒 在目标项目的 项目文件 文件。 例如， <orleanscodegenloglevel>跟踪</orleanscodegenloglevel> 是的。 初始化期间 通过安装 Microsoft.Orleans.Orleanscodegenerator 打包并使用 IApplicationPartManager.WithCodeGeneration 扩展方法。 builder.ConfigureApplicationParts( parts => parts .AddApplicationPart(typeof(IRuntimeCodeGenGrain).Assembly) .WithCodeGeneration()); 在上面的例子中， builder 可能是其中之一的实例 IsiloHostBuilder 或 IClientBuilder 是的。 可选的 ILoggerfactory 实例可以传递到 WithCodeGeneration 要在代码生成期间启用日志记录，例如： ILoggerFactory codeGenLoggerFactory = new LoggerFactory(); codeGenLoggerFactory.AddProvider(new ConsoleLoggerProvider()); builder.ConfigureApplicationParts( parts => parts .AddApplicationPart(typeof(IRuntimeCodeGenGrain).Assembly) .WithCodeGeneration(codeGenLoggerFactory)); 影响代码生成 为特定类型生成代码 自动为grain接口、grain类、grain状态和在grain方法中作为参数传递的类型生成代码。 如果类型不符合此条件，则可以使用以下方法进一步指导代码生成。 添加 [Serializable] 指示代码生成器为类型生成序列化程序。 添加 [assembly: GenerateSerializer(Type)] 指示代码生成器将该类型视为可序列化的，并且如果无法为该类型生成序列化程序(例如，因为该类型不可访问)，则将导致错误。 如果启用代码生成，此错误将停止生成。 此属性还允许从另一个程序集为特定类型生成代码。 [assembly：knownype(type)] 还指示代码生成器包含特定类型(可能来自引用的程序集)，但如果该类型不可访问，则不会导致异常。 为所有子类型生成序列化程序 添加 [KnownBaseType] 指示代码生成器为继承/实现该类型的所有类型生成序列化代码。 为其他程序集中的所有类型生成代码 在某些情况下，生成的代码在生成时不能包含在特定程序集中。 例如，这可以包括不引用Orleans的共享库、用C以外的语言编写的程序集以及开发人员没有源代码的程序集。 在这些情况下，为这些程序集生成的代码可以放在一个单独的程序集中，该程序集在初始化期间被引用。 要为程序集启用此功能，请执行以下操作： 创建一个C项目。 安装 Microsoft.Orleans.CodeGenerator.MSBuild 或者 Microsoft.Orleans.OrleansCodeGenerator.Build 包裹。 添加对目标程序集的引用。 添加 [assembly: knownAssembly(\"otherAssembly\")] 在C文件的顶层。 这个 KnownAssemblyAttribute 属性指示代码生成器检查指定的程序集并为其中的类型生成代码。 该属性可以在项目中多次使用。 然后，必须在初始化期间将生成的程序集添加到客户端/silos： builder.ConfigureApplicationParts( parts => parts.AddApplicationPart(\"CodeGenAssembly\")); 在上面的例子中， builder 可能是其中之一的实例 IsiloHostBuilder 或 IClientBuilder 是的。 KnownAssemblyAttribute 具有可选属性， TreatTypesAsSerializable ，可以设置为 true 指示代码生成器将程序集中的所有类型标记为可序列化。"
  },
  "docs/grains/event_sourcing/event_sourcing_configuration.html": {
    "href": "docs/grains/event_sourcing/event_sourcing_configuration.html",
    "title": "Configuration | Microsoft Orleans Documentation",
    "keywords": "Configuration 配置项目引用 grains接口 和以前一样，接口只依赖于 Microsoft.Orleans.Core 包，因为grain接口独立于实现。 Grains实现 日志需要从 JournaledGrain<S,E> 或 JournaledGrain<S> ，定义见 Microsoft.Orleans.EventSourcing 包。 日志一致性提供程序 我们目前包括三个日志一致性提供程序(用于状态存储、日志存储和自定义存储)。 所有这三个都包含在 Microsoft.Orleans.EventSourcing 包中。 因此，所有被记录的Grains都已经可以获得这些。 有关这些提供程序的功能和区别的说明，请参见 包括日志一致性提供程序 . 群集配置 日志一致性提供程序的配置与任何其他Orleans提供程序一样。 例如，要包含所有三个提供者(当然，您可能不需要全部三个提供者)，请将此添加到 <Globals> 配置文件的元素： <LogConsistencyProviders> <Provider Type=\"Orleans.EventSourcing.StateStorage.LogConsistencyProvider\" Name=\"StateStorage\" /> <Provider Type=\"Orleans.EventSourcing.LogStorage.LogConsistencyProvider\" Name=\"LogStorage\" /> <Provider Type=\"Orleans.EventSourcing.CustomStorage.LogConsistencyProvider\" Name=\"CustomStorage\" /> </LogConsistencyProviders> 同样可以通过编程实现。 移动到2.0.0稳定，客户端配置和集群配置不再存在！ 它现在已经被一个clientbuilder和一个silobuilder所取代(注意没有集群构建器)。 builder.AddLogStorageBasedLogConsistencyProvider(\"LogStorage\") Grains类属性 每个记录的Grains类必须有 日志一致性提供程序 属性指定日志一致性提供程序。 一些提供商还要求 存储提供程序 属性。 如：[存储提供程序(providername=“orleanslocalstorage”)][logconsistencyprovider(providername = \"logstorage\")]公共类事件源dbankAccountGrain:JournaledGrain [StorageProvider(ProviderName = \"OrleansLocalStorage\")] [LogConsistencyProvider(ProviderName = \"LogStorage\")] public class EventSourcedBankAccountGrain : JournaledGrain<BankAccountState>, IEventSourcedBankAccountGrain { ... } 所以这里“orleanslocalstorage”被用来存储grain状态，其中“logstorage”是eventsourcing事件的内存存储提供程序。 LogConsistencyProvider属性 要指定日志一致性提供程序，请添加 [日志一致性提供程序(providername=…)] 属性，并提供由群集配置配置配置的提供程序的名称。 例如： [LogConsistencyProvider(ProviderName = \"CustomStorage\")] public class ChatGrain : JournaledGrain<XDocument, IChatEvent>, IChatGrain, ICustomStorage { ... } StorageProvider属性 一些日志一致性提供程序(包括 日志存储 和 状态存储 )使用标准的StorageProvider与存储通信。 此提供程序使用单独的 存储提供程序 属性，如下所示： [LogConsistencyProvider(ProviderName = \"LogStorage\")] [StorageProvider(ProviderName = \"AzureBlobStorage\")] public class ChatGrain : JournaledGrain<XDocument, IChatEvent>, IChatGrain { ... } 默认提供程序 可以省略 日志一致性提供程序 和/或 存储提供程序 属性，如果在配置中指定了默认值。 这是通过使用特殊的名称来完成的 违约 各自的供应商。 例如： <LogConsistencyProviders> <Provider Type=\"Orleans.EventSourcing.LogStorage.LogConsistencyProvider\" Name=\"Default\" /> </LogConsistencyProviders> <StorageProviders> <Provider Type=\"Orleans.Storage.MemoryStorage\" Name=\"Default\" /> </StorageProviders>"
  },
  "docs/grains/event_sourcing/immediate_vs_delayed_confirmation.html": {
    "href": "docs/grains/event_sourcing/immediate_vs_delayed_confirmation.html",
    "title": "Immediate vs. Delayed Confirmation | Microsoft Orleans Documentation",
    "keywords": "立即确认 对于许多应用程序，我们希望确保事件立即得到确认，以便持久化的版本不会落后于内存中的当前版本，并且我们不会冒丢失最新状态的风险(如果grain失败)。 我们可以通过以下规则来保证： 在Grain方法返回之前，使用 ConfirmEvents 确认所有 RaiseEvent 调用。 在Grain方法返回之前确保由 RaiseConditionalEvent 返回的任务已完成。 避免 [Reentrant] 或 [AlwaysInterleave] 属性，因此一次只能处理一个grain调用。 如果我们遵循这些规则，则意味着在引发事件之后，在将事件写入存储器之前，不能执行其他Grain代码。 因此，不可能观察到内存中的版本和存储中的版本之间的不一致。 虽然这通常正是我们想要的，但它也有一些潜在的缺点。 潜在劣势 如果 与远程群集或存储的连接暂时中断 ，则grain变得不可用：实际上，grain在等待确认事件时无法执行任何代码，这可能需要无限长的时间(日志一致性协议一直在重试，直到恢复存储连接)。 处理时 对单个grain实例的大量更新 ，一次确认一个会变得非常低效，即吞吐量很低。 延迟确认 为了提高上述情况下的可用性和吞吐量，Grains可以选择执行以下一项或两项操作： 允许grain方法在不等待确认的情况下引发事件。 允许重入，这样即使以前的调用在等待确认时被阻塞，grain也可以继续处理新的调用。 这意味着当某些事件仍在确认过程中时，可以执行Grain代码。 这个 日志记录 api有一些具体规定，让开发人员能够精确控制如何处理当前“正在运行”的未经确认的事件。 可以检查以下属性以了解当前未确认的事件： IEnumerable<EventType> UnconfirmedEvents { get; } 而且，由于 State 属性不包括未确认事件的影响，有一个可选属性 StateType TentativeState { get; } 它返回一个“暂定”状态，通过应用所有未确认的事件从“状态”获得。 在所有未经证实的事件被证实后，暂时状态本质上是对下一个确认状态的“最佳猜测”。 然而，并不能保证它真的会发生，因为Grains可能会失败，或者因为事件可能与其他事件竞争而失败，导致它们被取消(如果它们是有条件的)或者出现在序列中比预期的更晚的位置(如果它们是无条件的)。 并发保证 请注意，即使在使用Reentrant性或延迟确认的情况下，基于orleans turn的调度(协作并发)保证也始终适用。 这意味着，即使有几个方法在进行中，也只有一个方法可以主动执行——所有其他的方法都处于等待状态，因此从来没有任何真正的竞争是由并行线程引起的。 尤其要注意： State , TentativeState , Version , 和 UnconfirmedEvents 属性可以在方法执行期间更改。 但这种变化只能在等待的时候发生。 这些保证假定用户代码保持在 推荐做法 关于任务和异步/等待(特别是，不使用线程池任务，或者只将它们用于不调用grain功能且等待正确的代码)。"
  },
  "docs/grains/event_sourcing/index.html": {
    "href": "docs/grains/event_sourcing/index.html",
    "title": "Event Sourcing Overview | Microsoft Orleans Documentation",
    "keywords": "活动来源 事件溯源提供了一种灵活的方式来管理和持久化Grain状态。 与标准Grains相比，事件源Grains具有许多潜在优势。 首先，它可以与许多不同的存储提供程序配置一起使用，并支持跨多个群集的地理复制。 此外，它还将grain类与grain状态(由grain状态对象表示)和grain更新(由事件对象表示)的定义完全分离。 文件结构如下： 日志训练基础 解释如何通过从 日志记录 ，如何访问当前状态，以及如何引发更新状态的事件。 复制实例 解释事件源机制如何处理复制的grain实例并确保一致性。 它讨论了比赛事件和冲突的可能性，以及如何解决它们。 立即/延迟确认 解释延迟的事件确认和重新进入如何提高可用性和吞吐量。 通知 解释如何订阅通知，允许Grains对新事件作出反应。 事件源配置 说明如何配置项目、群集和日志一致性提供程序。 内置日志一致性提供程序 解释当前包含的三个日志一致性提供程序的工作方式。 日志Grain诊断 解释如何监视连接错误，并获取简单的统计信息。 就journaledgrain api而言，上面记录的行为是相当稳定的。 但是，我们希望很快扩展或更改日志一致性提供程序列表，以便更容易地允许开发人员插入标准事件存储系统。"
  },
  "docs/grains/event_sourcing/journaledgrain_basics.html": {
    "href": "docs/grains/event_sourcing/journaledgrain_basics.html",
    "title": "JournaledGrain API | Microsoft Orleans Documentation",
    "keywords": "日志训练基础 日记grains来源于 <journaledgrain<statetype，事件类型> ，具有以下类型参数： 这个 状态类型 表示Grains的状态。 它必须是具有公共默认构造函数的类。 事件类型 是可为此Grain引发的所有事件的通用父类型，可以是任何类或接口。 所有状态和事件对象都应该是可序列化的(因为日志一致性提供程序可能需要持久化它们，和/或在通知消息中发送它们)。 对于事件是pocos(普通的旧c对象)的Grains， 日志记录<statetype> 可用作 journaledgrain<statetype，对象> 是的。 解读grain状况 要读取当前grains状态并确定其版本号，journaledgrain具有属性 GrainState State { get; } int Version { get; } 版本号始终等于已确认事件的总数，状态是将所有已确认事件应用于初始状态的结果。 初始状态的版本为0(因为没有应用任何事件)，由grainstate类的默认构造函数确定。 重要： 应用程序不应直接修改 State 是的。 这本书仅供阅读。 相反，当应用程序想要修改状态时，它必须通过引发事件间接地进行修改。 引发事件 通过调用 葡萄干 功能。 例如，一个代表聊天的Grains可以引发 后遗症 要指示用户提交了帖子，请执行以下操作： RaiseEvent(new PostedEvent() { Guid = guid, User = user, Text = text, Timestamp = DateTime.UtcNow }); 请注意 葡萄干 启动对存储的写入访问，但不等待写入完成。 对于许多应用程序，必须等到我们确认事件已被持久化。 在这种情况下，我们总是等待 证实人 以下内容： RaiseEvent(new DepositTransaction() { DepositAmount = amount, Description = description }); await ConfirmEvents(); 请注意，即使您没有显式调用 证实人 ，事件最终将得到确认-它在后台自动发生。 状态转换方法 运行时更新Grains状态 自动 每当事件发生时。 应用程序不需要在引发事件后显式更新状态。 但是，应用程序仍然必须提供指定 怎样 更新状态以响应事件。 这可以通过两种方式来实现。 (一) grainstate类可以实现一个或多个 应用 方法论 状态类型 是的。 通常，会创建多个重载，并为事件的运行时类型选择最接近的匹配： class GrainState { Apply(E1 @event) { // code that updates the state } Apply(E2 @event) { // code that updates the state } } (二) grains可以覆盖transitionState函数： protected override void TransitionState(State state, EventType @event) { // code that updates the state } 假设转换方法除了修改状态对象之外没有任何副作用，并且应该是确定性的(否则，效果是不可预测的)。 如果转换代码抛出异常，则会捕获该异常并将其包含在日志一致性提供程序发出的Orleans日志中的警告中。 确切地说，运行时调用转换方法取决于所选的日志一致性提供程序及其配置。 对于应用程序来说，最好不要依赖于特定的时间，除非日志一致性提供程序特别保证。 一些提供者，如 日志存储 日志一致性提供程序，每次加载Grain时重播事件序列。 因此，只要事件对象仍然可以从存储中正确反序列化，就有可能从根本上修改grainstate类和转换方法。 但对于其他提供商，如 状态存储 日志一致性提供程序，仅 Grain灰岩 对象是持久化的，因此开发人员必须确保从存储中读取时可以正确反序列化它。 引发多个事件 在调用confirmeEvents之前，可以多次调用raiseEvent： RaiseEvent(e1); RaiseEvent(e2); await ConfirmEvents(); 但是，这可能会导致两次连续的存储访问，并且只在写入第一个事件之后，Grains可能会失败。 因此，通常最好使用 RaiseEvents(IEnumerable<EventType> events) 这保证了给定的事件序列以原子方式写入存储器。 请注意，由于版本号始终与事件序列的长度匹配，因此引发多个事件会使版本号每次增加一个以上。 检索事件序列 下面的方法 日志记录 类允许应用程序检索所有已确认事件序列的指定段： Task<IReadOnlyList<EventType>> RetrieveConfirmedEvents(int fromVersion, int toVersion) 但是，并非所有日志一致性提供程序都支持它。 如果不支持，或者序列的指定段不再可用，则 冒号 被扔了。 要检索最新确认版本之前的所有事件，可以调用 await RetrieveConfirmedEvents(0, Version); 只能检索已确认的事件：如果 Toversion 大于属性的当前值 版本 是的。 因为确认的事件永远不会改变，所以即使在存在多个实例或延迟确认的情况下，也不必担心比赛。 但是，在这种情况下，有可能 版本 当await比当时恢复 检索确认事件 被调用，因此建议将其值保存在变量中。 另请参阅关于并发保证的部分。"
  },
  "docs/grains/event_sourcing/journaledgrain_diagnostics.html": {
    "href": "docs/grains/event_sourcing/journaledgrain_diagnostics.html",
    "title": "JournaledGrain Diagnostics | Microsoft Orleans Documentation",
    "keywords": "JournaledGrain Diagnostics 监视连接错误 通过设计，日志一致性提供程序在出现连接错误(包括与存储的连接以及群集之间的连接)时具有弹性。 但是仅仅容忍错误是不够的，因为应用程序通常需要监视任何此类问题，并在严重时提请操作员注意。 当观察到连接错误并解决了这些错误时，JournaledGrain子类可以重写以下方法来接收通知： protected override void OnConnectionIssue(ConnectionIssue issue) { /// handle the observed error described by issue } protected override void OnConnectionIssueResolved(ConnectionIssue issue) { /// handle the resolution of a previously reported issue } ConnectionIssue 是一个抽象类，有几个公共字段描述该问题，包括自上次成功连接以来已观察到此问题的次数。 连接问题的实际类型由子类定义。 连接问题分为以下几种类型： PrimaryOperationFailed 要么 NotificationFailed ，有时还有多余的键(例如 RemoteCluster )，进一步缩小了类别。 如果同一类别的问题多次发生(例如，我们不断收到以相同的 RemoteCluster 为目标的 NotificationFailed )，每次由 OnConnectionIssue 。 解决此类问题后(例如，我们终于可以成功向此发送通知 RemoteCluster )， 然后 OnConnectionIssueResolved 被调用一次，与 问题 上次报告的对象 OnConnectionIssue 。 独立类别的连接问题及其解决方案将独立报告。 简单统计 目前，我们为基本统计信息提供了简单的支持(将来，我们可能会用更标准的遥测机制来代替它)。 通过调用可以为JournaledGrain启用或禁用统计信息收集 void EnableStatsCollection() void DisableStatsCollection() 可以通过调用获取统计信息 LogConsistencyStatistics GetStats()"
  },
  "docs/grains/event_sourcing/log_consistency_providers.html": {
    "href": "docs/grains/event_sourcing/log_consistency_providers.html",
    "title": "Log-Consistency Providers | Microsoft Orleans Documentation",
    "keywords": "内置日志一致性提供程序 的 Microsoft.Orleans.EventSourcing 该软件包包括几个日志一致性提供程序，这些提供程序涵盖了适合入门的基本方案，并具有一定的可扩展性。 Orleans.EventSourcing. StateStorage .LogConsistencyProvide 该提供商存储 grains状态快照 ，使用可以独立配置的标准存储提供程序。 保留在存储中的数据是一个对象，它既包含Grain状态(由第一个type参数指定为 JournaledGrain )和一些元数据(版本号，以及用于避免存储访问失败时事件重复的特殊标记)。 由于每次访问存储时都会读取/写入整个grains状态，因此此提供程序不适用于grains状态非常大的对象。 该提供者不支持 RetrieveConfirmedEvents (检索已确认事件)：它不能从存储中检索事件，因为事件没有持久化。 Orleans.EventSourcing。 LogStorage .LogConsistencyProvider 该提供商存储 完整的事件序列作为单个对象 ，使用可以独立配置的标准存储提供程序。 保留在存储中的数据是一个包含以下内容的对象： List <EventType> object 以及一些元数据(一个特殊的标记，用于在存储访问失败时避免事件重复)。 该提供者确实支持 RetrieveConfirmedEvents . 所有事件始终可用并保存在内存中。 All events are always available and kept in memory. 由于每次访问存储时都会读取/写入整个事件序列，因此此提供程序是 不适合在生产中使用 ，除非保证事件序列保持很短。 此提供程序的主要目的是说明事件源的语义，以及用于示例/测试环境的语义。 Orleans.EventSourcing. CustomStorage .LogConsistencyProvider 此提供程序允许开发人员插入自己的存储接口，然后在适当的时间由conistency协议调用。 这个提供程序不会对存储的内容是状态快照还是事件做出特定的假设—程序员可以控制这个选择(并且可以存储其中一个或两个)。 要使用此提供程序，必须从 JournaledGrain<StateType, EventType> ，但还必须实现以下接口： public interface ICustomStorageInterface<StateType, EventType> { Task<KeyValuePair<int,StateType>> ReadStateFromStorage(); Task<bool> ApplyUpdatesToStorage(IReadOnlyList<EventType> updates, int expectedversion); } 一致性提供程序希望它们以某种方式运行。 程序员应该意识到： 第一种方法， ReadStateFromStorage ，应同时返回版本和状态read。 如果尚未存储任何内容，则应为版本返回零，并返回与的默认构造函数相匹配的状态 状态类型 . ApplyUpdatesToStorage 如果预期版本与实际版本不匹配，则必须返回false(这类似于e-tag检查)。 如果 ApplyUpdatesToStorage 失败，但出现异常，一致性提供程序将重试。 这意味着如果抛出这样的异常，某些事件可能会被复制，但事件实际上是持久化的。 开发人员负责确保这是安全的：例如，要么通过不引发异常来避免这种情况，要么确保重复事件对应用程序逻辑无害，要么添加一些额外的机制来过滤重复项。 This provider does not support RetrieveConfirmedEvents . 此提供程序不支持 RetrieveConfirmedEvents . 当然，由于开发人员无论如何都控制着存储接口，所以他们不需要首先调用这个接口，而是可以实现自己的事件检索。"
  },
  "docs/grains/event_sourcing/notifications.html": {
    "href": "docs/grains/event_sourcing/notifications.html",
    "title": "通知 | Microsoft Orleans Documentation",
    "keywords": "通知 有能力对状态变化作出反应通常是很方便的。 所有回调都受orleans的基于轮换的保证的约束；另请参见关于并发保证的一节。 跟踪确认状态 如果确认状态发生任何变化， 日志记录 子类可以重写此方法： protected override void OnStateChanged() { // read state and/or event log and take appropriate action } 状态已更改 每当确认的状态更新(即版本号增加)时调用。 这可能发生在 已从存储中加载状态的新版本。 此实例引发的事件已成功写入存储。 从其他实例接收到通知消息。 注意，由于所有的grains最初都有版本0，直到存储的初始加载完成，这意味着 状态已更改 在初始加载完成且版本大于零时调用。 跟踪暂定状态 如果临时状态有任何变化， 日志记录 子类可以重写此方法： protected override void OnTentativeStateChanged() { // read state and/or events and take appropriate action } ontentativestatechanged 当暂定状态改变时调用，即如果组合序列(confirmedEvents+confirmedEvents)改变。 特别是，回调 ontentativestatechanged() 总是发生在 葡萄干 ."
  },
  "docs/grains/event_sourcing/replicated_instances.html": {
    "href": "docs/grains/event_sourcing/replicated_instances.html",
    "title": "Replicated Grains | Microsoft Orleans Documentation",
    "keywords": "Replicated Grains 有时，同一Grain的多个实例可能处于活动状态，例如在操作多集群时，使用 [OneInstancePerCluster] 属性。 journaledgrain旨在以最小的影响支持多副本实例。 它依赖于 日志一致性提供程序 运行必要的协议以确保所有实例同意相同的事件序列。 特别要注意以下几个方面： 一致的版本 ：Grains状态的所有版本(临时版本除外)都基于相同的全局事件序列。 特别是，如果两个实例看到相同的版本号，则它们看到相同的状态。 事件竞争 ：多个实例可以同时引发事件。 一致性提供程序解决了这个竞争，并确保每个人都同意相同的顺序。 通知/反应性 ：在一个Grains实例上引发事件后，一致性提供程序不仅更新存储，还通知所有其他Grains实例。 有关一致性模型的一般讨论，请参见 技术报告 以及 GSP 论文 (全局序列协议)。 条件事件 如果事件竞争有冲突，也就是说，由于某种原因，不应该同时进行，那么事件竞争可能会有问题。 例如，在从银行账户取款时，有两个实例可以独立地确定有足够的资金用于取款，并发出取款事件。 但这两个事件的结合可能透支。 为了避免这种情况，journaledgrain api支持 RaiseConditionalEvent 方法。 bool success = await RaiseConditionalEvent(new WithdrawalEvent() { ... }); 条件事件仔细检查本地版本是否与存储中的版本匹配。 如果没有，则意味着事件序列同时增长，这意味着此事件已失去与其他事件的竞争。 在这种情况下，条件事件是 不 附加到日志中，并且 RaiseConditionalEvent 返回false。 这类似于在条件存储更新中使用e-tags，并且同样提供了一种简单的机制来避免提交冲突事件。 对同一个Grain同时使用条件和无条件事件是可能和明智的，例如 DepositEvent 以及 WithdrawalEvent 。 存款不需要有条件：即使 DepositEvent 如果竞争失败，则不必取消，但仍可以附加到全局事件序列中。 等待任务返回者 RaiseConditionalEvent 足以确认事件，即不必同时调用 ConfirmEvents 。 显式同步 有时，最好确保Grains完全赶上最新版本。 这可以通过调用 await RefreshNow(); 其中(1)确认所有未确认事件，和(2)从存储中加载最新版本。"
  },
  "docs/grains/external_tasks_and_grains.html": {
    "href": "docs/grains/external_tasks_and_grains.html",
    "title": "External Tasks and Grains | Microsoft Orleans Documentation",
    "keywords": "External Tasks and Grains 根据设计，任何从子级代码中产生的子任务(例如，通过使用await要么 继续 要么 Task.Factory.StartNew )将在每次激活时分派 TPL任务计划程序 作为父任务，因此继承了与其余Grains代码相同的单线程执行模型。 这是单线程执行的主要要点 基于Grains转向的并发 。 在某些情况下，Grains代码可能需要“突破”Orleans任务调度模型并“做一些特别的事情”，例如明确指向 Task 到其他任务计划程序或使用.NET线程池。 这种情况的一个例子是当Grains代码必须执行同步的远程阻塞调用(例如远程IO)时。 在Grains环境中执行此操作将阻塞Grains以及Orleans线程之一，因此永远不应该这样做。 相反，grain代码可以在线程池线程上执行这段阻塞代码并加入(await)该执行的完成，并根据具体情况进行。 我们希望，从“Orleans”调度程序中转义将是非常高级且很少需要的使用场景，超出了“正常”使用模式。 基于任务的API： 1)await， Task.Factory.StartNew (见下文)， Task.ContinuewWith ， Task.WhenAny ， Task.WhenAll ， Task.Delay 都尊重当前的任务计划程序。 这意味着以默认方式使用它们而不传递其他TaskScheduler会使它们在Grains上下文中执行。 2)两者Task.Run 和 endMethod 的代表 Task.Factory.FromAsync 不要尊重当前的任务计划程序。 他们都使用 TaskScheduler.Default Scheduler，它是.NET线程池任务Scheduler。 因此，里面的代码Task.Run 和 endMethod 将始终在OrleansGrains的单线程执行模型之外的.NET线程池上运行， 如这里详细 。 但是， 等待Task.Run 要么 等待Task.Factory.FromAsync 将在创建任务时在调度程序下运行，这就是Grains调度程序。 3) configureAwait(false) 是用于逃避当前任务计划程序的显式API。 这将导致在等待的任务之后在 TaskScheduler.Default 调度程序，它是.NET线程池，因此将中断Orleans grain的单线程执行。 你一般应该**永远不要使用 ConfigureAwait(false) 直接在Grains代码中。 ** 4)带签名的方法 异步无效 不应与Grains一起使用。 它们旨在用于图形用户接口事件处理程序。 Task.Factory.StartNew和异步委托 在任何C＃程序中调度任务的通常建议是使用Task.Run 有利于 Task.Factory.StartNew 。 实际上，谷歌快速搜索使用 Task.Factory.StartNew() 会建议[那是危险的](https://blog.stephencleary.com/2013/08/startnew-is-dangerous.html)和[那应该永远喜欢Task.Run ]( https://devblogs.microsoft.com/pfxteam/task-run-vs-task-factory-startnew/)。 但是，如果我们希望保留在Orleans单线程执行模型中，那么我们需要使用它，那么我们如何正确地执行它呢？ 使用时的“危险” Task.Factory.StartNew() 是它本身不支持异步委托。 这意味着这可能是一个错误： var notIntendedTask = Task.Factory.StartNew(SomeDelegateAsync) 。 notIntendedTask 是 不 在以下时间完成的任务 SomeDelegateAsync 做。 相反，应该 总是 解开返回的任务： var task = Task.Factory.StartNew(SomeDelegateAsync).Unwrap() 。 例： 以下是示例代码，演示了如何使用 TaskScheduler.Current ，Task.Run`以及一个特殊的自定义调度程序，可从OrleanGrains上下文以及如何返回到该上下文中逃脱。 public async Task MyGrainMethod() { // Grab the Orleans task scheduler var orleansTs = TaskScheduler.Current; await TaskDelay(10000); // Current task scheduler did not change, the code after await is still running in the same task scheduler. Assert.AreEqual(orleansTs, TaskScheduler.Current); Task t1 = Task.Run( () => { // This code runs on the thread pool scheduler, not on Orleans task scheduler Assert.AreNotEqual(orleansTS, TaskScheduler.Current); Assert.AreEqual(TaskScheduler.Default, TaskScheduler.Current); } ); await t1; // We are back to the Orleans task scheduler. // Since await was executed in Orleans task scheduler context, we are now back to that context. Assert.AreEqual(orleansTS, TaskScheduler.Current); // Example of using ask.Factory.StartNew with a custom scheduler to escape from the Orleans scheduler Task t2 = Task.Factory.StartNew(() => { // This code runs on the MyCustomSchedulerThatIWroteMyself scheduler, not on the Orleans task scheduler Assert.AreNotEqual(orleansTS, TaskScheduler.Current); Assert.AreEqual(MyCustomSchedulerThatIWroteMyself, TaskScheduler.Current); }, CancellationToken.None, TaskCreationOptions.None, scheduler: MyCustomSchedulerThatIWroteMyself); await t2; // We are back to Orleans task scheduler. Assert.AreEqual(orleansTS, TaskScheduler.Current); } Assert.AreEqual(orleansTs, TaskScheduler.Current); Task t1 = Task.Run( () => { // This code runs on the thread pool scheduler, not on Orleans task scheduler Assert.AreNotEqual(orleansTS, TaskScheduler.Current); Assert.AreEqual(TaskScheduler.Default, TaskScheduler.Current); } ); await t1; // We are back to the Orleans task scheduler. // Since await was executed in Orleans task scheduler context, we are now back to that context. Assert.AreEqual(orleansTS, TaskScheduler.Current); // Example of using ask.Factory.StartNew with a custom scheduler to escape from the Orleans scheduler Task t2 = Task.Factory.StartNew(() => { // This code runs on the MyCustomSchedulerThatIWroteMyself scheduler, not on the Orleans task scheduler Assert.AreNotEqual(orleansTS, TaskScheduler.Current); Assert.AreEqual(MyCustomSchedulerThatIWroteMyself, TaskScheduler.Current); }, CancellationToken.None, TaskCreationOptions.None, scheduler: MyCustomSchedulerThatIWroteMyself); await t2; // We are back to Orleans task scheduler. Assert.AreEqual(orleansTS, TaskScheduler.Current); } 高级示例-从运行在线程池上的代码进行Grain调用 甚至更高级的方案是一段Grains代码，需要“突破”Orleans任务调度模型并在线程池(或其他非Orleans上下文)上运行，但仍需要调用另一个Grains。 如果您尝试进行一次Grains调用但不在Orleans上下文中，则会收到一个异常，指出您正在“尝试从silos而不是从Grains内部而不是系统目标内部发送消息(RuntimeContext不是 设置为SchedulingContext)”。 public async Task MyGrainMethod() { // Grab the Orleans task scheduler var orleansTs = TaskScheduler.Current; Task<int> t1 = Task.Run(async () => { // This code runs on the thread pool scheduler, not on Orleans task scheduler Assert.AreNotEqual(orleansTS, TaskScheduler.Current); // You can do whatever you need to do here. Now let's say you need to make a grain call. Task<Task<int>> t2 = Task.Factory.StartNew(() => { // This code runs on the Orleans task scheduler since we specified the scheduler: orleansTs. Assert.AreEqual(orleansTS, TaskScheduler.Current); return GrainFactory.GetGrain<IFooGrain>(0).MakeGrainCall(); }, CancellationToken.None, TaskCreationOptions.None, scheduler: orleansTs); int res = await (await t2); // double await, unrelated to Orleans, just part of TPL APIs. // This code runs back on the thread pool scheduler, not on the Orleans task scheduler Assert.AreNotEqual(orleansTS, TaskScheduler.Current); return res; } ); int result = await t1; // We are back to the Orleans task scheduler. // Since await was executed in the Orleans task scheduler context, we are now back to that context. Assert.AreEqual(orleansTS, TaskScheduler.Current); } Now let's say you need to make a grain call. Task<Task<int>> t2 = Task.Factory.StartNew(() => { // This code runs on the Orleans task scheduler since we specified the scheduler: orleansTs. Assert.AreEqual(orleansTS, TaskScheduler.Current); return GrainFactory.GetGrain<IFooGrain>(0).MakeGrainCall(); }, CancellationToken.None, TaskCreationOptions.None, scheduler: orleansTs); int res = await (await t2); // double await, unrelated to Orleans, just part of TPL APIs. // This code runs back on the thread pool scheduler, not on the Orleans task scheduler Assert.AreNotEqual(orleansTS, TaskScheduler.Current); return res; } ); int result = await t1; // We are back to the Orleans task scheduler. // Since await was executed in the Orleans task scheduler context, we are now back to that context. Assert.AreEqual(orleansTS, TaskScheduler.Current); } 下面的代码演示了如何从在Grains内部但不在Grains上下文中运行的一段代码进行Grains调用。 与图书馆打交道 您的代码正在使用的某些外部库可能正在使用 ConfigureAwait(false)内部。 实际上，在.NET中使用它是一种正确的好习惯 ConfigureAwait(false) 在实现通用库时。 在Orleans，这不是问题。 只要调用库方法的grain中的代码正在等待常规的库调用 等待，粒码正确。 结果将完全符合要求-库代码将在Default Scheduler上继续运行(碰巧是 ThreadPoolTask​​Scheduler 另一个经常问到的问题是，是否需要使用Task.Run -也就是说，是否需要将库代码显式卸载到ThreadPool(用于Grains代码) Task.Run(()=> myLibrary.FooAsync()))。 答案是否定的。 The answer is No. 除了库代码进行阻塞同步调用的情况外，无需将任何代码卸载到ThreadPool。 通常，任何编写正确且正确的.NET异步库(返回的方法 Task 并以 异步`后缀)请勿拨调用。 因此，除非您怀疑异步库有故障或故意使用同步阻塞库，否则无需将任何内容卸载到ThreadPool。 摘要 你想做什么？ 怎么做 在.NET线程池线程上运行后台工作。 不允许使用任何Grains代码或Grains调用。 Task.Run` grains接口调用 方法返回类型= Task 或 Task<T> 使用基于Orleans回合的并发保证( 往上看 )。 Task.Factory.StartNew(WorkerAsync).Unwrap() 使用基于Orleans回合的并发保证，可以从Grains代码运行同步工作者任务。 Task.Factory.StartNew(WorkerSync) 执行工作项的超时 Task.Delay + Task.WhenAny 用于async/await 普通的.NET Task-Async编程模型。 支持和推荐 ConfigureAwait(false) 请勿使用内部Grains代码。 仅在库内部允许。 调用异步库 await图书馆调用"
  },
  "docs/grains/grain_identity.html": {
    "href": "docs/grains/grain_identity.html",
    "title": "Grain Identity | Microsoft Orleans Documentation",
    "keywords": "Grain Identity 在面向对象的环境中，很难将对象的标识与对其的引用区分开。 因此，当使用new创建对象时，您获得的引用代表其身份的所有方面，除了那些将对象映射到其所代表的外部实体的方面。 在分布式系统中，对象引用不能表示实例身份，因为引用通常限于单个地址空间。 .NET引用肯定是这种情况。 此外，无论Grains是否处于活动状态，它都必须具有身份，以便我们可以按需激活它。 因此，Grains具有主键。 主键可以是全局唯一标识符(GUID)，长整数或字符串。 Grain的主键在其类型中定义。 因此，Grain的完整标识由Grain的类型及其键组成。 Grains的调用者决定应使用哪种方案。 选项包括： long GUID string GUID + string long + string 因为基础数据是相同的，所以这些方案可以互换使用。 当使用长整数时，实际上会创建一个GUID并用零填充。 需要使用单例Grains实例的情况(例如字典或注册表)可从使用中受益 Guid.Empty 作为其关键。 这仅仅是一个约定，但是通过坚持，正如我们在第一个教程中所看到的，在调用站点处，事情已经很清楚了。 使用GUID 当有多个进程可能需要请求grain时，例如Web场中的许多Web服务器，GUID很有用。 您不需要协调主键的分配，这可能会导致系统出现单点故障，也可能不需要对资源进行系统侧锁定就可能造成瓶颈。 GUID发生碰撞的可能性很小，因此在构建Orleans系统时，它们可能是默认选择。 在客户端代码中通过GUID引用Grains： var grain = grainFactory.GetGrain<IExample>(Guid.NewGuid()); 从Grains代码中检索主键： public override Task OnActivateAsync() { Guid primaryKey = this.GetPrimaryKey(); return base.OnActivateAsync(); } 使用Longs 也可以使用一个长整数，如果将Grains持久保存到关系数据库中(在该数据库中数字索引优先于GUID)，这将是有意义的。 在客户端代码中通过长整数引用Grains： var grain = grainFactory.GetGrain<IExample>(1); 检索主键形式的Grain代码： public override Task OnActivateAsync() { long primaryKey = this.GetPrimaryKeyLong(); return base.OnActivateAsync(); } 使用字符串 字符串也是可用的。 在客户端代码中按字符串引用Grains： var grain = grainFactory.GetGrain<IExample>(\"myGrainKey\"); 检索主键形式的Grain代码： public override Task OnActivateAsync() { string primaryKey = this.GetPrimaryKeyString(); return base.OnActivateAsync(); } 使用复合主键 如果您的系统与GUID或long均不合适，则可以选择复合主键，该主键允许您使用GUID或long与字符串的组合来引用Grains。 您可以从 IGrainWithGuidCompoundKey 或 IGrainWithIntegerCompoundKey 接口继承接口，如下所示： public interface IExampleGrain : Orleans.IGrainWithIntegerCompoundKey { Task Hello(); } 在客户端代码中，这会向 GetGrain 粮厂的方法。 var grain = grainFactory.GetGrain<IExample>(0, \"a string!\", null); 要访问Grains中的复合键，我们可以在 GetPrimaryKey 方法： public class ExampleGrain : Orleans.Grain, IExampleGrain { public Task Hello() { string keyExtension; long primaryKey = this.GetPrimaryKeyLong(out keyExtension); Console.WriteLine(\"Hello from \" + keyExtension); Task.CompletedTask; } }"
  },
  "docs/grains/grain_lifecycle.html": {
    "href": "docs/grains/grain_lifecycle.html",
    "title": "Grain Lifecycle | Microsoft Orleans Documentation",
    "keywords": "Grain Lifecycle 总览 OrleansGrains使用可观察到的生命周期(请参见 Orleans生命周期 )进行有序的激活和停用。 这允许在Grains激活和收集期间以有序的方式启动和停止Grains逻辑，系统组件和应用程序逻辑。 阶段 预定的Grains生命周期阶段如下。 public static class GrainLifecycleStage { public const int First = int.MinValue; public const int SetupState = 1000; public const int Activate = 2000; public const int Last = int.MaxValue; } First -Grains生命周期的第一阶段 SetupState –在激活之前设置grains状态。 对于有状态的Grains，这是从存储中加载状态的阶段。 Activate – OnActivateAsync 和 OnDeactivateAsync 阶段 Last -Grains生命周期的最后阶段 尽管将在Grains激活期间使用Grains生命周期，但由于在某些错误情况下(例如Silo崩溃)并非总是停用Grains，因此应用程序不应依赖于在Grains停用过程中始终执行的Grains生命周期。 grain生命周期参与 应用程序逻辑可以通过两种方式参与Grains的生命周期：Grains可以参与其生命周期，和/或组件可以通过Grains激活上下文访问生命周期(请参阅IGrainActivationContext.ObservableLifecycle)。 Grains始终参与其自身的生命周期，因此可以通过覆盖参与方法来引入应用程序逻辑。 示例 public override void Participate(IGrainLifecycle lifecycle) { base.Participate(lifecycle); lifecycle.Subscribe(this.GetType().FullName, GrainLifecycleStage.SetupState, OnSetupState); } 在上面的示例中， grains<T> 覆盖 参加 告诉生命周期的方法在生命周期的SetupState阶段调用其OnSetupState方法。 在Grains的构造过程中创建的组件也可以参与生命周期，而无需添加任何特殊的Grains逻辑。 由于Grains的激活环境( IGrainActivationContext )，包括Grains的生命周期( IGrainActivationContext.ObservableLifecycle )是在创建Grains之前创建的，容器注入Grains中的任何成分都可以参与Grains的生命周期。 示例 使用工厂方法 Create(..) 创建时，以下组件会参与Grains的生命周期。 这种逻辑可能存在于组件的构造函数中，但是这会冒着风险在组件完全构建之前将其添加到生命周期中的风险，这可能并不安全。 public class MyComponent : ILifecycleParticipant<IGrainLifecycle> { public static MyComponent Create(IGrainActivationContext context) { var component = new MyComponent(); component.Participate(context.ObservableLifecycle); return component; } public void Participate(IGrainLifecycle lifecycle) { lifecycle.Subscribe<MyComponent>(GrainLifecycleStage.Activate, OnActivate); } private Task OnActivate(CancellationToken ct) { // Do stuff } } 通过工厂方法 Create(..) 注册上述组件到服务容器中，任何将组件作为依赖项构造的grain将使组件参与其生命周期，而grain中没有任何特殊逻辑。 在容器中注册组件 services.AddTransient<MyComponent>(sp => MyComponent.Create(sp.GetRequiredService<IGrainActivationContext>()); Grains以成分为依存关系 public class MyGrain : Grain, IMyGrain { private readonly MyComponent component; public MyGrain(MyComponent component) { this.component = component; } }"
  },
  "docs/grains/grain_persistence/azure_storage.html": {
    "href": "docs/grains/grain_persistence/azure_storage.html",
    "title": "Azure Storage Grain Persistence | Microsoft Orleans Documentation",
    "keywords": "Azure Storage Grain Persistence Azure存储Grain持久化提供程序同时支持 Azure Blob存储 和 Azure表存储 。 安装 安装 Microsoft.Orleans.Persistence.AzureStorage NuGet的软件包。 组态 Azure表存储 Azure表存储提供程序将状态存储在表行中，如果超出单个列的限制，则将状态分为多个列。 每行的最大长度为一兆字节，例如 扩展Azure表存储 。 使用以下命令配置Azure表存储Grain持久化提供程序 ISiloBuilder.AddAzureTableGrainStorage 扩展方法。 siloBuilder.AddAzureTableGrainStorage( name: \"profileStore\", configureOptions: options => { options.UseJson = true; options.ConnectionString = \"DefaultEndpointsProtocol=https;AccountName=data1;AccountKey=SOMETHING1\"; }); Azure Blob存储 Azure Blob存储提供程序将状态存储在Blob中。 使用以下命令配置Azure Blob存储Grain持久化提供程序 ISiloBuilder.AddAzureBlobGrainStorage 扩展方法。 siloBuilder.AddAzureBlobGrainStorage( name: \"profileStore\", configureOptions: options => { options.UseJson = true; options.ConnectionString = \"DefaultEndpointsProtocol=https;AccountName=data1;AccountKey=SOMETHING1\"; });"
  },
  "docs/grains/grain_persistence/dynamodb_storage.html": {
    "href": "docs/grains/grain_persistence/dynamodb_storage.html",
    "title": "Amazon DynamoDB Grain Persistence | Microsoft Orleans Documentation",
    "keywords": "Amazon DynamoDB Grain Persistence 安装 安装 Microsoft.Orleans.Persistence.DynamoDB NuGet的软件包。 组态 使用以下命令配置Dynamo DB Grain Persistence提供程序 ISiloBuilder.AddDynamoDBGrainStorage 扩展方法。 siloBuilder.AddDynamoDBGrainStorage( name: \"profileStore\", configureOptions: options => { options.UseJson = true; options.AccessKey = /* Dynamo DB access key */; options.SecretKey = /* Dynamo DB secret key */; options.Service = /* Dynamo DB service name */; });"
  },
  "docs/grains/grain_persistence/index.html": {
    "href": "docs/grains/grain_persistence/index.html",
    "title": "Persistence | Microsoft Orleans Documentation",
    "keywords": "Persistence Grains can have multiple named persistent data objects associated with them. These state objects are loaded from storage during grain activation so that they are available during requests. Grain persistence uses an extensible plugin model so that storage providers for any database can be used. This persistence model is designed for simplicity, and is not intended to cover all data access patterns. Grains can also access databases directly, without using the grain persistence model. In the above diagram, UserGrain has a Profile state and a Cart state, each of which is stored in a separate storage system. Goals Multiple named persistent data objects per grain. Multiple configured storage providers, each of which can have different configuration and be backed by a different storage system. Storage providers can be developed and published by the community. Storage providers have complete control over how they store grain state data in persistent backing store. Corollary: Orleans is not providing a comprehensive ORM storage solution, but instead allows custom storage providers to support specific ORM requirements as and when required. Packages Orleans grain storage providers can be found on NuGet . Officially maintained packages include: Microsoft.Orleans.Persistence.AdoNet is for SQL databases and other storage systems supported by ADO.NET. For more information, see ADO.NET Grain Persistence . Microsoft.Orleans.Persistence.AzureStorage is for Azure Storage, including Azure Blob Storage, Azure Table Storage, and Azure CosmosDB, via the Azure Table Storage API. For more information, see Azure Storage Grain Persistence . Microsoft.Orleans.Persistence.DynamoDB is for Amazon DynamoDB. For more information, see Amazon DynamoDB Grain Persistence . API Grains interact with their persistent state using IPersistentState<TState> where TState is the serializable state type: public interface IPersistentState<TState> where TState : new() { TState State { get; set; } string Etag { get; } Task ClearStateAsync(); Task WriteStateAsync(); Task ReadStateAsync(); } Instances of IPersistentState<TState> are injected into the grain as constructor parameters. These parameters can be annotated with a [PersistentState(stateName, storageName)] attribute to identify the name of the state being injected and the name of the storage provider which provides it. The following example demonstrates this by injecting two named states into the UserGrain constructor: public class UserGrain : Grain, IUserGrain { private readonly IPersistentState<ProfileState> _profile; private readonly IPersistentState<CartState> _cart; public UserGrain( [PersistentState(\"profile\", \"profileStore\")] IPersistentState<ProfileState> profile, [PersistentState(\"cart\", \"cartStore\")] IPersistentState<CartState> cart, ) { _profile = profile; _cart = cart; } } Different grain types can use different configured storage providers, even if both are the same type; for example, two different Azure Table Storage provider instances, connected to different Azure Storage accounts. Reading State Grain state will automatically be read when the grain is activated, but grains are responsible for explicitly triggering the write for any changed grain state when necessary. If a grain wishes to explicitly re-read the latest state for this grain from the backing store, the grain should call the ReadStateAsync() method. This will reload the grain state from the persistent store via the storage provider, and the previous in-memory copy of the grain state will be overwritten and replaced when the ReadStateAsync() Task completes. The value of the state is accessed using the State property. For example, the following method accesses the profile state declared in the code above: public Task<string> GetNameAsync() => Task.FromResult(_profile.State.Name); There is no need to call ReadStateAsync() during normal operation; the state is loaded automatically during activation. However, ReadStateAsync() can be used to refresh state which is modified externally. See the Failure Modes section below for details of error-handling mechanisms. Writing State State can be modified via the State property. Modified state is not automatically persisted. Instead, the developer decides when to persist state by calling the WriteStateAsync() method. For example, the following method updates a property on State and persists the updated state: public async Task SetNameAsync(string name) { _profile.State.Name = name; await _profile.WriteStateAsync(); } Conceptually, the Orleans Runtime will take a deep copy of the grain state data object for its own use during any write operations. Under the covers, the runtime may use optimization rules and heuristics to avoid performing some or all of the deep copy in some circumstances, provided that the expected logical isolation semantics are preserved. See the Failure Modes section below for details of error handling mechanisms. Clearing State The ClearStateAsync() method clears the grain's state in storage. Depending on the provider, this operation may optionally delete the grain state entirely. Getting Started Before a grain can use persistence, a storage provider must be configured on the silo. First, configure storage providers, one for profile state and one for cart state: var host = new HostBuilder() .UseOrleans(siloBuilder => { // Configure Azure Table storage using the name \"profileStore\" siloBuilder.AddAzureTableGrainStorage( name: \"profileStore\", configureOptions: options => { // Use JSON for serializing the state in storage options.UseJson = true; // Configure the storage connection key options.ConnectionString = \"DefaultEndpointsProtocol=https;AccountName=data1;AccountKey=SOMETHING1\"; }) // Configure Azure Blob storage using the name \"cartStore\" .AddAzureBlobGrainStorage( name: \"cartStore\", configureOptions: options => { // Use JSON for serializing the state in storage options.UseJson = true; // Configure the storage connection key options.ConnectionString = \"DefaultEndpointsProtocol=https;AccountName=data2;AccountKey=SOMETHING2\"; }); // -- other options }) .Build(); Now that a storage provider has been configured with the name \"profileStore\" , we can access this provider from a grain. Persistent state can be added to a grain in two primary ways: By injecting IPersistentState<TState> into the grain's constructor By inheriting from Grain<TState> The recommended way to add storage to a grain is by injecting IPersistentState<TState> into the grain's constructor with an associated [PersistentState(\"stateName\", \"providerName\")] attribute. For details on Grain<TState> , see below . This is still supported, but is considered legacy. Declare a class to hold our grain's state: [Serializable] public class ProfileState { public string Name { get; set; } public Date DateOfBirth } Inject IPersistentState<ProfileState> into the grain's constructor: public class UserGrain : Grain, IUserGrain { private readonly IPersistentState<ProfileState> _profile; public UserGrain([PersistentState(\"profile\", \"profileStore\")] IPersistentState<ProfileState> profile) { _profile = profile; } } Note: the profile state will not be loaded at the time it is injected into the constructor, so accessing it is invalid at that time. The state will be loaded before OnActivateAsync is called. Now that the grain has persistent state, we can add methods to read and write the state: public class UserGrain : Grain, IUserGrain { private readonly IPersistentState<ProfileState> _profile; public UserGrain([PersistentState(\"profile\", \"profileStore\")] IPersistentState<ProfileState> profile) { _profile = profile; } public Task<string> GetNameAsync() => Task.FromResult(_profile.State.Name); public async Task SetNameAsync(string name) { _profile.State.Name = name; await _profile.WriteStateAsync(); } } Failure modes for persistence operations Failure modes for read operations Failures returned by the storage provider during the initial read of state data for that particular grain will result in failure of the activate operation for that grain; in such case, there will not be any call to that grain’s OnActivateAsync() life cycle callback method. The original request to the grain which caused the activation will be faulted back to the caller, the same way as any other failure during grain activation. Failures encountered by the storage provider when reading state data for a particular grain will result in an exception from ReadStateAsync() Task . The grain can choose to handle or ignore the Task exception, just like any other Task in Orleans. Any attempt to send a message to a grain which failed to load at silo startup time due to a missing / bad storage provider config will return the permanent error Orleans.BadProviderConfigException . Failure modes for write operations Failures encountered by the storage provider when writing state data for a particular grain will result in an exception thrown by WriteStateAsync() Task . Usually this means that the grain call exception will be thrown back to the client caller, provided the WriteStateAsync() Task is correctly chained in to the final return Task for this grain method. However, it is possible in certain advanced scenarios to write grain code to specifically handle such write errors, just like they can handle any other faulted Task . Grains that execute error-handling / recovery code must catch exceptions / faulted WriteStateAsync() Task s and not re-throw them, to signify that they have successfully handled the write error. Recommendations Use JSON serialization or another version-tolerant serialization format Code evolves over time and this often includes storage types, too. To accommodate for these changes, an appropriate serializer should be configured. For most storage providers, a UseJson option or similar is available to use JSON as a serialization format. Ensure that when evolving data contracts that already-stored data will still be loadable. Using Grain<TState> to add storage to a grain NOTE: Using Grain<T> to add storage to a grain is considered legacy functionality: grain storage should be added using IPersistentState<T> as previously described. Grain classes that inherit from Grain<T> (where T is an application-specific state data type that needs to be persisted) will have their state loaded automatically from a specified storage. Such grains are marked with a [StorageProvider] attribute that specifies a named instance of a storage provider to use for reading / writing the state data for this grain. [StorageProvider(ProviderName=\"store1\")] public class MyGrain : Grain<MyGrainState>, /*...*/ { /*...*/ } The Grain<T> base class defined the following methods for subclasses to call: protected virtual Task ReadStateAsync() { /*...*/ } protected virtual Task WriteStateAsync() { /*...*/ } protected virtual Task ClearStateAsync() { /*...*/ } The behavior of these methods corresponds to their counterparts on IPersistentState<TState> defined earlier. Creating a storage provider There are two parts to the state persistence APIs: the API exposed to the grain via IPersistentState<T> or Grain<T> , and the storage provider API, which is centered around IGrainStorage — the interface which storage providers must implement: /// <summary> /// Interface to be implemented for a storage able to read and write Orleans grain state data. /// </summary> public interface IGrainStorage { /// <summary>Read data function for this storage instance.</summary> /// <param name=\"grainType\">Type of this grain [fully qualified class name]</param> /// <param name=\"grainReference\">Grain reference object for this grain.</param> /// <param name=\"grainState\">State data object to be populated for this grain.</param> /// <returns>Completion promise for the Read operation on the specified grain.</returns> Task ReadStateAsync(string grainType, GrainReference grainReference, IGrainState grainState); /// <summary>Write data function for this storage instance.</summary> /// <param name=\"grainType\">Type of this grain [fully qualified class name]</param> /// <param name=\"grainReference\">Grain reference object for this grain.</param> /// <param name=\"grainState\">State data object to be written for this grain.</param> /// <returns>Completion promise for the Write operation on the specified grain.</returns> Task WriteStateAsync(string grainType, GrainReference grainReference, IGrainState grainState); /// <summary>Delete / Clear data function for this storage instance.</summary> /// <param name=\"grainType\">Type of this grain [fully qualified class name]</param> /// <param name=\"grainReference\">Grain reference object for this grain.</param> /// <param name=\"grainState\">Copy of last-known state data object for this grain.</param> /// <returns>Completion promise for the Delete operation on the specified grain.</returns> Task ClearStateAsync(string grainType, GrainReference grainReference, IGrainState grainState); } Create a custom storage provider by implementing this interface and registering that implementation. For an example of an existing storage provider implementation, see AzureBlobGrainStorage . Storage provider semantics An opaque provider-specific Etag value ( string ) may be set by a storage provider as part of the grain state metadata populated when state was read. Some providers may choose to leave this as null if they do not use Etag s. Any attempt to perform a write operation when the storage provider detects an Etag constraint violation should cause the write Task to be faulted with transient error Orleans.InconsistentStateException and wrapping the underlying storage exception. public class InconsistentStateException : OrleansException { public InconsistentStateException( string message, string storedEtag, string currentEtag, Exception storageException) : base(message, storageException) { this.StoredEtag = storedEtag; this.CurrentEtag = currentEtag; } public InconsistentStateException(string storedEtag, string currentEtag, Exception storageException) : this(storageException.Message, storedEtag, currentEtag, storageException) { } /// <summary>The Etag value currently held in persistent storage.</summary> public string StoredEtag { get; private set; } /// <summary>The Etag value currently held in memory, and attempting to be updated.</summary> public string CurrentEtag { get; private set; } } Any other failure conditions from a storage operation must cause the returned Task to be broken with an exception indicating the underlying storage issue. In many cases, this exception may be thrown back to the caller which triggered the storage operation by calling a method on the grain. It is important to consider whether or not the caller will be able to deserialize this exception. For example, the client might not have loaded the specific persistence library containing the exception type. For this reason, it is advisable to convert exceptions into exceptions which can be propagated back to the caller. Data mapping Individual storage providers should decide how best to store grain state – blob (various formats / serialized forms) or column-per-field are obvious choices. Registering a storage provider The Orleans runtime will resolve a storage provider from the service provider ( IServiceProvider ) when a grain is created. The runtime will resolve an instance of IGrainStorage . If the storage provider is named, for example via the [PersistentState(stateName, storageName)] attribute, then a named instance of IGrainStorage will be resolved. To register a named instance of IGrainStorage , use the IServiceCollection.AddSingletonNamedService extension method following the example of the AzureTableGrainStorage provider here ."
  },
  "docs/grains/grain_persistence/relational_storage.html": {
    "href": "docs/grains/grain_persistence/relational_storage.html",
    "title": "ADO.NET Grain Persistence | Microsoft Orleans Documentation",
    "keywords": "ADO.NET Grain Persistence Orleans的关系存储后端代码是基于ADO.NET功能，因此与数据库供应商无关。 Orleans数据存储布局已经在运行时表中解释过了。 按照中的说明设置连接字符串 Orleans配置指南 . 要使Orleans代码在给定的关系数据库后端运行，需要执行以下操作： 适当的ADO.NET库必须加载到进程中。 这应该像往常一样定义，例如 数据库供应商工厂 应用程序配置中的元素。 配置ADO.NET不变性 Invariant 属性。 数据库需要存在并与代码兼容。 这是通过运行特定于供应商的数据库创建脚本来完成的。 有关详细信息，请参阅 ADO.NET配置 . NETGrain存储提供程序允许您在关系数据库中存储Grain状态。 当前支持以下数据库： SQLServer MySQL/MariaDB PostgreSQL Oracle 首先，安装基本软件包： Install-Package Microsoft.Orleans.Persistence.AdoNet 阅读 ADO.NET配置 文章获取有关配置数据库的信息，包括相应的ADO.NET不变和设置脚本。 下面是如何通过 ISiloHostBuilder 配置ADO.NET存储提供商: var siloHostBuilder = new SiloHostBuilder() .AddAdoNetGrainStorage(\"OrleansStorage\", options => { options.Invariant = \"<Invariant>\"; options.ConnectionString = \"<ConnectionString>\"; options.UseJsonFormat = true; }); 实际上，您只需要设置特定于数据库供应商的连接字符串和 Invariant (参见 ADO.NET配置 )标识供应商。 您还可以选择保存数据的格式，可以是二进制(默认)、JSON或XML。 虽然二进制是最紧凑的选项，但它是不透明的，您将无法读取或处理数据。 JSON是推荐的选项。 您可以通过设置以下属性 AdoNetGrainStorageOptions : /// <summary> /// Options for AdoNetGrainStorage /// </summary> public class AdoNetGrainStorageOptions { /// <summary> /// Connection string for AdoNet storage. /// </summary> [Redact] public string ConnectionString { get; set; } /// <summary> /// Stage of silo lifecycle where storage should be initialized. Storage must be initialized prior to use. /// </summary> public int InitStage { get; set; } = DEFAULT_INIT_STAGE; /// <summary> /// Default init stage in silo lifecycle. /// </summary> public const int DEFAULT_INIT_STAGE = ServiceLifecycleStage.ApplicationServices; /// <summary> /// The default ADO.NET invariant used for storage if none is given. /// </summary> public const string DEFAULT_ADONET_INVARIANT = AdoNetInvariants.InvariantNameSqlServer; /// <summary> /// The invariant name for storage. /// </summary> public string Invariant { get; set; } = DEFAULT_ADONET_INVARIANT; /// <summary> /// Whether storage string payload should be formatted in JSON. /// <remarks>If neither <see cref=\"UseJsonFormat\"/> nor <see cref=\"UseXmlFormat\"/> is set to true, then BinaryFormatSerializer will be configured to format storage string payload.</remarks> /// </summary> public bool UseJsonFormat { get; set; } public bool UseFullAssemblyNames { get; set; } public bool IndentJson { get; set; } public TypeNameHandling? TypeNameHandling { get; set; } public Action<JsonSerializerSettings> ConfigureJsonSerializerSettings { get; set; } /// <summary> /// Whether storage string payload should be formatted in Xml. /// <remarks>If neither <see cref=\"UseJsonFormat\"/> nor <see cref=\"UseXmlFormat\"/> is set to true, then BinaryFormatSerializer will be configured to format storage string payload.</remarks> /// </summary> public bool UseXmlFormat { get; set; } } /// </summary> [Redact] public string ConnectionString { get; set; } /// <summary> /// Set the stage of the silo lifecycle where storage should be initialized. Storage must be initialized prior to use. /// </summary> public int InitStage { get; set; } = DEFAULT_INIT_STAGE; /// <summary> /// Default init stage in silo lifecycle. /// </summary> public const int DEFAULT_INIT_STAGE = ServiceLifecycleStage.ApplicationServices; /// <summary> /// The default ADO.NET invariant will be used for storage if none is given. /// </summary> public const string DEFAULT_ADONET_INVARIANT = AdoNetInvariants.InvariantNameSqlServer; /// <summary> /// Define the invariant name for storage. /// </summary> public string Invariant { get; set; } = DEFAULT_ADONET_INVARIANT; /// <summary> /// Determine whether the storage string payload should be formatted in JSON. /// <remarks>If neither <see cref=\"UseJsonFormat\"/> nor <see cref=\"UseXmlFormat\"/> is set to true, then BinaryFormatSerializer will be configured to format the storage string payload.</remarks> /// </summary> public bool UseJsonFormat { get; set; } public bool UseFullAssemblyNames { get; set; } public bool IndentJson { get; set; } public TypeNameHandling? TypeNameHandling { get; set; } public Action<JsonSerializerSettings> ConfigureJsonSerializerSettings { get; set; } /// <summary> /// Determine whether storage string payload should be formatted in Xml. /// <remarks>If neither <see cref=\"UseJsonFormat\"/> nor <see cref=\"UseXmlFormat\"/> is set to true, then BinaryFormatSerializer will be configured to format storage string payload.</remarks> /// </summary> public bool UseXmlFormat { get; set; } } 这个ADO.NETpersistence具有版本数据和使用任意应用程序规则和流定义任意(反)序列化程序的功能，但目前还没有将它们公开给应用程序代码的方法。 ADO.NET持久化原理 原则ADO.NET支持的持久化存储包括： 在数据、数据格式和代码不断发展的同时，保持业务关键数据的安全性。 利用特定于供应商和存储的功能。 实际上，这意味着要坚持ADO.NET中的实现目标和一些添加的实现逻辑ADO.NET允许改变存储器中数据形状的特定存储提供程序。 除了通常的存储提供程序功能之外ADO.NET提供程序的内置功能 在往返状态下，将存储数据格式从一种格式更改为另一种格式(例如从JSON更改为二进制)。 以任意方式塑造要保存或从存储器中读取的类型。 这有助于改进版本状态。 从数据库中流出数据。 两者兼而有之 1 和 2 可以应用于任意决策参数，例如 grains id , grains type , payload data . 简单二进制编码(SBE) 和工具 IStorageDeserializer 和 IStorageSerializer . 内置序列化程序是使用此方法生成的。 The built-in serializers have been built using this method. 这个 OrleanStorageDefault(反)序列化程序 可以作为如何实现其他格式的示例。 实现序列化程序后，需要将它们添加到 StorageSerializationPicker 中的属性 AdoNetGrainStorage . 这是一个 IStorageSerializationPicker . 默认情况下 StorageSerializationPicker 将被使用。 Here is an implementation of IStorageSerializationPicker . By default, StorageSerializationPicker will be used. 更改数据存储格式或使用序列化程序的示例可以在 关系存储测试 . 目前还没有方法将其公开给Orleans应用程序使用，因为没有方法访问所创建的框架 AdoNetGrainStorage . 设计目标 1. 1. 允许使用任何具有ADO.NET供应商 这应该包括.NET可用的最广泛的后端集，这是本地安装的一个因素。 一些提供商列在 ADO.NET数据提供程序MSDN页 ，但为了说明，并不是所有的都列出来了，比如 Teradata . 2. 2. 即使在部署正在运行时，也要保持适当地优化查询和数据库结构的潜力 在许多情况下，服务器和数据库由与客户端有合同关系的第三方托管。 由于虚拟化环境的不可预见性和不可预见性等因素，虚拟化环境下的主机性能是不可预见的。 可能无法更改和重新部署Orleans二进制文件(合同原因)甚至应用程序二进制文件，但通常可以调整数据库部署。 改变 标准部件 ，例如Orleans二进制文件，需要一个更长的过程来确定在给定的情况下可以提供什么。 3. 3. 允许使用供应商和版本特定的能力 供应商在他们的产品中实现了不同的扩展和特性。 当这些功能可用时，使用它们是明智的。 这些功能包括 本地UPSERT 或 管道数据库 在PostgreSQL中， 多基 或 本机编译的表和存储过程 在SQL Server中–以及无数其他功能。 4. 4. 使硬件资源优化成为可能 在设计应用程序时，通常可以预测哪些数据需要比其他数据更快地插入，哪些数据更有可能被放入 冷库 哪种更便宜(例如在SSD和HDD之间拆分数据)。 例如，进一步的考虑因素是某些数据的物理位置可能更昂贵(例如SSD RAID viz HDD RAID)、更安全或使用一些其他决策属性。 与…有关*第三点。 *有些数据库提供特殊的分区方案，如sqlserver 分区表和索引 . 这一原则也适用于整个应用程序生命周期。 考虑到Orleans本身的一个原则是高可用性系统，因此应该可以在不中断Orleans部署的情况下调整存储系统，或者可以根据数据和其他应用程序参数调整查询。 变化的一个例子是布莱恩·哈里的 博客文章 : 当表很小时，查询计划是什么几乎无关紧要。 当它是中等的时候，一个好的查询计划是好的。 当它是巨大的(数以百万计或数十亿行)时，查询计划中的微小变化可能会杀死您。 因此，我们对敏感查询进行了大量提示。 5. 5. 对组织中使用的工具、库或部署过程没有任何假设 许多组织都熟悉某种数据库工具，例如 Dacpac 或 Red Gate . 部署数据库可能需要权限或人员(例如DBA角色中的人员)来执行此操作。 It may be that deploying a database requires either a permission or a person, such as someone in a DBA role, to do it. 通常这意味着还要有目标数据库布局和应用程序将对数据库产生的查询的粗略草图来估计负载。 可能有一些流程，可能受行业标准的影响，强制要求基于脚本的部署。 将查询和数据库结构放在一个外部脚本中使这成为可能。 6. 6. 使用接口功能所需的最小集来加载ADO.NET库和功能 这是既快又较少暴露ADO.NET库的实现细节。 7. Make the design shardable 当它有意义时，例如在关系存储提供程序中，使设计易于共享。 这意味着没有依赖于数据库的数据(例如。 Identity )基本上，这意味着区分行数据的信息应该只建立在数据和实际参数的基础上。 8. 8. 使设计易于测试 理想情况下，创建一个新的后端应该像翻译一个部署脚本和向测试添加一个新的连接字符串一样简单，假设默认参数，检查是否安装了给定的数据库，然后对其运行测试。 9. 9. 考虑到前面几点，使新后端的移植脚本和修改已部署的后端脚本尽可能透明 目标的实现 Orleans framework不了解特定于部署的硬件(在主动部署期间可能会发生变化)、部署生命周期中的数据更改以及某些特定于供应商的特性仅在某些情况下可用。 因此，关系数据库和Orleans之间的接口应该遵循一组最小的抽象和规则，以满足目标，但也要使其健壮，防止误用，并在需要时易于测试。 运行时表、集群管理和具体的 成员协议实现 . 此外，SQL Server实现包含SQL Server版本特定的调整。 Also, the SQL Server implementation contains SQL Server edition-specific tuning. 数据库与Orleans的接口合同定义如下： 总的想法是通过Orleans特定的查询来读写数据。 Orleans在读取时操作列名和类型，在写入时操作参数名称和类型。 实施 必须 保留输入和输出名称和类型。 Orleans使用这些参数按名称和类型读取查询结果。 只要保持接口契约，就允许进行特定于供应商和部署的调优，并鼓励贡献。 跨供应商特定脚本的实现 应该 保留约束名称。 这通过跨具体实现的统一命名简化了故障排除。 版本 –或 ETag 应用程序代码中–因为Orleans代表了一个独特的版本。 它实际实现的类型并不重要，只要它代表一个唯一的版本。 在实现中，Orleans代码需要一个有符号的32位整数。 为了明确和消除歧义，Orleans希望一些查询返回 TRUE as > 0 值或 False as=0 价值观。 也就是说，受影响的行或类似的行并不重要。 如果引发错误或引发异常，则查询 必须 确保整个事务被回滚，并且可能返回FALSE或传播异常。 目前除了一个查询外，所有查询都是单行插入或更新(注意，一个可以替换 Update 查询 Insert 他们提供了 Select 查询将提供最后一次写入)统计插入除外。 数据库引擎支持数据库编程，这类似于加载可执行脚本并调用它来执行数据库操作的思想。 This is similar to the idea of loading an executable script and invoking it to execute database operations. 在伪代码中，它可以描述为 const int Param1 = 1; const DateTime Param2 = DateTime.UtcNow; const string queryFromOrleansQueryTableWithSomeKey = \"SELECT column1, column2 FROM <some Orleans table> where column1 = @param1 AND column2 = @param2;\"; TExpected queryResult = SpecificQuery12InOrleans<TExpected>(query, Param1, Param2); 这些原则也是 包含在数据库脚本中 . 应用定制脚本的几点思考 更改 OrleansQuery 中脚本的 IF ELSE ，以便Grains的持久化使用默认值保存某些状态 插入 ,例如，一些Grains状态使用， 内存优化表 . 这个 SELECT 查询需要相应地修改。 The SELECT queries need to be altered accordingly. 这个想法 1 可用于利用其他部署或特定于供应商的方面。 例如在 SSD 或 HDD ，将一些数据放在加密的表上，或者通过sqlserver将统计数据插入Hadoop，甚至 链接服务器 . 修改后的脚本可以通过运行Orleans测试套件或直接在数据库中测试，例如， SQL Server单元测试项目 . 添加新的ADO.NET供应商指南 根据 目标的实现 以上章节。 将供应商ADO不变名称添加到 ADO变量 以及ADO.NET提供程序特定数据 DbConstantStore . 它们(可能)用于某些查询操作。 These are (potentially) used in some query operations. e、 g.选择正确的统计插入模式(即 Union All 有或没有 FROM DUAL ). Orleans对所有系统商店都有全面的测试：会员资格、提醒和统计数据。 为新数据库脚本添加测试是通过复制粘贴现有测试类和更改ADO不变名来完成的。 同样，从 关系存储测试 以定义ADOInvariant的测试功能。"
  },
  "docs/grains/grain_placement.html": {
    "href": "docs/grains/grain_placement.html",
    "title": "Grain Placement | Microsoft Orleans Documentation",
    "keywords": "Grain Placement When a grain is activated in Orleans, the runtime decides which server (silo) to activate that grain on. This is called grain placement. The placement process in Orleans is fully configurable: developers can choose from a set of out-of-the-box placement policies such as random, prefer-local, and load-based, or custom logic can be configured. This allows for full flexibility in deciding where grains are created. For example, grains can be placed on a server close to resources which they need to operate on or close to other grains which they communicate with. Sample custom placement strategy First define a class which implements IPlacementDirector interface, requiring a single method. In this example we assume you have a function GetSiloNumber defined which will return a silo number given the guid of the grain about to be created. public class SamplePlacementStrategyFixedSiloDirector : IPlacementDirector { public Task<SiloAddress> OnAddActivation(PlacementStrategy strategy, PlacementTarget target, IPlacementContext context) { var silos = context.GetCompatibleSilos(target).OrderBy(s => s).ToArray(); int silo = GetSiloNumber(target.GrainIdentity.PrimaryKey, silos.Length); return Task.FromResult(silos[silo]); } } You then need to define two classes to allow grain classes to be assigned to the strategy: [Serializable] public class SamplePlacementStrategy : PlacementStrategy { } [AttributeUsage(AttributeTargets.Class, AllowMultiple = false)] public sealed class SamplePlacementStrategyAttribute : PlacementAttribute { public SamplePlacementStrategyAttribute() : base(new SamplePlacementStrategy()) { } } Then just tag any grain classes you want to use this strategy with the attribute: [SamplePlacementStrategy] public class MyGrain : Grain, IMyGrain { ... } And finally register the strategy when you build the SiloHost: private static async Task<ISiloHost> StartSilo() { ISiloHostBuilder builder = new SiloHostBuilder() // normal configuration methods omitted for brevity .ConfigureServices(ConfigureServices); var host = builder.Build(); await host.StartAsync(); return host; } private static void ConfigureServices(IServiceCollection services) { services.AddSingletonNamedService<PlacementStrategy, SamplePlacementStrategy>(nameof(SamplePlacementStrategy)); services.AddSingletonKeyedService<Type, IPlacementDirector, SamplePlacementStrategyFixedSiloDirector>(typeof(SamplePlacementStrategy)); } For a second simple example showing further use of the placement context, refer to the PreferLocalPlacementDirector in the Orleans source repo"
  },
  "docs/grains/grain_versioning/backward_compatibility_guidelines.html": {
    "href": "docs/grains/grain_versioning/backward_compatibility_guidelines.html",
    "title": "向后兼容准则 | Microsoft Orleans Documentation",
    "keywords": "向后兼容准则 编写向后兼容的代码可能很难测试。 永远不要更改现有方法的签名 由于Orleans序列化程序的工作方式，您永远不应该更改现有方法的签名。 以下示例是正确的： [Version(1)] public interface IMyGrain : IGrainWithIntegerKey { // First method Task MyMethod(int arg); } [Version(2)] public interface IMyGrain : IGrainWithIntegerKey { // Method inherited from V1 Task MyMethod(int arg); // New method added in V2 Task MyNewMethod(int arg, obj o); } 这是不正确的： [Version(1)] public interface IMyGrain : IGrainWithIntegerKey { // First method Task MyMethod(int arg); } [Version(2)] public interface IMyGrain : IGrainWithIntegerKey { // Method inherited from V1 Task MyMethod(int arg, obj o); } 注意 ：您不应在代码中进行此更改，因为这是导致非常糟糕的副作用的不良实践的示例。 这是一个如果您只重命名参数名会发生什么的示例：假设我们在集群中部署了以下两个接口版本： [Version(1)] public interface IMyGrain : IGrainWithIntegerKey { // return a - b Task<int> Substract(int a, int b); } [Version(2)] public interface IMyGrain : IGrainWithIntegerKey { // return y - x Task<int> Substract(int y, int x); } 这种方法似乎是相同的。 但是，如果使用V1调用客户端，并且请求由V2激活处理： var grain = client.GetGrain<IMyGrain>(0); var result = await grain.Substract(5, 4); // Will return \"-1\" instead of expected \"1\" 这是由于内部Orleans序列化程序是如何工作的。 避免改变现有的方法逻辑 这看起来很明显，但是在更改现有方法的主体时应该非常小心。 除非您正在修复一个bug，否则如果您需要修改代码，最好只添加一个新方法。 例子： // V1 public interface MyGrain : IMyGrain { // First method Task MyMethod(int arg) { SomeSubRoutine(arg); } } // V2 public interface MyGrain : IMyGrain { // Method inherited from V1 // Do not change the body Task MyMethod(int arg) { SomeSubRoutine(arg); } // New method added in V2 Task MyNewMethod(int arg) { SomeSubRoutine(arg); NewRoutineAdded(arg); } } 不要从grain接口删除方法 除非确定不再使用这些方法，否则不应从grain接口中删除方法。 如果要删除方法，应该分两步完成：1。 当您确定没有进行V1调用时(实际上V1不再部署在正在运行的集群中)，则在部署V3时删除V1方法 [Version(3)] public interface IMyGrain : IGrainWithIntegerKey { // New method added in V2 Task MyNewMethod(int arg, obj o); } [Version(2)] public interface IMyGrain : IGrainWithIntegerKey { // Method inherited from V1 [Obsolete] Task MyMethod(int arg); // New method added in V2 Task MyNewMethod(int arg, obj o); } When you are sure that no V1 calls are made (effectively V1 is no longer deployed in the running cluster), deploy V3 with V1 method removed [Version(3)] public interface IMyGrain : IGrainWithIntegerKey { // New method added in V2 Task MyNewMethod(int arg, obj o); }"
  },
  "docs/grains/grain_versioning/compatible_grains.html": {
    "href": "docs/grains/grain_versioning/compatible_grains.html",
    "title": "兼容Grains | Microsoft Orleans Documentation",
    "keywords": "兼容Grains 当现有的Grains激活将要处理请求时，运行时将检查请求中的版本与Grains的实际版本是否兼容。 Orleans不会在运行时推断要使用哪个策略 ，确定两个版本是否兼容的默认行为由 GrainVersioningOptions.CompatibilityStrategy 向后兼容(默认) 定义 如果满足以下条件，则Grain接口版本Vn可以与Vm向后兼容： 接口名称未更改(或覆盖的类型代码) Vm版本中存在的所有公共方法都在Vn版本中。 **重要的是，不要修改从Vm继承的方法的签名。 **：由于Orleans使用内部内置的序列化程序，因此修改/重命名字段(甚至私有)可能会使序列化中断。 由于Vn与Vm相比可以增加其他方法，因此Vm与Vn不兼容。 例 如果在集群中，给定接口有两个版本，即V1和V2，并且该V2向后兼容V1： 如果当前激活为V2，而请求的版本为V1，则当前激活将能够正常处理请求 如果当前激活为V1，而请求的版本为V2，则将取消激活当前激活，并创建与V2兼容的新激活(请参见 版本选择器策略 )。 完全兼容 定义 如果满足以下条件，则Grains接口版本Vn可以与Vm完全兼容： Vn与Vm向后兼容 在Vn版本中未添加任何公共方法 如果Vn与Vm完全兼容，则Vm也与Vn完全兼容。 例 如果在集群中，给定接口有两个版本，即V1和V2，并且该V2与V1完全兼容： 如果当前激活为V2，而请求的版本为V1，则当前激活将能够正常处理请求 如果当前激活为V1，而请求的版本为V2，则当前激活也将能够正常处理请求"
  },
  "docs/grains/grain_versioning/deploying_new_versions_of_grains.html": {
    "href": "docs/grains/grain_versioning/deploying_new_versions_of_grains.html",
    "title": "部署新版本的Grains | Microsoft Orleans Documentation",
    "keywords": "部署新版本的Grains 滚动升级 通过这种方法，您可以直接在环境中部署较新的Silo。 这是最简单的方法，但是可能很难中断正在进行的部署并回滚。 推荐配置： DefaultCompatibilityStrategy 调成 BackwardCompatible DefaultVersionSelectorStrategy 调成 AllCompatibleVersions var silo = new SiloHostBuilder() [...] var silo = new SiloHostBuilder() [...] .Configure<GrainVersioningOptions>(options => { options.DefaultCompatibilityStrategy = nameof(BackwardCompatible); options.DefaultVersionSelectorStrategy = nameof(AllCompatibleVersions); }) [...] 使用此配置时，“旧”客户端将能够与两个版本的silos上的激活进行对话。 较新的客户端和silos只会在较新的silos上触发新的激活。 使用预生产环境 在这种方法中，您将需要第二个环境(预生产环境)，在该环境中您将在停止生产环境之前部署较新的Silo。 生产和预生产Silos和客户端将作为 同一集群的一部分 。 两个环境中的silos可以相互通信，这一点很重要。 推荐配置： DefaultCompatibilityStrategy 调成 BackwardCompatible DefaultVersionSelectorStrategy 调成 MinimumVersion var silo = new SiloHostBuilder() [...] var silo = new SiloHostBuilder() [...] .Configure<GrainVersioningOptions>(options => { options.DefaultCompatibilityStrategy = nameof(BackwardCompatible); options.DefaultVersionSelectorStrategy = nameof(MinimumVersion); }) [...] 建议的部署步骤： “V1” silos和客户端已部署并正在生产插槽中运行。 “V2” silos和客户端开始在预生产插槽中启动。 他们将与生​​产广告位加入同一集群。 到目前为止，将不会创建“V2”激活。 在预生产插槽中的部署完成后，开发人员可以重定向V2客户端上的某些流量(烟雾测试，目标Beta用户等)。 这将创建V2激活，但是由于Grains是向后兼容的，并且所有Silo都在同一集群中，因此不会创建重复的激活。 如果验证成功，请继续进行VIP交换。 如果没有，您可以安全地关闭预生产群集：如果需要，现有的V2激活将被销毁，而V1激活将被创建。 V1激活自然会最终“迁移”到V2 Silo。 您可以安全地关闭V1 silos。 [！ 警告!]请记住，无状态工作器没有版本控制，流代理也将在预生产环境中启动。"
  },
  "docs/grains/grain_versioning/grain_versioning.html": {
    "href": "docs/grains/grain_versioning/grain_versioning.html",
    "title": "grains接口版本控制 | Microsoft Orleans Documentation",
    "keywords": "grains接口版本控制 [!警告]本页介绍如何使用Grain接口版本控制。 Grain状态的版本控制超出范围。 概述 在给定的集群上，silos可以支持不同版本的Grains类型。 在本例中，客户端和silos{1,2,3}是用grain接口编译的 A 版本1。 silos4是用 A 版本2。 限制： 无状态工作进程 流接口没有版本控制 启用版本控制 默认情况下，不会对grains进行版本控制。 您可以使用grain接口上的VersionAttribute来设置grain版本： [Version(X)] public interface IVersionUpgradeTestGrain : IGrainWithIntegerKey {} 十 是grains接口的版本号，通常单调递增。 grains版本兼容性和存储 当来自版本控制的grain的调用到达集群时： 如果不存在激活，将创建兼容的激活 如果激活存在： 如果当前的不兼容，它将被停用并创建新的兼容的(请参阅 版本选择器策略 ) 如果当前版本兼容(请参见 相容grains )，访问将正常处理。 默认情况下： 所有版本化的grains只能向后兼容(参见 向后兼容准则 和 相容grains ). 这意味着v1grains可以调用v2grains，但v2grains不能调用v1。 That means that a v1 grain can make calls to a v2 grain, but a v2 grain cannot call a v1. 当集群中存在多个版本时，新的激活将随机存储在兼容的silos上。 您可以通过选项更改此默认行为 GrainVersioning选项 : var silo = new SiloHostBuilder() [...] var silo = new SiloHostBuilder() [...] .Configure<GrainVersioningOptions>(options => { options.DefaultCompatibilityStrategy = nameof(BackwardCompatible); options.DefaultVersionSelectorStrategy = nameof(MinimumVersion); }) [...]"
  },
  "docs/grains/grain_versioning/version_selector_strategy.html": {
    "href": "docs/grains/grain_versioning/version_selector_strategy.html",
    "title": "版本选择器策略 | Microsoft Orleans Documentation",
    "keywords": "版本选择器策略 当集群中存在相同grains接口的多个版本，并且必须创建新的激活时， 兼容版本 将根据中定义的策略进行选择 GrainVersioningOptions.DefaultVersionSelectorStrategy 。 开箱即用的Orleans支持以下策略： 所有兼容版本(默认) 使用此策略，将在所有兼容版本中随机选择新激活的版本。 例如，如果我们有给定的grains接口的两个版本，即V1和V2： V2与V1向后兼容 集群中有2个支持V2的silos，有8个支持V1的silos 该请求是从V1客户/silos发出的 在这种情况下，新激活将有20％的机会成为V2，而有80％的机会将是V1。 最新版本 使用此策略，新激活的版本将始终是最新的兼容版本。 例如，如果我们有给定的grains接口的两个版本，即V1和V2(V2向后或与V1完全兼容)，则所有新激活将为V2。 最低版本 使用此策略，新激活的版本将始终是请求的版本或最低兼容版本。 例如，如果给定的Grain接口有2个版本，即V2，V3，则所有版本都完全兼容： 如果请求是从V1客户端/silos发出的，则新的激活将是V2 如果请求是从V3客户端/silos发出的，则新的激活也将是V2"
  },
  "docs/grains/grainservices.html": {
    "href": "docs/grains/grainservices.html",
    "title": "GrainServices | Microsoft Orleans Documentation",
    "keywords": "GrainServices GrainService是一种特殊的Grains。 一个没有身份的，并且从启动到关闭都在每个silos中运行的程序。 创建一个GrainService **第1步。 **创建接口。 GrainService的接口是使用与构建其他任何grain的接口完全相同的原理构建的。 public interface IDataService : IGrainService { Task MyMethod(); } **第2步。 **创建DataService本身。 如果可能，使GrainServiceReentrant以获得更好的性能。 注意必要的基本构造函数调用。 很高兴知道您也可以注入 IGrainFactory 因此您可以从GrainService进行Grains调用。 关于流的说明：GrainService无法在Orleans流中写入，因为它在Grain Task Scheduler中不起作用。 如果您需要GrainService为您写入流，则必须将对象发送到另一种Grains以写入流。 [Reentrant] public class LightstreamerDataService : GrainService, IDataService { readonly IGrainFactory GrainFactory; public LightstreamerDataService(IServiceProvider services, IGrainIdentity id, Silo silo, ILoggerFactory loggerFactory, IGrainFactory grainFactory) : base(id, silo, loggerFactory) { GrainFactory = grainFactory; } public override Task Init(IServiceProvider serviceProvider) { return base.Init(serviceProvider); } public override async Task Start() { await base.Start(); } public override Task Stop() { return base.Stop(); } public Task MyMethod() { } } 第三步 为GrainServiceClient创建一个接口，供其他Grains使用以连接到GrainService。 public interface IDataServiceClient : IGrainServiceClient<IDataService>, IDataService { } **第4步。 **创建实际的Grains服务客户端。 它几乎只是充当数据服务的代理。 不幸的是，您必须手动输入所有方法映射，它们只是简单的一列式。 public class DataServiceClient : GrainServiceClient<IDataService>, IDataServiceClient { public DataServiceClient(IServiceProvider serviceProvider) : base(serviceProvider) { } public Task MyMethod() => GrainService.MyMethod(); } 第五步 将Grains服务客户端注入需要它的其他Grains中。 注意，GrainServiceClient不保证访问本地silos上的GrainService。 您的命令可能会发送到集群中任何silos上的GrainService。 public class MyNormalGrain: Grain<NormalGrainState>, INormalGrain { readonly IDataServiceClient DataServiceClient; public MyNormalGrain(IGrainActivationContext grainActivationContext, IDataServiceClient dataServiceClient) { DataServiceClient = dataServiceClient; } } 第六步 将grain服务注入Silo本身。 您需要执行此操作，以便silos将启动GrainService。 (ISiloHostBuilder builder) => builder .ConfigureServices(services => { services.AddSingleton<IDataService, DataService>(); }); 补充笔记 ###注1 有一个扩展方法 ISiloHostBuilder：AddGrainService <SomeGrainService>() 。 类型约束是： 其中T：GrainService 。 最终调用此位： orleans / src / Orleans.Runtime / Services / GrainServicesSiloBuilderExtensions.cs 返回服务。 AddSingleton <IGrainService>(sp => GrainServiceFactory(grainServiceType，sp)); Basically, the silo fetches IGrainService types from the service provider when starting: orleans/src/Orleans.Runtime/Silo/Silo.cs var grainServices = this.Services.GetServices<IGrainService>(); 基本上，silos取 IGrain服务 启动时来自服务提供商的类型： orleans / src / Orleans.Runtime / Silo / Silo.cs var grainServices = this.Services.GetServices <IGrainService>(); ＃＃＃笔记2 为了使其正常工作，您必须注册服务及其客户端。 代码看起来像这样： var builder = new SiloHostBuilder() .AddGrainService<DataService>() // Register GrainService .ConfigureServices(s => { // Register Client of GrainService s.AddSingleton<IDataServiceClient, DataServiceClient>(); })"
  },
  "docs/grains/index.html": {
    "href": "docs/grains/index.html",
    "title": "Persistence | Microsoft Orleans Documentation",
    "keywords": "持久化 Before you write code to implement a grain class, create a new Class Library project targeting .NET Standard or .Net Core (preferred) or .NET Framework 4.6.1 or higher (if you cannot use .NET Standard or .NET Core due to dependencies). Grain interfaces and grain classes can be defined in the same Class Library project, or in two different projects for better separation of interfaces from implementation. In either case, the projects need to reference Microsoft.Orleans.Core.Abstractions and Microsoft.Orleans.CodeGenerator.MSBuild NuGet packages. For more thorough instructions, see the Project Setup section of Tutorial One – Orleans Basics . Grain Interfaces and Classes Grains interact with each other and get called from outside by invoking methods declared as part of the respective grain interfaces. A grain class implements one or more previously declared grain interfaces. All methods of a grain interface must return a Task (for void methods), a Task<T> or a ValueTask<T> (for methods returning values of type T ). The following is an excerpt from the Orleans version 1.5 Presence Service sample: //an example of a Grain Interface public interface IPlayerGrain : IGrainWithGuidKey { Task<IGameGrain> GetCurrentGame(); Task JoinGame(IGameGrain game); Task LeaveGame(IGameGrain game); } //an example of a Grain class implementing a Grain Interface public class PlayerGrain : Grain, IPlayerGrain { private IGameGrain currentGame; // Game the player is currently in. May be null. public Task<IGameGrain> GetCurrentGame() { return Task.FromResult(currentGame); } // Game grain calls this method to notify that the player has joined the game. public Task JoinGame(IGameGrain game) { currentGame = game; Console.WriteLine( \"Player {0} joined game {1}\", this.GetPrimaryKey(), game.GetPrimaryKey()); return Task.CompletedTask; } // Game grain calls this method to notify that the player has left the game. public Task LeaveGame(IGameGrain game) { currentGame = null; Console.WriteLine( \"Player {0} left game {1}\", this.GetPrimaryKey(), game.GetPrimaryKey()); return Task.CompletedTask; } } Returning Values from Grain Methods A grain method that returns a value of type T is defined in a grain interface as returning a Task<T> . For grain methods not marked with the async keyword, when the return value is available, it is usually returned via the following statement: public Task<SomeType> GrainMethod1() { ... return Task.FromResult(<variable or constant with result>); } A grain method that returns no value, effectively a void method, is defined in a grain interface as returning a Task . The returned Task indicates asynchronous execution and completion of the method. For grain methods not marked with the async keyword, when a \"void\" method completes its execution, it needs to return the special value of Task.CompletedTask : public Task GrainMethod2() { ... return Task.CompletedTask; } 即使它们是同一类型，不同的Grain类型也可以使用不同的配置存储提供程序：例如，两个不同的Azure Table Storage提供程序实例连接到不同的Azure存储帐户。 public async Task<SomeType> GrainMethod3() { ... return <variable or constant with result>; } 当激活grains时，将自动读取grains状态，但是grains负责在必要时显式触发任何更改的grains状态的写入。 public async Task GrainMethod4() { ... return; } If a grain method receives the return value from another asynchronous method call, to a grain or not, and doesn't need to perform error handling of that call, it can simply return the Task it receives from that asynchronous call: public Task<SomeType> GrainMethod5() { ... Task<SomeType> task = CallToAnotherGrain(); return task; } Similarly, a \"void\" grain method can return a Task returned to it by another call instead of awaiting it. public Task GrainMethod6() { ... Task task = CallToAsyncAPI(); return task; } ValueTask<T> can be used instead of Task<T> 读取状态 A Grain Reference is a proxy object that implements the same grain interface as the corresponding grain class. It encapsulates the logical identity (type and unique key) of the target grain. A grain reference is used for making calls to the target grain. Each grain reference is to a single grain (a single instance of the grain class), but one can create multiple independent references to the same grain. Since a grain reference represents the logical identity of the target grain, it is independent from the physical location of the grain, and stays valid even after a complete restart of the system. Developers can use grain references like any other .NET object. It can be passed to a method, used as a method return value, etc., and even saved to persistent storage. A grain reference can be obtained by passing the identity of a grain to the GrainFactory.GetGrain<T>(key) method, where T is the grain interface and key is the unique key of the grain within the type. 见 失败模式 以下部分提供了有关错误处理机制的详细信息。 From inside a grain class: public class UserGrain : Grain, IUserGrain { private readonly IPersistentState<ProfileState> _profile; public UserGrain([PersistentState(\"profile\", \"profileStore\")] IPersistentState<ProfileState> profile) { _profile = profile; } public Task<string> GetNameAsync() => Task.FromResult(_profile.State.Name); public async Task SetNameAsync(string name) { _profile.State.Name = name; await _profile.WriteStateAsync(); } } 在Grains可以使用持久化之前，必须在silos上配置存储提供程序。 [StorageProvider(ProviderName=\"store1\")] public class MyGrain : Grain<MyGrainState>, /*...*/ { /*...*/ } 写入状态 首先，配置存储提供程序： 现在，已经使用名称配置了存储提供程序 “ profileStore” ，我们可以从Grains访问此提供程序。 //Invoking a grain method asynchronously Task joinGameTask = player.JoinGame(this); //The await keyword effectively makes the remainder of the method execute asynchronously at a later point (upon completion of the Task being awaited) without blocking the thread. await joinGameTask; //The next line will execute later, after joinGameTask has completed. players.Add(playerId); It is possible to join two or more Tasks ; the join operation creates a new Task that is resolved when all of its constituent Task s are completed. This is a useful pattern when a grain needs to start multiple computations and wait for all of them to complete before proceeding. For example, a front-end grain that generates a web page made of many parts might make multiple back-end calls, one for each part, and receive a Task for each result. The grain would then await the join of all of these Tasks ; when the join Task is resolved, the individual Task s have been completed, and all the data required to format the web page has been received. Example: List<Task> tasks = new List<Task>(); Message notification = CreateNewMessage(text); foreach (ISubscriber subscriber in subscribers) { tasks.Add(subscriber.Notify(notification)); } // WhenAll joins a collection of tasks, and returns a joined Task that will be resolved when all of the individual notification Tasks are resolved. Task joinedTask = Task.WhenAll(tasks); await joinedTask; // Execution of the rest of the method will continue asynchronously after joinedTask is resolve. 状态清理 A grain class can optionally override OnActivateAsync and OnDeactivateAsync virtual methods; these are invoked by the Orleans runtime upon activation and deactivation of each grain of the class. This gives the grain code a chance to perform additional initialization and cleanup operations. 该状态将在 OnActivateAsync 调用。 While OnActivateAsync , if overridden, is always called as part of the grain activation process, OnDeactivateAsync is not guaranteed to get called in all situations, for example, in case of a server failure or other abnormal event. Because of that, applications should not rely on OnDeactivateAsync for performing critical operations such as persistence of state changes. They should use it only for best-effort operations."
  },
  "docs/grains/interceptors.html": {
    "href": "docs/grains/interceptors.html",
    "title": "Grain Call Filters | Microsoft Orleans Documentation",
    "keywords": "Grain Call Filters Grains调用过滤器提供了一种拦截Grains调用的方法。 筛选器可以在Grains调用之前和之后执行代码。 可以同时安装多个过滤器。 过滤器是异步的，可以修改 RequestContext ，参数和被调用方法的返回值。 过滤器还可以检查 方法信息 可以在Grain类上调用的方法，可用于引发或处理异常。 Grain调用过滤器的一些示例用法是： 授权：过滤器可以检查正在调用的方法以及其中的参数或某些授权信息 RequestContext 确定是否允许呼叫继续进行。 记录/遥测：过滤器可以记录信息并捕获计时数据和有关方法调用的其他统计信息。 错误处理：过滤器可以拦截方法调用引发的异常，并将其转换为另一个异常，或者在通过过滤器时处理该异常。 过滤器有两种口味： 访问过滤 呼出调用过滤器 收到呼叫时，将执行传入呼叫过滤器。 拨调用时执行呼出调用过滤器。 访问过滤 传入的Grain调用过滤器实现了 IIncomingGrainCallFilter 接口，它具有一种方法： public interface IIncomingGrainCallFilter { Task Invoke(IIncomingGrainCallContext context); } 的 IIncomingGrainCallContext 参数传递给 Invoke 方法具有以下形状： public interface IIncomingGrainCallContext { /// <summary> /// Gets the grain being invoked. /// </summary> IAddressable Grain { get; } /// <summary> /// Gets the <see cref=\"MethodInfo\"/> for the interface method being invoked. /// </summary> MethodInfo InterfaceMethod { get; } /// <summary> /// Gets the <see cref=\"MethodInfo\"/> for the implementation method being invoked. /// </summary> MethodInfo ImplementationMethod { get; } /// <summary> /// Gets the arguments for this method invocation. /// </summary> object[] Arguments { get; } /// <summary> /// Invokes the request. /// </summary> Task Invoke(); /// <summary> /// Gets or sets the result. /// </summary> object Result { get; set; } } public interface IOutgoingGrainCallContext { /// <summary> /// Gets the grain being invoked. /// </summary> IAddressable Grain { get; } /// <summary> /// Gets the <see cref=\"MethodInfo\"/> for the interface method being invoked. /// </summary> MethodInfo InterfaceMethod { get; } /// <summary> /// Gets the arguments for this method invocation. /// </summary> object[] Arguments { get; } /// <summary> /// Invokes the request. /// </summary> Task Invoke(); /// <summary> /// Gets or sets the result. /// </summary> object Result { get; set; } } /// </summary> MethodInfo InterfaceMethod { get; } /// <summary> /// Gets the <see cref=\"MethodInfo\"/> for the implementation method being invoked. /// </summary> MethodInfo ImplementationMethod { get; } /// <summary> /// Gets the arguments for this method invocation. /// </summary> object[] Arguments { get; } /// <summary> /// Invokes the request. /// </summary> Task Invoke(); /// <summary> /// Gets or sets the result. /// </summary> object Result { get; set; } } 的 IIncomingGrainCallFilter.Invoke(IIncomingGrainCallContext) 方法必须等待或返回的结果 IIncomingGrainCallContext.Invoke() 执行下一个配置的过滤器，最终执行grain方法本身。 的 Result 可以在等待 Invoke() 方法。 ImplementationMethod 属性返回 MethodInfo 实现类。 获取 MethodInfo 可以使用 InterfaceMethod 属性。 对于所有对Grains的方法调用，都会调用Grains调用过滤器，其中包括对Grains扩展的调用( IGrain扩展 )安装在Grains中。 例如，grains扩展用于实现流和取消令牌。 因此，应该期望 ImplementationMethod 在Grains类本身中并不总是一种方法。 配置传入呼叫过滤器 的实现 IIncomingGrainCallFilter 可以通过Dependency Injection注册为silos级过滤器，也可以通过Grains实现将其注册为grains级过滤器 IIncomingGrainCallFilter 直。 silos范围内的所有访问过滤器 可以使用Dependency Injection将委托注册为silos级的Grain调用过滤器，如下所示： siloHostBuilder.AddIncomingGrainCallFilter(async context => { // If the method being called is 'MyInterceptedMethod', then set a value // on the RequestContext which can then be read by other filters or the grain. if (string.Equals(context.InterfaceMethod.Name, nameof(IMyGrain.MyInterceptedMethod))) { RequestContext.Set(\"intercepted value\", \"this value was added by the filter\"); } await context.Invoke(); // If the grain method returned an int, set the result to double that value. if (context.Result is int resultValue) context.Result = resultValue * 2; }); if (string.Equals(context.InterfaceMethod.Name, nameof(IMyGrain.MyInterceptedMethod))) { RequestContext.Set(\"intercepted value\", \"this value was added by the filter\"); } await context.Invoke(); // If the grain method returned an int, set the result to double that value. if (context.Result is int resultValue) context.Result = resultValue * 2; }); 同样，可以使用 AddIncomingGrainCallFilter 辅助方法。 这是一个grain调用过滤器的示例，它记录每个grain方法的结果： public class LoggingCallFilter : IIncomingGrainCallFilter { private readonly Logger log; public LoggingCallFilter(Factory<string, Logger> loggerFactory) { this.log = loggerFactory(nameof(LoggingCallFilter)); } public async Task Invoke(IIncomingGrainCallContext context) { try { await context.Invoke(); var msg = string.Format( \"{0}.{1}({2}) returned value {3}\", context.Grain.GetType(), context.InterfaceMethod.Name, string.Join(\", \", context.Arguments), context.Result); this.log.Info(msg); } catch (Exception exception) { var msg = string.Format( \"{0}.{1}({2}) threw an exception: {3}\", context.Grain.GetType(), context.InterfaceMethod.Name, string.Join(\", \", context.Arguments), exception); this.log.Info(msg); // If this exception is not re-thrown, it is considered to be // handled by this filter. throw; } } } throw; } } } 然后可以使用 AddIncomingGrainCallFilter 扩展方法： siloHostBuilder.AddIncomingGrainCallFilter<LoggingCallFilter>(); 或者，可以在不使用扩展方法的情况下注册过滤器： siloHostBuilder.ConfigureServices( services => services.AddSingleton<IIncomingGrainCallFilter, LoggingCallFilter>()); 每粒Grains调用过滤器 Grains类可以将自己注册为Grains调用过滤器，并可以通过实现对它的所有调用进行过滤 IIncomingGrainCallFilter 像这样： public class MyFilteredGrain : Grain, IMyFilteredGrain, IIncomingGrainCallFilter { public async Task Invoke(IIncomingGrainCallContext context) { await context.Invoke(); // Change the result of the call from 7 to 38. if (string.Equals(context.InterfaceMethod.Name, nameof(this.GetFavoriteNumber))) { context.Result = 38; } } public Task<int> GetFavoriteNumber() => Task.FromResult(7); } if (string.Equals(context.InterfaceMethod.Name, nameof(this.GetFavoriteNumber))) { context.Result = 38; } } public Task<int> GetFavoriteNumber() => Task.FromResult(7); } 在上面的示例中，对 GetFavoriteNumber 方法将返回 38 代替 7 ，因为返回值已被过滤器更改。 过滤器的另一个用例是在访问控制中，如以下示例所示： [AttributeUsage(AttributeTargets.Method)] public class AdminOnlyAttribute : Attribute { } public class MyAccessControlledGrain : Grain, IMyFilteredGrain, IIncomingGrainCallFilter { public Task Invoke(IIncomingGrainCallContext context) { // Check access conditions. var isAdminMethod = context.ImplementationMethod.GetCustomAttribute<AdminOnlyAttribute>(); if (isAdminMethod && !(bool) RequestContext.Get(\"isAdmin\")) { throw new AccessDeniedException($\"Only admins can access {context.ImplementationMethod.Name}!\"); } return context.Invoke(); } [AdminOnly] public Task<int> SpecialAdminOnlyOperation() => Task.FromResult(7); } var isAdminMethod = context.ImplementationMethod.GetCustomAttribute<AdminOnlyAttribute>(); if (isAdminMethod && !(bool) RequestContext.Get(\"isAdmin\")) { throw new AccessDeniedException($\"Only admins can access {context.ImplementationMethod.Name}!\"); } return context.Invoke(); } [AdminOnly] public Task<int> SpecialAdminOnlyOperation() => Task.FromResult(7); } 在以上示例中， SpecialAdminOnlyOperation 该方法只能在以下情况下调用 “ isAdmin” 设定为 真正 在里面 RequestContext 。 这样，可以将Grains调用过滤器用于授权。 在此示例中，呼叫者有责任确保 “ isAdmin” 值设置正确，并且验证正确执行。 请注意 [仅管理员] 属性是在Grains类方法上指定的。 这是因为 实现方法 属性返回 方法信息 的实现，而不是接口。 过滤器还可以检查 接口方法 属性。 grains呼叫过滤器的订购 Grains调用过滤器遵循定义的顺序： IIncomingGrainCallFilter 在依赖项注入容器中配置的实现(按注册顺序)。 Grains级过滤器(如果使用Grains) IIncomingGrainCallFilter 。 grain方法实施或grain扩展方法实施。 每次调用 IIncomingGrainCallContext.Invoke() 封装下一个定义的过滤器，以便每个过滤器都有机会在链中下一个过滤器之前和之后执行代码，并最终执行grain方法本身。 呼出调用过滤器 传出Grains调用过滤器类似于传入Grains调用过滤器，主要区别在于它们是在调用者(客户端)而不是被调用者(grains)上调用的。 传出呼叫过滤器实现了 IOutgoingGrainCallFilter 接口，它具有一种方法： public interface IOutgoingGrainCallFilter { Task Invoke(IOutgoingGrainCallContext context); } 的 IOutgoingGrainCallContext 参数传递给 Invoke 方法具有以下形状： public interface IOutgoingGrainCallContext { /// <summary> /// Gets the grain being invoked. /// </summary> IAddressable Grain { get; } /// <summary> /// Gets the <see cref=\"MethodInfo\"/> for the interface method being invoked. /// </summary> MethodInfo InterfaceMethod { get; } /// <summary> /// Gets the arguments for this method invocation. /// </summary> object[] Arguments { get; } /// <summary> /// Invokes the request. /// </summary> Task Invoke(); /// <summary> /// Gets or sets the result. /// </summary> object Result { get; set; } } 的 IOutgoingGrainCallFilter.Invoke(IOutgoingGrainCallContext) 方法必须等待或返回的结果 IOutgoingGrainCallContext.Invoke() 执行下一个配置的过滤器，最终执行grain方法本身。 的 结果 可以在等待 调用() 方法。 的 方法信息 可以使用 接口方法 属性。 传出的Grains调用过滤器会针对所有对Grains的方法调用进行调用，其中包括对Orleans进行的系统方法的调用。 配置去电呼叫过滤器 的实现 IOutgoingGrainCallFilter 可以使用依赖注入在silos和客户端上注册。 可以将委托注册为呼叫过滤器，如下所示： builder.AddOutgoingGrainCallFilter(async context => { // If the method being called is 'MyInterceptedMethod', then set a value // on the RequestContext which can then be read by other filters or the grain. if (string.Equals(context.InterfaceMethod.Name, nameof(IMyGrain.MyInterceptedMethod))) { RequestContext.Set(\"intercepted value\", \"this value was added by the filter\"); } await context.Invoke(); // If the grain method returned an int, set the result to double that value. if (context.Result is int resultValue) context.Result = resultValue * 2; }); if (string.Equals(context.InterfaceMethod.Name, nameof(IMyGrain.MyInterceptedMethod))) { RequestContext.Set(\"intercepted value\", \"this value was added by the filter\"); } await context.Invoke(); // If the grain method returned an int, set the result to double that value. if (context.Result is int resultValue) context.Result = resultValue * 2; }); 在上面的代码中， 建造者 可能是 ISiloHostBuilder 要么 IClientBuilder 。 同样，可以将一个类注册为传出的Grain调用过滤器。 这是一个grain调用过滤器的示例，它记录每个grain方法的结果： public class LoggingCallFilter : IOutgoingGrainCallFilter { private readonly Logger log; public LoggingCallFilter(Factory<string, Logger> loggerFactory) { this.log = loggerFactory(nameof(LoggingCallFilter)); } public async Task Invoke(IOutgoingGrainCallContext context) { try { await context.Invoke(); var msg = string.Format( \"{0}.{1}({2}) returned value {3}\", context.Grain.GetType(), context.InterfaceMethod.Name, string.Join(\", \", context.Arguments), context.Result); this.log.Info(msg); } catch (Exception exception) { var msg = string.Format( \"{0}.{1}({2}) threw an exception: {3}\", context.Grain.GetType(), context.InterfaceMethod.Name, string.Join(\", \", context.Arguments), exception); this.log.Info(msg); // If this exception is not re-thrown, it is considered to be // handled by this filter. throw; } } } throw; } } } 然后可以使用 AddOutgoingGrainCallFilter 扩展方法： builder.AddOutgoingGrainCallFilter<LoggingCallFilter>(); 或者，可以在不使用扩展方法的情况下注册过滤器： builder.ConfigureServices( services => services.AddSingleton<IOutgoingGrainCallFilter, LoggingCallFilter>()); 与委托调用过滤器示例一样， 建造者 可能是以下任何一个的实例 ISiloHostBuiler 要么 IClientBuilder 。 用例 异常转换 当从服务器引发的异常在客户端上反序列化时，有时可能会收到以下异常，而不是实际的异常： TypeLoadException：找不到Whatever.dll。 如果包含异常的程序集对客户端不可用，则会发生这种情况。 例如，假设您在grain实现中使用实体框架；那么有可能 EntityException 被抛出。 另一方面，客户端不(也不应该)引用 EntityFramework.dll 因为它不了解基础数据访问层。 当客户端尝试反序列化 EntityException ，它将因缺少DLL而失败；结果是 TypeLoadException类型加载异常 把原来的东西藏起来了 实体异常 . 有人可能会说这很好，因为客户永远不会处理 实体异常 否则就得参考 EntityFramework.dll . 但是如果客户端希望至少记录异常呢？ 问题是原来的错误消息丢失了。 解决此问题的一种方法是截获服务器端异常并用类型的纯异常替换它们 例外 如果异常类型可能在客户端未知。 然而，有一件重要的事我们必须牢记：我们只想替换一个例外 如果调用者是Grains客户 . 如果调用者是另一个grain(或者正在进行grain调用的Orleans基础设施；例如 GrainBasedReminderTable Grains)。 We don't want to replace an exception if the caller is another grain (or the Orleans infrastructure which is making grain calls, too; e.g. on the GrainBasedReminderTable grain). 在服务器端，这可以通过silos级别的拦截器来实现： public class ExceptionConversionFilter : IIncomingGrainCallFilter { private static readonly HashSet<string> KnownExceptionTypeAssemblyNames = new HashSet<string> { typeof(string).Assembly.GetName().Name, \"System\", \"System.ComponentModel.Composition\", \"System.ComponentModel.DataAnnotations\", \"System.Configuration\", \"System.Core\", \"System.Data\", \"System.Data.DataSetExtensions\", \"System.Net.Http\", \"System.Numerics\", \"System.Runtime.Serialization\", \"System.Security\", \"System.Xml\", \"System.Xml.Linq\", \"MyCompany.Microservices.DataTransfer\", \"MyCompany.Microservices.Interfaces\", \"MyCompany.Microservices.ServiceLayer\" }; public async Task Invoke(IIncomingGrainCallContext context) { var isConversionEnabled = RequestContext.Get(\"IsExceptionConversionEnabled\") as bool? == true; if (!isConversionEnabled) { // If exception conversion is not enabled, execute the call without interference. await context.Invoke(); return; } RequestContext.Remove(\"IsExceptionConversionEnabled\"); try { await context.Invoke(); } catch (Exception exc) { var type = exc.GetType(); if (KnownExceptionTypeAssemblyNames.Contains(type.Assembly.GetName().Name)) { throw; } // Throw a base exception containing some exception details. throw new Exception( string.Format( \"Exception of non-public type '{0}' has been wrapped.\" + \" Original message: <<<<----{1}{2}{3}---->>>>\", type.FullName, Environment.NewLine, exc, Environment.NewLine)); } } } == true; if (!isConversionEnabled) { // If exception conversion is not enabled, execute the call without interference. await context.Invoke(); return; } RequestContext.Remove(\"IsExceptionConversionEnabled\"); try { await context.Invoke(); } catch (Exception exc) { var type = exc.GetType(); if (KnownExceptionTypeAssemblyNames.Contains(type.Assembly.GetName().Name)) { throw; } // Throw a base exception containing some exception details. throw new Exception( string.Format( \"Exception of non-public type '{0}' has been wrapped.\" + \" Original message: <<<<----{1}{2}{3}---->>>>\", type.FullName, Environment.NewLine, exc, Environment.NewLine)); } } } 然后可以在silos上注册此筛选器： siloHostBuilder.AddIncomingGrainCallFilter<ExceptionConversionFilter>(); 通过添加传出呼叫筛选器，为客户端发出的呼叫启用筛选器： clientBuilder.AddOutgoingGrainCallFilter(context => { RequestContext.Set(\"IsExceptionConversionEnabled\", true); return context.Invoke(); }); 这样，客户端就告诉服务器它要使用异常转换。 从拦截器呼叫Grains 通过注入，可以从拦截器发出grain调用 IGR工厂 进入拦截器类： private readonly IGrainFactory grainFactory; public CustomCallFilter(IGrainFactory grainFactory) { this.grainFactory = grainFactory; } public async Task Invoke(IIncomingGrainCallContext context) { // Hook calls to any grain other than ICustomFilterGrain implementations. // This avoids potential infinite recursion when calling OnReceivedCall() below. if (!(context.Grain is ICustomFilterGrain)) { var filterGrain = this.grainFactory.GetGrain<ICustomFilterGrain>(context.Grain.GetPrimaryKeyLong()); // Perform some grain call here. await filterGrain.OnReceivedCall(); } // Continue invoking the call on the target grain. await context.Invoke(); } // This avoids potential infinite recursion when calling OnReceivedCall() below. if (!(context.Grain is ICustomFilterGrain)) { var filterGrain = this.grainFactory.GetGrain<ICustomFilterGrain>(context.Grain.GetPrimaryKeyLong()); // Perform some grain call here. await filterGrain.OnReceivedCall(); } // Continue invoking the call on the target grain. await context.Invoke(); }"
  },
  "docs/grains/observers.html": {
    "href": "docs/grains/observers.html",
    "title": "Observers | Microsoft Orleans Documentation",
    "keywords": "Observers 在某些情况下，简单的消息/响应模式是不够的，客户端需要接收异步通知。 例如，当朋友发布了新的即时消息时，用户可能希望收到通知。 客户端观察器是一种允许异步通知客户端的机制。 观察者是一个单向异步接口，它继承自 IGrainObserver ，其所有方法都必须是无效的。 grain通过像grain接口方法一样调用它来向观察者发送通知，只是它没有返回值，因此grain不需要依赖于结果。 Orleans运行时将确保单向传递通知。 发布此类通知的Grain应该提供一个api来添加或删除观察者。 此外，通常公开一种允许取消现有订阅的方法通常是方便的。 Grains开发商可能会使用Orleans ObserverSubscriptionManager<T> 类，以简化观察到的grains类型的开发。 要订阅通知，客户端必须首先创建一个实现观察者接口的本地c对象。 然后调用观察者工厂上的静态方法， CreateObjectReference() ，将c对象转换为一个grain引用，然后可以将其传递给通知grain上的订阅方法。 这个模型也可以被其他Grains用来接收异步通知。 与客户端订阅情况不同，订阅Grain只是将observer接口实现为一个方面，并将引用传递给自己(例如。 this.AsReference<IMyGrainObserverInterface> )中。 代码示例 假设我们有一个周期性地向客户发送消息的Grain。 为了简单起见，我们的示例中的消息将是一个字符串。 我们首先在客户端上定义将接收消息的接口。 接口将如下所示 public interface IChat : IGrainObserver { void ReceiveMessage(string message); } 唯一特别的是接口应该继承自 IGrainObserver 是的。 现在，任何希望观察这些消息的客户端都应该实现一个实现 IChat 是的。 最简单的例子是这样的： public class Chat : IChat { public void ReceiveMessage(string message) { Console.WriteLine(message); } } 现在在服务器上，我们应该有一个Grains发送这些聊天信息给客户端。 grain还应该有一个机制，让客户端订阅和取消订阅自己以接收通知。 对于订阅，grain可以使用utility类 ObserverSubscriptionManager 是的。 这个班的学生 OrleansException 如果您尝试订阅已订阅的观察者(或取消订阅未订阅的观察者)，那么使用 IsSubscribed() 方法或通过处理 OrleansException 以下内容： class HelloGrain : Grain, IHello { private ObserverSubscriptionManager<IChat> _subsManager; public override async Task OnActivateAsync() { // We created the utility at activation time. _subsManager = new ObserverSubscriptionManager<IChat>(); await base.OnActivateAsync(); } // Clients call this to subscribe. public Task Subscribe(IChat observer) { if (!_subsManager.IsSubscribed(observer)) { _subsManager.Subscribe(observer); } return Task.CompletedTask; } //Also clients use this to unsubscribe themselves to no longer receive the messages. public Task UnSubscribe(IChat observer) { if (_subsManager.IsSubscribed(observer)) { _subsManager.Unsubscribe(observer); } return Task.CompletedTask; } } _subsManager = new ObserverSubscriptionManager<IChat>(); await base.OnActivateAsync(); } // Clients call this to subscribe. public Task Subscribe(IChat observer) { if (!_subsManager.IsSubscribed(observer)) { _subsManager.Subscribe(observer); } return Task.CompletedTask; } //Clients use this to unsubscribe and no longer receive messages. public Task UnSubscribe(IChat observer) { if (_subsManager.IsSubscribed(observer)) { _subsManager.Unsubscribe(observer); } return Task.CompletedTask; } } 将消息发送到客户端 Notify 方法 ObserverSubscriptionManager<Ichat> 可以使用实例。 这种方法需要 Action<T> 方法或lambda表达式(其中 T 属于类型 IChat )。 可以调用接口上的任何方法将其发送给客户端。 我们只有一种方法 ReceiveMessage 我们在服务器上发送的代码如下所示： public Task SendUpdateMessage(string message) { _subsManager.Notify(s => s.ReceiveMessage(message)); return Task.CompletedTask; } 现在，我们的服务器有一个向观察者客户端发送消息的方法，两个用于订阅/取消订阅的方法，并且客户端实现了一个能够观察到grain消息的类。 最后一步是使用之前实现的 Chat 类并让它在订阅后接收消息。 代码如下所示： //First create the grain reference var friend = GrainClient.GrainFactory.GetGrain<IHello>(0); Chat c = new Chat(); //Create a reference for chat usable for subscribing to the observable grain. var obj = await GrainClient.GrainFactory.CreateObjectReference<IChat>(c); //Subscribe the instance to receive messages. await friend.Subscribe(obj); var obj = await GrainClient.GrainFactory.CreateObjectReference<IChat>(c); //Subscribe the instance to receive messages. await friend.Subscribe(obj); 现在每当服务器上的Grains调用 SendUpdateMessage 方法，所有已订阅的客户端都将收到消息。 在我们的客户代码中， Chat 变量中的实例 C 将接收消息并将其输出到控制台。 注： 传递给的对象 CreateObjectReference 通过 WeakReference<T> 因此，如果没有其他引用，则将被垃圾收集。 用户应该为每个不希望被收集的观察者维护一个引用。 注： 观察者本质上是不可靠的，因为您没有得到任何响应来知道消息是被接收和处理的，还是仅仅由于分布式系统中可能出现的任何情况而失败。 因此，您的观察者应该定期轮询grain或使用任何其他机制来确保他们接收到了所有应该接收到的消息。 在某些情况下，您可能会丢失一些消息，并且不需要任何附加机制，但如果您需要确保所有观察者始终接收消息并接收所有消息，则定期重新订阅和轮询观察者Grain有助于确保最终处理所有消息。"
  },
  "docs/grains/reentrancy.html": {
    "href": "docs/grains/reentrancy.html",
    "title": "Reentrancy | Microsoft Orleans Documentation",
    "keywords": "Reentrancy Grain激活是单线程的，默认情况下，在下一个请求可以开始处理之前，从头到尾处理每个请求。 在某些情况下，当一个请求等待异步操作完成时，可能需要激活来处理其他请求。 由于这个和其他原因，Orleans给了开发人员一些控制请求交错行为的权限。 在以下情况下，多个请求可能被交错： Grains等级标记为 [Reentrant] 接口方法标记为 [AlwaysInterleave] 同一调用链中的请求 Grains的 MayInterleave 谓词返回 true 以下各节将讨论这些情况。 重入grains Grains 实现类可以用 [Reentrant] 属性指示不同的请求可以自由交错。 换言之，Reentrant激活可能在前一个请求尚未完成处理时开始执行另一个请求。 执行仍然局限于单个线程，因此激活仍然一次执行一个回合，并且每个回合只代表激活的一个请求执行。 ReentrantGrain代码永远不会并行运行多个Grain代码(Grain代码的执行将始终是单线程的)，但ReentrantGrain代码 可能 看见不同请求交错执行的代码。 也就是说，不同请求的续转可以交错。 例如，使用下面的伪代码，当Foo和Bar是同一grain类的2个方法时： Task Foo() { await task1; // line 1 return Do2(); // line 2 } Task Bar() { await task2; // line 3 return Do2(); // line 4 } 如果这个grains有标记 [Reentrant] ，Foo和Bar的执行可以交错执行。 例如，可以按以下顺序执行： 1号线、3号线、2号线和4号线。 也就是说，来自不同请求的圈数交错。 如果grain不Reentrant，唯一可能的执行将是：第1行、第2行、第3行、第4行或：第3行、第4行、第1行、第2行(在前一个请求完成之前，新请求无法启动)。 在选择Reentrant和不Reentrantgrains时，主要的折衷是使交织正确工作的代码复杂度和对此进行推理的困难。 在一个很小的例子中，当Grain是无状态的，逻辑也很简单时，更少(但不是太少，以便使用所有的硬件线程)Reentrantgrains通常会稍微更有效一些。 如果代码更复杂，那么大量的不Reentrantgrains，即使总体效率稍低，也可以避免您在解决不明显的交错问题时的许多痛苦。 最终答案将取决于具体的应用程序。 交错方法 grains接口被标记为 [AlwaysInterleave] 无论grains是否Reentrant，都将被交错执行。 考虑以下示例： public interface ISlowpokeGrain : IGrainWithIntegerKey { Task GoSlow(); [AlwaysInterleave] Task GoFast(); } public class SlowpokeGrain : Grain, ISlowpokeGrain { public async Task GoSlow() { await Task.Delay(TimeSpan.FromSeconds(10)); } public async Task GoFast() { await Task.Delay(TimeSpan.FromSeconds(10)); } } 现在考虑由以下客户端请求启动的调用流： var slowpoke = client.GetGrain<ISlowpokeGrain>(0); // A) This will take around 20 seconds await Task.WhenAll(slowpoke.GoSlow(), slowpoke.GoSlow()); // B) This will take around 10 seconds. await Task.WhenAll(slowpoke.GoFast(), slowpoke.GoFast(), slowpoke.GoFast()); await Task.WhenAll(slowpoke.GoFast(), slowpoke.GoFast(), slowpoke.GoFast()); 访问 GoSlow 不会交错，所以执行两个 GoSlow() 调用大约需要20秒。 另一方面，因为 GoFast 有标记 [AlwaysInterleave] ，对它的三个调用将同时执行，并将在大约10秒内完成，而不是至少需要30秒才能完成。 访问链中的Reentrant性 为了避免死锁，调度器允许在给定的调用链中进行重入。 考虑以下两个grains的例子，它们具有相互递归的方法， IsEven 和 IsOdd : public interface IEvenGrain : IGrainWithIntegerKey { Task<bool> IsEven(int num); } public interface IOddGrain : IGrainWithIntegerKey { Task<bool> IsOdd(int num); } public class EvenGrain : Grain, IEvenGrain { public async Task<bool> IsEven(int num) { if (num == 0) return true; var oddGrain = this.GrainFactory.GetGrain<IOddGrain>(0); return await oddGrain.IsOdd(num - 1); } } public class OddGrain : Grain, IOddGrain { public async Task<bool> IsOdd(int num) { if (num == 0) return false; var evenGrain = this.GrainFactory.GetGrain<IEvenGrain>(0); return await evenGrain.IsEven(num - 1); } } 现在考虑由以下客户端请求启动的调用： var evenGrain = client.GetGrain<IEvenGrain>(0); await evenGrain.IsEven(2); 上面的代码调用 IEvenGrain.IsEven(2) ，调用 IOddGrain.IsOdd(1) ，调用 IEvenGrain.IsEven(0) ，返回 true 将访问链备份到客户端。 如果没有调用链Reentrant，上述代码将在以下情况下导致死锁当 IOddGrain 调用 IEvenGrain.IsEven(0) . 然而，对于调用链Reentrant，调用被认为是开发人员的意图，因此允许继续进行。 However, with call chain reentrancy, the call is allowed to proceed, as it is deemed to be the intention of the developer. 可以通过设置来禁用此行为 SchedulingOptions.AllowCallChainEntrancy 为 false . 例如： For example: siloHostBuilder.Configure<SchedulingOptions>( options => options.AllowCallChainReentrancy = false); 使用谓词的Reentrant性 Grain类可以指定一个谓词，用于通过检查请求逐个调用确定交错。 这个 [MayInterleave(string methodName)] 属性提供此功能。 属性的参数是grain类中接受 InvokeMethodRequest 对象并返回 bool 指示是否应交错请求。 下面是一个示例，如果请求参数类型具有 [Interleave] 属性： [AttributeUsage(AttributeTargets.Class | AttributeTargets.Struct)] public sealed class InterleaveAttribute : Attribute { } // Specify the may-interleave predicate. [AttributeUsage(AttributeTargets.Class | AttributeTargets.Struct)] public sealed class InterleaveAttribute : Attribute { } // Specify the may-interleave predicate. [MayInterleave(nameof(ArgHasInterleaveAttribute))] public class MyGrain : Grain, IMyGrain { public static bool ArgHasInterleaveAttribute(InvokeMethodRequest req) { // Returning true indicates that this call should be interleaved with other calls. // Returning false indicates the opposite. return req.Arguments.Length == 1 && req.Arguments[0]?.GetType().GetCustomAttribute<InterleaveAttribute>() != null; } public Task Process(object payload) { // Process the object. } } // Returning false indicates the opposite. return req.Arguments.Length == 1 && req.Arguments[0]?.GetType().GetCustomAttribute<InterleaveAttribute>() != null; } public Task Process(object payload) { // Process the object. } }"
  },
  "docs/grains/request_context.html": {
    "href": "docs/grains/request_context.html",
    "title": "Request Context | Microsoft Orleans Documentation",
    "keywords": "Request Context RequestContext是一个Orleans特性，它允许应用程序元数据(如跟踪ID)与请求一起流动。 应用程序元数据可以添加到客户端上；它将与Orleans请求一起流向接收Grain。 该特性由Orleans名称空间中的一个公共静态类RequestContext实现。 此类公开了两个简单方法： void Set(string key, object value) 用于在请求上下文中存储值。 该值可以是任何可序列化类型。 Object Get(string key) 用于从当前请求上下文中检索值。 RequestContext的后台存储是线程静态的。 当一个线程(无论是客户端还是在Orleans内)发送请求时，发送线程的RequestContext的内容都包含在请求的Orleans消息中；当grain代码接收到请求时，可以从本地RequestContext访问该元数据。 如果grain代码没有修改RequestContext，那么它请求的任何grain都将接收相同的元数据，依此类推。 当您使用StartNew或ContinueWith计划未来的计算时，也会维护应用程序元数据；在这两种情况下，后续的任务将使用与调度代码在调度计算时所具有的相同元数据执行(即，系统复制当前元数据并将其传递给后续任务，因此，调用StartNew或ContinueWith之后的更改将不会被后续任务看到)。 请注意，应用程序元数据不会随响应返回；也就是说，由于接收到响应而运行的代码，无论是在ContinueWith 后续任务中，还是在调用Wait或GetValue之后，仍将在原始请求设置的当前上下文中运行。 例如，要将客户端中的跟踪ID设置为新的GUID，只需调用： RequestContext.Set(\"TraceId\", new Guid()); 在grain代码(或在Orleans内运行的调度程序线程上的其他代码)中，可以使用原始客户端请求的跟踪ID，例如，在编写日志时： Logger.Info(\"Currently processing external request {0}\", RequestContext.Get(\"TraceId\")); 虽然任何可序列化的对象都可以作为应用程序元数据发送，但值得一提的是，大型或复杂的对象可能会给消息序列化时间增加显著的开销。 因此，建议使用简单类型(字符串、guid或数字类型)。"
  },
  "docs/grains/stateless_worker_grains.html": {
    "href": "docs/grains/stateless_worker_grains.html",
    "title": "Stateless Worker Grains | Microsoft Orleans Documentation",
    "keywords": "Stateless Worker Grains 默认情况下，Orleans运行时在集群中创建的grain不超过一次激活。 这是虚拟角色模型最直观的表达方式，每个Grain对应一个具有唯一类型/标识的实体。 但是，也有一些情况下，应用程序需要执行与系统中特定实体无关的功能性无状态操作。 例如，如果客户端发送的请求带有压缩的有效负载，而这些负载需要在将它们路由到目标Grain进行处理之前进行解压缩，那么这种解压缩/路由逻辑就不会绑定到应用程序中的特定实体，并且可以很容易地进行扩展。 当 [StatelessWorker] 属性应用于grain类，它向Orleans运行时指示该类的grains应被视为 无状态工作者 Grains。 无状态工作者 grains具有以下特性，使得它们的执行与普通grains类的执行非常不同。 Orleans运行时可以并且将在集群的不同silos上创建多个无状态工作线程的激活。 对无状态工作Grain的请求总是在本地执行，即在发出请求的同一个silos上执行，或者由silos上运行的Grain发出，或者由silos的客户端网关接收。 因此，从其他Grain或客户端网关调用无状态工作线程不会引发远程消息。 如果已经存在的工作线程繁忙，Orleans运行时会自动创建无状态工作线程的额外激活。 运行时为每个silos创建的无状态工作线程的最大激活数默认由计算机上的CPU内核数限制，除非可选的 maxLocalWorkers 争论。 由于2和3，无状态的Worker-grain激活不能单独寻址。 对无状态工作线程Grain的两个后续请求可以通过对其进行不同的激活来处理。 无状态工作线程提供了一种直接的方法来创建一个自动管理的grain激活池，该池根据实际负载自动伸缩。 运行时总是以相同的顺序扫描可用的无状态工作线程Grain激活。 因此，它总是将请求发送到它可以找到的第一个空闲本地激活，并且只有在所有以前的激活都很忙的情况下才能到达最后一个。 如果所有的激活都很忙并且还没有达到激活限制，它会在列表的末尾再创建一个激活，并将请求发送给它。 这意味着，当对无状态工作线程的请求速率增加，并且现有的激活当前都很忙时，运行时会将其激活池扩展到最大限度。 相反，当负载下降时，并且可以通过较少数量的无状态工作线程的激活来处理，则列表末尾的激活将不会得到分派给它们的请求。 它们将变为空闲，并最终被标准激活收集过程停用。 因此，激活池最终将缩小以匹配负载。 下面的示例定义了一个无状态的Worker grain类 MyStatelessWorkerGrain 使用默认的最大激活数限制。 [StatelessWorker] public class MyStatelessWorkerGrain : Grain, IMyStatelessWorkerGrain { ... } } Making a call to a Stateless Worker grain is the same as to any other grain. 唯一的区别是，在大多数情况下，使用单个grainsID，0或 Guid.Empty . 当需要多个无状态工作线程Grain池时，可以使用多个grain ID，每个ID一个。 Multiple grain IDs can be used when having multiple Stateless Worker grain pools, one per ID, is desirable. var worker = GrainFactory.GetGrain<IMyStatelessWorkerGrain>(0); await worker.Process(args); 这一个定义了一个无状态的Worker-grain类，每个silos只有一个grain激活。 [StatelessWorker(1)] // max 1 activation per silo public class MyLonelyWorkerGrain : ILonelyWorkerGrain { ... } } 请注意 [StatelessWorker] 属性不会更改目标grain类的Reentrant性。 与其他任何Grain一样，无状态工作者Grain在默认情况下是不Reentrant的。 通过添加一个 [Reentrant] 属性设置为grain类。 State “无状态工作者”的“无状态”部分并不意味着无状态工作者不能有状态，并且仅限于执行功能性操作。 与其他任何Grain一样，无状态工作线程可以加载所需的任何状态并将其保存在内存中。 这只是因为一个无状态的Worker-grain的多个激活可以在集群的同一个和不同的Silo上创建，所以没有一个简单的机制来协调不同激活所保持的状态。 有几个有用的模式涉及到无状态工作者保持状态。 扩展热缓存项 对于具有高吞吐量的热缓存项，将每个这样的项保存在无状态工作进程中会使其a)在silos中自动横向扩展并跨群集中的所有silos；b)使数据始终在通过其客户端网关接收客户端请求的silos上本地可用，这样就可以在不需要额外的网络跃点到另一个silos的情况下响应请求。 减少样式聚合 在某些场景中，应用程序需要计算集群中特定类型的所有Grain的特定度量，并定期报告聚合。 例如，报告每个游戏地图上的玩家数量、VoIP访问的平均持续时间等。 如果成千上万或数百万个grains中的每一个都向单个全局聚合器报告其指标，聚合器将立即过载，无法处理大量报告。 另一种方法就是将此任务转换为 2（或更多）步骤减少样式聚合。 聚合的第一层是通过报告Grain将其指标发送到无状态工作者预聚合Grain来完成的。 Orleans 运行时将自动为每个Silo创建无状态工作者Grain的多个激活。 由于所有此类调用都将在本地处理，无需远程调用或消息序列化，因此此类聚合的成本将大大低于远程案例。 现在，每个预聚合无状态工作者Grain的激活，独立或与其他本地激活协调，可以将其聚合报告发送到全局最终聚合器（或必要时发送到另一个缩减层），而无需重载。"
  },
  "docs/grains/timers_and_reminders.html": {
    "href": "docs/grains/timers_and_reminders.html",
    "title": "Timers and Reminders | Microsoft Orleans Documentation",
    "keywords": "Timers and Reminders Orleans运行时提供了两种机制，称为计时器和提醒，使开发人员可以指定Grains的周期性行为。 计时器 计时器说明 计时器 用于创建不需要多次激活(Grains实例化)的周期性Grains行为。 它与标准基本上相同。 NET System.Threading.Timer 类。 In addition, timers are subject to single-threaded execution guarantees within the grain activation that it operates on. 每次激活可能具有零个或多个与其关联的计时器。 运行时在与之关联的激活的运行时上下文中执行每个计时器例程。 计时器使用 要启动计时器，请使用 Grain.RegisterTimer 方法，该方法返回一个 IDisposable 参考： public IDisposable RegisterTimer( Func<object, Task> asyncCallback, // function invoked when the timer ticks object state, // object tp pass to asyncCallback TimeSpan dueTime, // time to wait before the first timer tick TimeSpan period) // the period of the timer 通过丢弃计时器来取消它。 如果取消激活激活或发生故障并且其silos崩溃，计时器将停止触发。 重要注意事项 启用激活收集后，计时器回调的执行不会将激活状态从空闲更改为使用中。 这意味着无法使用计时器来推迟其他情况下空闲激活的取消激活。 期间过去了 Grain.RegisterTimer 是从任务返回的那一刻起经过的时间 asyncCallback 解决到下一次调用 asyncCallback 应该发生。 这不仅使得无法连续调用 asyncCallback 重叠但也使时间长 asyncCallback 完成需要影响的频率 asyncCallback 被调用。 这与 System.Threading.Timer 。 每次调用 asyncCallback 将在单独的回合上传递给激活，并且永远不会与同一激活中的其他回合同时运行。 请注意， asyncCallback 调用不作为消息传递，因此不受消息交织语义的约束。 这意味着 asyncCallback 相对于传递给该Grains的其他消息，应被视为表现为在ReentrantGrains上运行。 提醒事项 提醒说明 提醒与计时器类似，但有一些重要区别： 提醒是持久化的，除非明确取消，否则提醒将在几乎所有情况下(包括部分或完全重启群集)继续触发。 提醒“定义”被写入存储。 但是，不是每个特定的事件及其特定的时间。 这样做的副作用是，如果在某个特定的提醒滴答声时群集完全崩溃，则它将丢失，并且仅会发生提醒的下一个滴答声。 提醒与Grains相关联，而不是任何特定的激活。 如果某个Grains没有与之关联的激活并且有提示音，则将创建一个。 例如：如果激活闲置而被停用，则与同一Grains关联的提醒会在下次勾选时重新激活Grains。 提醒是通过消息传递的，并且与其他所有grain方法都具有相同的交织语义。 提醒事项不应用于高频计时器，其周期应以分钟，小时或天为单位。 组态 提醒是持久的，依赖于存储来发挥作用。 在提醒子系统起作用之前，您必须指定要使用的存储支持。 这是通过以下方式配置提醒提供程序之一来完成的： UseXReminderService 扩展方法，其中X是提供者的名称，例如， UseAzureTableReminderService 。 Azure表配置： // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; var silo = new SiloHostBuilder() [...] // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; var silo = new SiloHostBuilder() [...] .UseAzureTableReminderService(options => options.ConnectionString = connectionString) [...] SQL： // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; const string invariant = \"YOUR_INVARIANT\"; var silo = new SiloHostBuilder() [...] .UseAdoNetReminderService(options => { options.ConnectionString = connectionString; options.Invariant = invariant; }) [...] .UseAdoNetReminderService(options => { options.ConnectionString = connectionString; options.Invariant = invariant; }) [...] 如果只希望使用提醒的占位符实现而不需要设置Azure帐户或SQL数据库，那么这将为您提供提醒系统的仅开发实现： var silo = new SiloHostBuilder() [...] .UseInMemoryReminderService() [...] .UseInMemoryReminderService() [...] 提醒用法 使用提醒的grain必须实现 IRemindable.RecieveReminder 方法。 Task IRemindable.ReceiveReminder(string reminderName, TickStatus status) { Console.WriteLine(\"Thanks for reminding me-- I almost forgot!\"); return Task.CompletedTask; } 要启动提醒，请使用 Grain.RegisterOrUpdateReminder 方法，该方法返回一个 IOrleansReminder 目的： protected Task<IOrleansReminder> RegisterOrUpdateReminder(string reminderName, TimeSpan dueTime, TimeSpan period) hinterName是一个字符串，必须在上下文范围内唯一地标识提醒。 dueTime指定发出第一个计时器刻度之前要等待的时间。 period指定计时器的时间。 由于提醒在任何一次激活的生命周期中都可以保留，因此必须将其明确取消(而不是处置)。 您通过调用取消提醒 Grain.UnregisterReminder ： protected Task UnregisterReminder(IOrleansReminder reminder) 提醒是返回的句柄对象 Grains.RegisterOrUpdateReminder . 实例 IOrleansReminder 不能保证在激活的有效期之外有效。 如果希望以持续的方式标识提醒，请使用包含提醒名称的字符串。 如果您只有提醒的名称并需要相应的实例 IOrleansReminder ，访问 Grains.GetReminder 方法： protected Task<IOrleansReminder> GetReminder(string reminderName) 我应该用哪一个？ 我们建议您在以下情况下使用计时器： 如果激活被停用或发生故障，计时器停止工作并不重要(或是可取的)。 计时器的分辨率很小(例如，可以用秒或分钟表示)。 计时器回调可以从 Grain.OnActivateAsync 或者调用grain方法时。 我们建议您在以下情况下使用提醒： 当周期性行为需要在激活和任何失败中幸存下来时。 执行一些不经常发生的任务(例如，在几分钟、几小时或几天内可以合理地表达)。 组合计时器和提醒 你可以考虑结合使用提醒和计时器来完成你的目标。 例如，如果您需要一个分辨率很小的计时器，而该计时器需要在激活期间继续存在，则可以使用每五分钟运行一次的提醒，该提醒的目的是唤醒一个grains，该grains将重新启动可能因停用而丢失的本地计时器。"
  },
  "docs/grains/transactions.html": {
    "href": "docs/grains/transactions.html",
    "title": "Transactions in Orleans 2.0 | Microsoft Orleans Documentation",
    "keywords": "Orleans事务 Orleans支持针对持久Grains状态的分布式ACID事务。 建立 Orleans选择加入事务。 必须将silos配置为使用事务。 如果不是，对Grains上的事务方法的任何调用都将收到一个 OrleansTransactionsDisabledException 。 要在silos上启用事务，请调用 UseTransactions() 在silos主机构建器上。 var builder = new SiloHostBuilder().UseTransactions(); 事务状态存储 要使用事务，用户需要配置数据存储。 为了支持带有事务的各种数据存储，存储抽象 ITransactionalStateStorage 已经介绍了。 这种抽象是特定于事务需求的，与普通的Grains存储不同( IGrain存储 )。 要使用特定于事务的存储，用户可以使用以下任何实现来配置其silos ITransactionalStateStorage ，例如Azure( AddAzureTableTransactionalStateStorage )。 例： var builder = new SiloHostBuilder() .AddAzureTableTransactionalStateStorage(\"TransactionStore\", options => { options.ConnectionString = \"YOUR_STORAGE_CONNECTION_STRING\"; }) .UseTransactions(); 出于开发目的，如果特定事务的存储不适用于您需要的数据存储，则 IGrainStorage 实现可以代替使用。 对于任何未为其配置存储的事务状态，事务将尝试使用网桥故障转移到Grains存储。 通过通往Grains存储的桥梁访问事务状态将效率较低，并且不是我们打算长期支持的模式，因此建议将其仅用于开发目的。 程式设计模型 grains接口 为了使Grains支持事务，必须使用“Transaction”属性将Grains接口上的事务方法标记为事务的一部分。 该属性需求通过下面的事务选项指示在调用环境中grain调用的行为： TransactionOption.Create -调用是事务性的，即使在现有事务上下文中被调用，也总是会创建一个新的事务上下文(即它将启动一个新事务)。 TransactionOption.Join -调用是事务性的，但只能在现有事务的上下文中调用。 TransactionOption.CreateOrJoin -通话具有事务性。 如果在事务上下文中调用，它将使用该上下文，否则它将创建一个新的上下文。 TransactionOption.Suppress -调用不是事务性的，但可以从事务中调用。 如果在事务上下文中调用，则上下文将不会传递给调用。 TransactionOption.Supported -通话不是事务性的，但支持事务。 如果在事务上下文中调用，则上下文将传递给调用。 TransactionOption.NotAllowed -访问不是事务性的，不能从事务中进行访问。 如果在事务环境中调用，它将抛出一个 NotSupportedException 。 可以将访问标记为“创建”，这意味着访问将始终启动自己的事务。 例如，下面的ATM中的“转帐”操作将始终启动一个涉及两个引用帐户的新事务。 public interface IATMGrain : IGrainWithIntegerKey { [Transaction(TransactionOption.Create)] Task Transfer(Guid fromAccount, Guid toAccount, uint amountToTransfer); } 帐户上的提款和存款事务操作标记为“加入”，表示只能在现有事务的上下文中调用它们，如果在 IATMGrain.Transfer(…) 。 的 GetBalance 通话被标记 CreateOrJoin 因此可以在现有事务中调用它，例如通过 IATMGrain.Transfer(…) ，或单独使用。 public interface IAccountGrain : IGrainWithGuidKey { [Transaction(TransactionOption.Join)] Task Withdraw(uint amount); [Transaction(TransactionOption.Join)] Task Deposit(uint amount); [Transaction(TransactionOption.CreateOrJoin)] Task<uint> GetBalance(); } Important Considerations Please be aware that OnActivateAsync could NOT be marked as transactional as any such call requires a proper setup before the call. It does exist only for the grain application API. This means that an attempt to read transactional state as part of these methods will raise an exception in the runtime. grain实施 grain实施需要使用 ITransactionalState facet(请参阅Facet System)以通过ACID事务管理grains状态。 public interface ITransactionalState<TState> where TState : class, new() { Task<TResult> PerformRead<TResult>(Func<TState, TResult> readFunction); Task<TResult> PerformUpdate<TResult>(Func<TState, TResult> updateFunction); } 必须通过传递给事务状态方面的同步功能来执行对持久状态的所有读取或写入访问。 这允许事务系统以事务方式执行或取消这些操作。 要在Grains中使用事务状态，只需要定义一个可序列化的状态类即可保留，并在Grains的构造函数中使用 事务状态 属性。 后者声明状态名称和(可选)使用哪个事务状态存储(请参阅安装程序)。 [AttributeUsage(AttributeTargets.Parameter)] public class TransactionalStateAttribute : Attribute { public TransactionalStateAttribute(string stateName, string storageName = null) { … } } } } 例： public class AccountGrain : Grain, IAccountGrain { private readonly ITransactionalState<Balance> balance; public AccountGrain( [TransactionalState(\"balance\", \"TransactionStore\")] ITransactionalState<Balance> balance) { this.balance = balance ?? throw new ArgumentNullException(nameof(balance)); } Task IAccountGrain.Deposit(uint amount) { return this.balance.PerformUpdate(x => x.Value += amount); } Task IAccountGrain.Withdrawal(uint amount) { return this.balance.PerformUpdate(x => x.Value -= amount); } Task<uint> IAccountGrain.GetBalance() { return this.balance.PerformRead(x => x.Value); } } throw new ArgumentNullException(nameof(balance)); } Task IAccountGrain.Deposit(uint amount) { return this.balance.PerformUpdate(x => x.Value += amount); } Task IAccountGrain.Withdrawal(uint amount) { return this.balance.PerformUpdate(x => x.Value -= amount); } Task<uint> IAccountGrain.GetBalance() { return this.balance.PerformRead(x => x.Value); } } 在上面的示例中，属性 TransactionalState 用于声明“balance”构造函数参数应与名为“balance”的事务状态相关联。 通过此声明，Orleans将注入 ITransactionalState 从名为“ TransactionStore”的事务状态存储中加载状态的实例(请参阅安装程序)。 可以通过以下方式修改状态 PerformUpdate 或通过阅读 PerformRead 。 事务基础架构将确保作为事务一部分进行的任何此类更改，即使是在分布于Orleans集群中的多个Grains之间，也将在创建事务的Grains调用完成后全部提交或全部撤消( IATMGrain.Transfer 在上述示例中)。 访问事务 如同其他任何Grains调用一样，调用Grains接口上的事务方法。 IATMGrain atm = client.GetGrain<IATMGrain>(0); Guid from = Guid.NewGuid(); Guid to = Guid.NewGuid(); await atm.Transfer(from, to, 100); uint fromBalance = await client.GetGrain<IAccountGrain>(from).GetBalance(); uint toBalance = await client.GetGrain<IAccountGrain>(to).GetBalance(); 在上述访问中，使用ATMGrains将100个单位的货币从一个帐户转移到另一个帐户。 转帐完成后，将查询两个帐户以获取其当前余额。 货币转帐以及两个帐户查询均作为ACID事务执行。 如上例所示，事务可以像其他grain调用一样返回任务中的值，但是在调用失败时，它们不会引发应用程序异常，而是 OrleansTransactionException 要么 TimeoutException 。 如果应用程序在事务期间引发异常，并且该异常导致事务失败(与其他系统故障导致的失败相反)，则应用程序异常将是事务的内部异常。 OrleansTransactionException 。 如果抛出类型的事务异常 OrleansTransactionAbortedException ，事务失败，可以重试。 引发的任何其他异常都表示事务以未知状态终止。 由于事务是分布式操作，因此处于未知状态的事务可能已经成功，失败或仍在进行中。 因此，建议设置通话超时时间( SiloMessagingOptions.ResponseTimeout )传递，以避免级联中止，然后再验证状态或重试操作。"
  },
  "docs/host/client.html": {
    "href": "docs/host/client.html",
    "title": "Clients | Microsoft Orleans Documentation",
    "keywords": "Clients A client allows non-grain code to interact with an Orleans cluster. Clients allow application code to communicate with grains and streams hosted in a cluster. There are two ways to obtain a client, depending on where the client code is hosted: in the same process as a silo, or in a separate process. This article will discuss both options, starting with the recommended option: co-hosting the client code in the same process as the grain code. Co-hosted clients If the client code is hosted in the same process as the grain code, then the client can be directly obtained from the hosting application's dependency injection container. In this case, the client communicates directly with the silo it is attached to and can take advantage of the extra knowledge that the silo has about the cluster. This provides several benefits, including reducing network and CPU overhead as well as decreasing latency and increasing throughput and reliability. The client utilizes the silo's knowledge of the cluster topology and state and does not need to use a separate gateway. This avoids a network hop and serialization/deserialization round trip. This therefore also increases reliability, since the number of required nodes in between the client and the grain is minimized. If the grain is a stateless worker grain or otherwise happens to be activated on the silo which the client is hosted in, then no serialization or network communication needs to be performed at all and the client can reap additional performance and reliability gains. Co-hosting client and grain code also simplifies deployment and application topology by eliminating the need for two distinct application binaries to be deployed and monitored. There are also detractors to this approach, primarily that the grain code is no longer isolated from the client process. Therefore, issues in client code, such as blocking IO or lock contention causing thread starvation can affect the performance of grain code. Even without code defects like the abovementioned, noisy neighbor effects can result simply by having the client code execute on the same processor as grain code, putting additional strain on CPU cache and additional contention for local resources in general. Additionally, identifying the source of these issues is now more difficult because monitoring systems cannot distinguish what is logically client code from grain code. Despite these detractors, co-hosting client code with grain code is a popular option and the recommended approach for most applications. To elaborate, the abovementioned detractors are minimal in practice for the following reasons: Client code is often very thin , for example translating incoming HTTP requests into grain calls, and therefore the noisy neighbor effects are minimal and comparable in cost to the otherwise required gateway. In the event that a performance issue arises, the typical workflow for a developer involves tools such as CPU profilers and debuggers, which are still effective in quickly identifying the source of the issue despite having both client and grain code executing in the same process. In other words, metrics become more coarse and less able to precisely identify the source of an issue, but more detailed tools are still effective. Obtaining a client from a host If hosting using the .NET Generic Host , the client will be available in the host's dependency injection container automatically and can be injected into services such as ASP.NET controllers or IHostedService implementations. Alternatively, a client interface such as IGrainFactory or IClusterClient can be obtained from either IHost or ISiloHost : var client = host.Services.GetService<IClusterClient>(); await client.GetGrain<IMyGrain>(0).Ping(); External clients Client code can run outside of the Orleans cluster where grain code is hosted. Hence, an external client acts as a connector or conduit to the cluster and to all grains of the application. Usually, clients are used on the frontend web servers to connect to an Orleans cluster that serves as a middle tier with grains executing business logic. In a typical setup, a frontend web server: Receives a web request Performs necessary authentication and authorization validation Decides which grain(s) should process the request Uses Grain Client to make one or more method call to the grain(s) Handles successful completion or failures of the grain calls and any returned values Sends a response for the web request Initialization of Grain Client Before a grain client can be used for making calls to grains hosted in an Orleans cluster, it needs to be configured, initialized, and connected to the cluster. Configuration is provided via ClientBuilder and a number of supplemental option classes that contain a hierarchy of configuration properties for programmatically configuring a client. More information can be in the Client Configuration guide . Example of a client configuration: var client = new ClientBuilder() // Clustering information .Configure<ClusterOptions>(options => { options.ClusterId = \"my-first-cluster\"; options.ServiceId = \"MyOrleansService\"; }) // Clustering provider .UseAzureStorageClustering(options => options.ConnectionString = connectionString) // Application parts: just reference one of the grain interfaces that we use .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(IValueGrain).Assembly)) .Build(); Lastly, we need to call Connect() method on the constructed client object to make it connect to the Orleans cluster. It's an asynchronous method that returns a Task . So we need to wait for its completion with an await or .Wait() . await client.Connect(); Making Calls to Grains Making calls to grain from a client is really no different from making such calls from within grain code . The same GetGrain<T>(key) method, where T is the target grain interface, is used in both cases to obtain grain references . The slight difference is in through what factory object we invoke GetGrain . In client code we do that through the connected client object. IPlayerGrain player = client.GetGrain<IPlayerGrain>(playerId); Task t = player.JoinGame(game) await t; A call to a grain method returns a Task or a Task<T> as required by the grain interface rules . The client can use the await keyword to asynchronously await the returned Task without blocking the thread, or in some cases the Wait() method to block the current thread of execution. The major difference between making calls to grains from client code and from within another grain is the single-threaded execution model of grains. Grains are constrained to be single-threaded by the Orleans runtime, while clients may be multi-threaded. Orleans does not provide any such guarantee on the client side, and so it is up to the client to manage its own concurrency using whatever synchronization constructs are appropriate for its environment – locks, events, Tasks , etc. Receiving Notifications There are situations in which a simple request-response pattern is not enough, and the client needs to receive asynchronous notifications. For example, a user might want to be notified when a new message has been published by someone that she is following. Observers is one such mechanism that enables exposing client side objects as grain-like targets to get invoked by grains. Calls to observers do not provide any indication of success or failure, as they are sent as one-way best effort message. So it is a responsibility of the application code to build a higher level reliability mechanism on top of observers where necessary. Another mechanism that can be used for delivering asynchronous messages to clients is Streams . Streams expose indications of success or failure of delivery of individual messages, and hence enable reliable communication back to the client. Client Connectivity There are two scenarios in which a cluster client can experience connectivity issues: When the IClusterClient.Connect method is called initially. When making calls on grain references which were obtained from a connected cluster client. In the first case, the Connect method will throw an exception to indicate what went wrong. This is typically (but not necessarily) a SiloUnavailableException . If this happens, the cluster client instance is unusable and should be disposed. A retry filter function can optionally be provided to the Connect method which could, for instance, wait for a specified duration before making another attempt. If no retry filter is provided, or if the retry filter returns false , the client gives up for good. If Connect returns successfully, the cluster client is guaranteed to be usable until it is disposed. This means that even if the client experiences connection issues, it will attempt to recover indefinitely. The exact recovery behavior can be configured on a GatewayOptions object provided by the ClientBuilder , e.g.: var client = new ClientBuilder() // ... .Configure<GatewayOptions>(opts => GatewayListRefreshPeriod = TimeSpan.FromMinutes(10)) // Default is 1 min. .Build(); In the second case, where a connection issue occurs during a grain call, a SiloUnavailableException will be thrown on the client side. This could be handled like so: IPlayerGrain player = client.GetGrain<IPlayerGrain>(playerId); try { await player.JoinGame(game); } catch (SiloUnavailableException) { // Lost connection to the cluster... } The grain reference is not invalidated in this situation; the call could be retried on the same reference later, when a connection might have been re-established. Dependency Injection The recommended way to create an external client in a program that uses the .NET Generic Host is to inject an IClusterClient singleton instance via dependency injection, which can then be accepted as a constructor parameter in hosted services, ASP.NET controllers, etc. [!NOTE] When co-hosting an Orleans silo in the same process that will be connecting to it, it is not necessary to manually create a client; Orleans will automatically provide one and manage its lifetime appropriately. When connecting to a cluster in a different process (e.g. on a different machine), a common pattern is to create a hosted service like this: public class ClusterClientHostedService : IHostedService { public IClusterClient Client { get; } public ClusterClientHostedService(ILoggerProvider loggerProvider) { Client = new ClientBuilder() // Appropriate client configuration here, e.g.: .UseLocalhostClustering() .ConfigureLogging(builder => builder.AddProvider(loggerProvider)) .Build(); } public async Task StartAsync(CancellationToken cancellationToken) { // A retry filter could be provided here. await Client.Connect(); } public async Task StopAsync(CancellationToken cancellationToken) { await Client.Close(); Client.Dispose(); } } The service is then registered like this: public class Program { static Task Main() { return new HostBuilder() .ConfigureServices(services => { services.AddSingleton<ClusterClientHostedService>(); services.AddSingleton<IHostedService>(sp => sp.GetService<ClusterClientHostedService>()); services.AddSingleton<IClusterClient>(sp => sp.GetService<ClusterClientHostedService>().Client); services.AddSingleton<IGrainFactory>(sp => sp.GetService<ClusterClientHostedService>().Client); }) .ConfigureLogging(builder => builder.AddConsole()) .RunConsoleAsync(); } } At this point, an IClusterClient instance could be consumed anywhere that dependency injection is supported, such as in an ASP.NET controller: public class HomeController : Controller { readonly IClusterClient _client; public HomeController(IClusterClient client) => _client = client; public IActionResult Index() { var grain = _client.GetGrain<IMyGrain>(); var model = grain.GetModel(); return View(model); } } Example Here is an extended version of the example given above of a client application that connects to Orleans, finds the player account, subscribes for updates to the game session the player is part of with an observer, and prints out notifications until the program is manually terminated. namespace PlayerWatcher { class Program { /// <summary> /// Simulates a companion application that connects to the game /// that a particular player is currently part of, and subscribes /// to receive live notifications about its progress. /// </summary> static void Main(string[] args) { RunWatcher().Wait(); // Block main thread so that the process doesn't exit. // Updates arrive on thread pool threads. Console.ReadLine(); } static async Task RunWatcher() { try { var client = new ClientBuilder() // Clustering information .Configure<ClusterOptions>(options => { options.ClusterId = \"my-first-cluster\"; options.ServiceId = \"MyOrleansService\"; }) // Clustering provider .UseAzureStorageClustering(options => options.ConnectionString = connectionString) // Application parts: just reference one of the grain interfaces that we use .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(IValueGrain).Assembly)) .Build(); // Hardcoded player ID Guid playerId = new Guid(\"{2349992C-860A-4EDA-9590-000000000006}\"); IPlayerGrain player = client.GetGrain<IPlayerGrain>(playerId); IGameGrain game = null; while (game == null) { Console.WriteLine(\"Getting current game for player {0}...\", playerId); try { game = await player.GetCurrentGame(); if (game == null) // Wait until the player joins a game { await Task.Delay(5000); } } catch (Exception exc) { Console.WriteLine(\"Exception: \", exc.GetBaseException()); } } Console.WriteLine(\"Subscribing to updates for game {0}...\", game.GetPrimaryKey()); // Subscribe for updates var watcher = new GameObserver(); await game.SubscribeForGameUpdates( await client.CreateObjectReference<IGameObserver>(watcher)); Console.WriteLine(\"Subscribed successfully. Press <Enter> to stop.\"); } catch (Exception exc) { Console.WriteLine(\"Unexpected Error: {0}\", exc.GetBaseException()); } } } /// <summary> /// Observer class that implements the observer interface. Need to pass a grain reference to an instance of this class to subscribe for updates. /// </summary> class GameObserver : IGameObserver { // Receive updates public void UpdateGameScore(string score) { Console.WriteLine(\"New game score: {0}\", score); } } } }"
  },
  "docs/host/configuration_guide/activation_garbage_collection.html": {
    "href": "docs/host/configuration_guide/activation_garbage_collection.html",
    "title": "Activation Garbage Collection | Microsoft Orleans Documentation",
    "keywords": "Activation Garbage Collection As described in the Core Concepts section, a grain activation is an in-memory instance of a grain class that gets automatically created by the Orleans runtime on an as-needed basis as a temporary physical embodiment of a grain. Activation Garbage Collection (Activation GC) is the process of removal from memory of unused grain activations. It is conceptually similar to how garbage collection of memory works in .NET. However, Activation GC only takes into consideration how long a particular grain activation has been idle. Memory usage is not used as a factor. How Activation GC Works The general process of Activation GC involves Orleans runtime in a silo periodically scanning for grain activations that have not been used at all for the configured period of time (Collection Age Limit). Once a grain activation has been idle for that long, it gets deactivated. The deactivation process begins by the runtime calling the grain’s OnDeactivateAsync() method, and completes by removing references to the grain activation object from all data structures of the silo, so that the memory is reclaimed by the .NET GC. As a result, with no burden put on the application code, only recently used grain activations stay in memory while activations that aren't used anymore get automatically removed, and system resources used by them get reclaimed by the runtime. What counts as “being active” for the purpose of grain activation collection receiving a method call receiving a reminder receiving an event via streaming What does NOT count as “being active” for the purpose of grain activation collection performing a call (to another grain or to an Orleans client) timer events arbitrary IO operations or external calls not involving Orleans framework Collection Age Limit This period of time after which an idle grain activation becomes subject to Activation GC is called Collection Age Limit. The default Collection Age Limit is 2 hours, but it can be changed globally or for individual grain classes. Explicit Control of Activation Garbage Collection Delaying Activation GC A grain activation can delay its own Activation GC, by calling this.DelayDeactivation() method: protected void DelayDeactivation(TimeSpan timeSpan) This call will ensure that this activation is not deactivated for at least the specified time duration. It takes priority over Activation Garbage Collection settings specified in the config, but does not cancel them. Therefore, this call provides an additional hook to delay the deactivation beyond what is specified in the Activation Garbage Collection settings . This call can not be used to expedite Activation Garbage Collection. A positive timeSpan value means “prevent GC of this activation for that time span”. A negative timeSpan value means “cancel the previous setting of the DelayDeactivation call and make this activation behave based on the regular Activation Garbage Collection settings”. Scenarios: 1) Activation Garbage Collection settings specify age limit of 10 minutes and the grain is making a call to DelayDeactivation(TimeSpan.FromMinutes(20)) , it will cause this activation to not be collected for at least 20 min. 2) Activation Garbage Collection settings specify age limit of 10 minutes and the grain is making a call to DelayDeactivation(TimeSpan.FromMinutes(5)) , the activation will be collected after 10 min, if no extra calls were made. 3) Activation Garbage Collection settings specify age limit of 10 minutes and the grain is making a call to DelayDeactivation(TimeSpan.FromMinutes(5)) , and after 7 minutes there is another call on this grain, the activation will be collected after 17 min from time zero, if no extra calls were made. 4) Activation Garbage Collection settings specify age limit of 10 minutes and the grain is making a call to DelayDeactivation(TimeSpan.FromMinutes(20)) , and after 7 minutes there is another call on this grain, the activation will be collected after 20 min from time zero, if no extra calls were made. Note that DelayDeactivation does not 100% guarantee that the grain activation will not get deactivated before the specified period of time expires. There are certain failure cases that may cause 'premature' deactivation of grains. That means that DelayDeactivation cannot not be used as a means to 'pin' a grain activation in memory forever or to a specific silo . DelayDeactivation is merely an optimization mechanism that can help reduce the aggregate cost of a grain getting deactivated and reactivated over time, if that matters. In most cases there should be no need to use DelayDeactivation at all. Expediting Activation GC A grain activation can also instruct the runtime to deactivate it next time it becomes idle by calling this.DeactivateOnIdle() method: protected void DeactivateOnIdle() A grain activation is considered idle if it is not processing any message at the moment. If you call DeactivateOnIdle while a grain is processing a message, it will get deactivated as soon as processing of the current message is finished. If there are any requests queued for the grain, they will be forwarded to the next activation. DeactivateOnIdle take priority over any Activation Garbage Collection settings specified in the config or DelayDeactivation . Note that this setting only applies to the grain activation from which it has been called and it does not apply to other grain activation of this type. Configuration Grain garbage collection can be configured using the GrainCollectionOptions options: mySiloHostBuilder.Configure<GrainCollectionOptions>(options => { // Set the value of CollectionAge to 10 minutes for all grain options.CollectionAge = TimeSpan.FromMinutes(10); // Override the value of CollectionAge to 5 minutes for MyGrainImplementation options.ClassSpecificCollectionAge[typeof(MyGrainImplementation).FullName] = TimeSpan.FromMinutes(5); })"
  },
  "docs/host/configuration_guide/adonet_configuration.html": {
    "href": "docs/host/configuration_guide/adonet_configuration.html",
    "title": "ADO.NET Database Configuration | Microsoft Orleans Documentation",
    "keywords": "ADO.NET Database Configuration The following sections contain links to SQL scripts to configure your database as well as the corresponding ADO.NET invariant used to configure ADO.NET providers in Orleans. These scripts are intended to be customized if needed for your deployment. Before executing scripts for Clustering, Persistence, or Reminders, one needs to create main tables with the Main scripts. Main scripts Database Script NuGet Package ADO.NET Invariant SQL Server SQLServer-Main.sql System.Data.SqlClient System.Data.SqlClient MySQL / MariaDB MySQL-Main.sql MySql.Data MySql.Data.MySqlClient PostgreSQL PostgreSQL-Main.sql Npgsql Npgsql Oracle Oracle-Main.sql ODP.net Oracle.DataAccess.Client Clustering Database Script NuGet Package ADO.NET Invariant SQL Server SQLServer-Clustering.sql System.Data.SqlClient System.Data.SqlClient MySQL / MariaDB MySQL-Clustering.sql MySql.Data MySql.Data.MySqlClient PostgreSQL PostgreSQL-Clustering.sql Npgsql Npgsql Oracle Oracle-Clustering.sql ODP.net Oracle.DataAccess.Client Persistence Database Script NuGet Package ADO.NET Invariant SQL Server SQLServer-Persistence.sql System.Data.SqlClient System.Data.SqlClient MySQL / MariaDB MySQL-Persistence.sql MySql.Data MySql.Data.MySqlClient PostgreSQL PostgreSQL-Persistence.sql Npgsql Npgsql Oracle Oracle-Persistence.sql ODP.net Oracle.DataAccess.Client Reminders Database Script NuGet Package ADO.NET Invariant SQL Server SQLServer-Reminders.sql System.Data.SqlClient System.Data.SqlClient MySQL / MariaDB MySQL-Reminders.sql MySql.Data MySql.Data.MySqlClient PostgreSQL PostgreSQL-Reminders.sql Npgsql Npgsql Oracle Oracle-Reminders.sql ODP.net Oracle.DataAccess.Client"
  },
  "docs/host/configuration_guide/client_configuration.html": {
    "href": "docs/host/configuration_guide/client_configuration.html",
    "title": "Client Configuration | Microsoft Orleans Documentation",
    "keywords": "Note If you just want to start a local silo and a local client for development purpose, look at the Local Development Configuration page. Client Configuration A client for connecting to a cluster of silos and sending requests to grains is configured programmatically via a ClientBuilder and a number of supplemental option classes. Like silo options, client option classes follow the ASP.NET Options . Add the Microsoft.Orleans.Clustering.AzureStorage nuget package to the client project. There are several key aspects of client configuration: Orleans clustering information Clustering provider Application parts Example of a client configuration: using Orleans.Hosting; var client = new ClientBuilder() // Clustering information .Configure<ClusterOptions>(options => { options.ClusterId = \"my-first-cluster\"; options.ServiceId = \"MyOrleansService\"; }) // Clustering provider .UseAzureStorageClustering(options => options.ConnectionString = connectionString) // Application parts: just reference one of the grain interfaces that we use .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(IValueGrain).Assembly)) .Build(); Let's breakdown the steps used in this sample: Orleans clustering information [...] // Clustering information .Configure<ClusterOptions>(options => { options.ClusterId = \"orleans-docker\"; options.ServiceId = \"AspNetSampleApp\"; }) [...] Here we set two things: the ClusterId to \"my-first-cluster\" : this is a unique ID for the Orleans cluster. All clients and silo that uses this ID will be able to directly talk to each other. Some will choose to use a different ClusterId for each deployments for example. the ServiceId to \"AspNetSampleApp\" : this is a unique ID for your application, that will be used by some provider (for example for persistence providers). This ID should be stable (not change) across deployments . Clustering provider [...] // Clustering provider .UseAzureStorageClustering(options => options.ConnectionString = connectionString) [...] The client will discover all gateway available in the cluster using this provider. Several providers are available, here in this sample we use the Azure Table provider. To get more detail, look in the matching section in the Server Configuration page. Application parts [...] // Application parts: just reference one of the grain interfaces that we use .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(IValueGrain).Assembly)).WithReferences()) [...]; To get more detail, look in the matching section in the Server Configuration page."
  },
  "docs/host/configuration_guide/configuring_.NET_garbage_collection.html": {
    "href": "docs/host/configuration_guide/configuring_.NET_garbage_collection.html",
    "title": "Configuring .NET Garbage Collection | Microsoft Orleans Documentation",
    "keywords": "Configuring .NET Garbage Collection For good performance, it is important to configure .NET garbage collection for the silo process the right way. The best combination of settings we found is to set gcServer=true and gcConcurrent=true . These are easy to set via the application csproj file. See below as an example: .NET Core Note: This method is not supported with SDK style projects compiling against the full .NET Framework // .csproj <PropertyGroup> <ServerGarbageCollection>true</ServerGarbageCollection> <ConcurrentGarbageCollection>true</ConcurrentGarbageCollection> </PropertyGroup> .NET Framework Note: SDK style projects compiling against the full .NET Framework should still use this configuration style // App.config <configuration> <runtime> <gcServer enabled=\"true\"/> <gcConcurrent enabled=\"true\"/> </runtime> </configuration> However, this is not as easy to do if a silo runs as part of an Azure Worker Role, which by default is configured to use workstation GC. This blog post shows how to set the same configuration for an Azure Worker Role - https://blogs.msdn.microsoft.com/cclayton/2014/06/05/server-garbage-collection-mode-in-microsoft-azure/ Note Server garbage collection is available only on multiprocessor computers . Therefore, even if you configure the Garbage Collection either via application csproj file or via the scripts on the referred blog post, if the silo is running on a (virtual) machine with a single core, you will not get the benefits of gcServer=true ."
  },
  "docs/host/configuration_guide/configuring_ADO.NET_providers.html": {
    "href": "docs/host/configuration_guide/configuring_ADO.NET_providers.html",
    "title": "Configuring ADO.NET Providers | Microsoft Orleans Documentation",
    "keywords": "Configuring ADO.NET Providers Any reliable deployment of Orleans requires using persistent storage to keep system state, specifically Orleans cluster membership table and reminders. One of the available options is using a SQL database via the ADO.NET providers. In order to use ADO.NET for persistence, clustering or reminders, one needs to configure the ADO.NET providers as part of the silo configuration, and, in case of clustering, also as part of the client configurations. The silo configuration code should look like this: var siloHostBuilder = new SiloHostBuilder(); var invariant = \"System.Data.SqlClient\"; // for Microsoft SQL Server var connectionString = \"Data Source=(localdb)\\MSSQLLocalDB;Initial Catalog=Orleans;Integrated Security=True;Pooling=False;Max Pool Size=200;Asynchronous Processing=True;MultipleActiveResultSets=True\"; //use AdoNet for clustering siloHostBuilder.UseAdoNetClustering(options => { options.Invariant = invariant; options.ConnectionString = connectionString; }); //use AdoNet for reminder service siloHostBuilder.UseAdoNetReminderService(options => { options.Invariant = invariant; options.ConnectionString = connectionString; }); //use AdoNet for Persistence siloHostBuilder.AddAdoNetGrainStorage(\"GrainStorageForTest\", options => { options.Invariant = invariant; options.ConnectionString = connectionString; }); The client configuration code should look like this: var siloHostBuilder = new SiloHostBuilder(); var invariant = \"System.Data.SqlClient\"; var connectionString = \"Data Source=(localdb)\\MSSQLLocalDB;Initial Catalog=Orleans;Integrated Security=True;Pooling=False;Max Pool Size=200;Asynchronous Processing=True;MultipleActiveResultSets=True\"; //use AdoNet for clustering siloHostBuilder.UseAdoNetClustering(options => { options.Invariant = invariant; options.ConnectionString = connectionString; }); Where the ConnectionString is set to a valid AdoNet Server connection string. In order to use ADO.NET providers for persistence, reminders or clustering, there are scripts for creating database artifacts, to which all servers that will be hosting Orleans silos need to have access. Lack of access to the target database is a typical mistake we see developers making. The scripts will be copied to project directory \\OrleansAdoNetContent where each supported ADO.NET extensions has its own directory, after you install or do a nuget restore on the AdoNet extension nugets. We split AdoNet nugets into per feature nugets: Microsoft.Orleans.Clustering.AdoNet for clustering, Microsoft.Orleans.Persistence.AdoNet for persistence and Microsoft.Orleans.Reminders.AdoNet for reminders."
  },
  "docs/host/configuration_guide/index.html": {
    "href": "docs/host/configuration_guide/index.html",
    "title": "Orleans Configuration Guide | Microsoft Orleans Documentation",
    "keywords": "Orleans Configuration Guide This Configuration Guide explains the key configuration parameters and how they should be used for most typical usage scenarios. Orleans can be used in a variety of configurations that fit different usage scenarios, such as local single node deployment for development and testing, cluster of servers, multi-instance Azure worker role, etc. This guide provides instructions for the key configuration parameters that are necessary to make Orleans run in one of the target scenarios. There are also other configuration parameters that primarily help fine tune Orleans for better performance. Silos and Clients are configured programmatically via a SiloHostBuilder and ClientBuilder respectively and a number of supplemental option classes. Option classes in Orleans follow the ASP.NET Options pattern, and can be loaded via files, environment variables etc. Please refer to the Options pattern documentation for more information. If you want to configure a silo and a client for local development, look at the Local Development Configuration section. The Server Configuration and Client Configuration sections of the guide cover configuring silos and clients, respectively. The section on Typical Configurations provides a summary of a few common configurations. A list of important core options that can be configured can be found on this section . Important : Make sure you properly configure .NET Garbage Collection as detailed in Configuring .NET Garbage Collection ."
  },
  "docs/host/configuration_guide/list_of_options_classes.html": {
    "href": "docs/host/configuration_guide/list_of_options_classes.html",
    "title": "List of Options Classes | Microsoft Orleans Documentation",
    "keywords": "List of Options Classes All Options classes used to configure Orleans should be in the Orleans.Configuration namespace. Many of them have helper methods in the Orleans.Hosting namespace. Common core options for IClientBuilder and ISiloHostBuilder Option type Used for ClusterOptions Setting the ClusterId and the ServiceId NetworkingOptions Setting timeout values for sockets and opened connections SerializationProviderOptions Setting the serialization providers TypeManagementOptions Setting the refresh period of the Type Map (see Heterogeneous silos and Versioning) IClientBuilder specific options Option type Used for ClientMessagingOptions Setting the number of connections to keep open, and specify what network interface to use ClientStatisticsOption Setting various setting related to statistics output GatewayOptions Setting the refresh period of the list of available gateways StaticGatewayListProviderOptions Setting URIs a client will use to connect to cluster ISiloHostBuilder specific options Option type Used for ClusterMembershipOptions Settings for cluster membership ConsistentRingOptions Configuration options for consistent hashing algorithm, used to balance resource allocations across the cluster. EndpointOptions Setting the Silo endpoint options GrainCollectionOptions Options for grain garbage collection GrainVersioningOptions Governs grain implementation selection in heterogeneous deployments LoadSheddingOptions Settings for load shedding configuration. Must have a registered implementation of IHostEnvironmentStatistics such as through builder.UsePerfCounterEnvironmentStatistics() (Windows only) for LoadShedding to function. MultiClusterOptions Options for configuring multi-cluster support PerformanceTuningOptions Performance tuning options (networking, number of threads) ProcessExitHandlingOptions Configure silo behavior on process exit SchedulingOptions Configuring scheduler behavior SiloMessagingOptions Configuring global messaging options that are silo related. SiloOptions Setting the name of the Silo SiloStatisticsOptions Setting various setting related to statistics output TelemetryOptions Setting telemetry consumer settings"
  },
  "docs/host/configuration_guide/local_development_configuration.html": {
    "href": "docs/host/configuration_guide/local_development_configuration.html",
    "title": "Local development configuration | Microsoft Orleans Documentation",
    "keywords": "Local development configuration For a working sample application that targets Orleans 3.0 see: https://github.com/dotnet/orleans/tree/master/Samples/3.0/HelloWorld . The sample hosts the client and the silo in .NET Core console applications that work in different platforms, while the grains and interfaces target .NET Standard 2.0. For older versions of Orleans please see their respective Sample projects: https://github.com/dotnet/orleans/tree/master/Samples/ . Silo configuration For local development, please refer to the below example of how to configure a silo for that case. It configures and starts a silo listening on loopback address and 11111 and 30000 as silo and gateway ports respectively. Add the Microsoft.Orleans.Server NuGet meta-package to the project. After you get comfortable with the API, you can pick and choose which exact packages included in Microsoft.Orleans.Server you actually need, and reference them instead. PM> Install-Package Microsoft.Orleans.Server You need to configure ClusterOptions via ISiloBuilder.Configure method, specify that you want DevelopmentClustering as your clustering choice with this silo being the primary, and then configure silo endpoints. ConfigureApplicationParts call explicitly adds the assembly with grain classes to the application setup. It also adds any referenced assembly due to the WithReferences extension. After these steps are completed, the silo host gets built and the silo gets started. You can create an empty console application project targeting .NET Framework 4.6.1 or higher for hosting a silo, as well as a .NET Core console application. Here is an example of how a local silo can be started: public class Program { public static async Task Main(string[] args) { try { var host = await StartSilo(); Console.WriteLine(\"Press Enter to terminate...\"); Console.ReadLine(); await host.StopAsync(); return; } catch (Exception ex) { Console.WriteLine(ex); return; } } private static async Task<ISiloHost> StartSilo() { var builder = new SiloHostBuilder() // Use localhost clustering for a single local silo .UseLocalhostClustering() // Configure ClusterId and ServiceId .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"MyAwesomeService\"; }) // Configure connectivity .Configure<EndpointOptions>(options => options.AdvertisedIPAddress = IPAddress.Loopback) // Configure logging with any logging framework that supports Microsoft.Extensions.Logging. // In this particular case it logs using the Microsoft.Extensions.Logging.Console package. .ConfigureLogging(logging => logging.AddConsole()); var host = builder.Build(); await host.StartAsync(); return host; } } Client configuration For local development, please refer to the below example of how to configure a client for that case. It configures a client that would connect to a loopback silo. Add the Microsoft.Orleans.Client NuGet meta-package to the project. After you get comfortable with the API, you can pick and choose which exact packages included in Microsoft.Orleans.Client you actually need, and reference them instead. PM> Install-Package Microsoft.Orleans.Client You need to configure ClientBuilder with a cluster ID that matches the one you specified for local silo and specify static clustering as your clustering choice pointing it to the gateway port of the silo ConfigureApplicationParts call explicitly adds the assembly with grain interfaces to the application setup. After these steps are completed, we can build the client and Connect() method on it to connect to the cluster. You can create an empty console application project targeting .NET Framework 4.6.1 or higher for running a client or reuse the console application project you created for hosting a silo. Here is an example of how a client can connect to a local silo: client = new ClientBuilder() // Use localhost clustering for a single local silo .UseLocalhostClustering() // Configure ClusterId and ServiceId .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"MyAwesomeService\"; }) .ConfigureLogging(logging => logging.AddConsole()) var client = builder.Build(); await client.Connect();"
  },
  "docs/host/configuration_guide/serialization.html": {
    "href": "docs/host/configuration_guide/serialization.html",
    "title": "Serialization and Writing Custom Serializers | Microsoft Orleans Documentation",
    "keywords": "Serialization and Writing Custom Serializers Orleans has an advanced and extensible serialization framework. Orleans serializes data types passed in grain request and response messages as well as grain persistent state objects. As part of this framework, Orleans automatically generates serialization code for those data types. In addition to generating a more efficient serialization/deserialization for types that are already .NET-serializable, Orleans also tries to generate serializers for types used in grain interfaces that are not .NET-serializable. The framework also includes a set of efficient built-in serializers for frequently used types: lists, dictionaries, strings, primitives, arrays, etc. There are 2 important features of Orleans's serializer that set it apart from a lot of other third party serialization frameworks: dynamic types/arbitrary polymorphism and object identity. Dynamic types and arbitrary polymorphism - Orleans does not put any restrictions on the types that can be passed in grain calls and maintains the dynamic nature of the actual data type. That means, for example, that if the method in the grain interfaces is declared to accept IDictionary but at runtime the sender passes SortedDictionary , the receiver will indeed get SortedDictionary (although the \"static contract\"/grain interface did not specify this behaviour). Maintaining Object identity - if the same object is passed multiple types in the arguments of a grain call or is indirectly pointed more than once from the arguments, Orleans will serialize it only once. At the receiver side Orleans will restore all references correctly, so that two pointers to the same object still point to the same object after deserialization as well. Object identity is important to preserve in scenarios like the following. Imagine actor A is sending a dictionary with 100 entries to actor B, and 10 of the keys in the dictionary point to the same object, obj, on A's side. Without preserving object identity, B would receive a dictionary of 100 entries with those 10 keys pointing to 10 different clones of obj. With object identity preserved, the dictionary on B's side looks exactly like on A's side with those 10 keys pointing to a single object obj. The above two behaviours are provided by the standard .NET binary serializer and it was therefore important for us to support this standard and familiar behaviour in Orleans as well. Generated Serializers Orleans uses the following rules to decide which serializers to generate. The rules are: 1) Scan all types in all assemblies which reference the core Orleans library. 2) Out of those assemblies: generate serializers for types that are directly referenced in grain interfaces method signatures or state class signature or for any type that is marked with [Serializable] attribute. 3) In addition, a grain interface or implementation project can point to arbitrary types for serialization generation by adding a [KnownType] or [KnownAssembly] assembly level attributes to tell code generator to generate serializers for a specific types or all eligible types within an assembly. Serialization Providers Orleans supports integration with third-party serializers using a provider model. This requires an implementation of the IExternalSerializer type described in the custom serialization section of this document. Integrations for some common serializers are maintained alongside Orleans, for example: Protocol Buffers : Orleans.Serialization.ProtobufSerializer from the Microsoft.Orleans.OrleansGoogleUtils NuGet package. Bond : Orleans.Serialization.BondSerializer from the Microsoft.Orleans.Serialization.Bond NuGet package. Newtonsoft.Json AKA Json.NET : Orleans.Serialization.OrleansJsonSerializer from the core Orleans library. Custom implementation of IExternalSerializer is described in the Writing Custom Serializers section below. Configuration It is important to ensure that serialization configuration is identical on all clients and silos. If configurations are not consistent, serialization errors may occur. Serialization providers, which implement IExternalSerializer , can be specified using the SerializationProviders property of ClientConfiguration and GlobalConfiguration in code: var cfg = new ClientConfiguration(); cfg.SerializationProviders.Add(typeof(FantasticSerializer).GetTypeInfo()); var cfg = new GlobalConfiguration(); cfg.SerializationProviders.Add(typeof(FantasticSerializer).GetTypeInfo()); Alternatively, they can be specified in XML configuration under the <SerializationProviders /> property of <Messaging> : <Messaging> <SerializationProviders> <Provider type=\"GreatCompany.FantasticSerializer, GreatCompany.SerializerAssembly\"/> </SerializationProviders> </Messaging> In both cases, multiple providers can be configured. The collection is ordered, meaning that if a provider which can serialize types A and B is specified before a provider which can only serialize type B , then the latter provider will not be used. Writing Custom Serializers In addition to automatic serialization generation, application code can provide custom serialization for types it chooses. Orleans recommends using the automatic serialization generation for the majority of your application types and only write custom serializers in rare cases when you believe it is possible to get improved performance by hand-coding serializers. This note describes how to do so, and identifies some specific cases when it might be helpful. There are 3 ways in which applications can customize serialization: Add serialization methods to your type and mark them with appropriate attributes ( CopierMethod , SerializerMethod , DeserializerMethod ). This method is preferable for types that your application owns, that is, the types that you can add new methods to. Implement IExternalSerializer and register it during configuration time. This method is useful for integrating an external serialization library. Write a separate static class annotated with an [Serializer(typeof(YourType))] with the 3 serialization methods in it and the same attributes as above. This method is useful for types that the application does not own, for example, types defined in other libraries your application has no control over. Each of these methods are detailed in the sections below. Introduction Orleans serialization happens in three stages: objects are immediately deep copied to ensure isolation; before being put on the wire; objects are serialized to a message byte stream; and when delivered to the target activation, objects are recreated (deserialized) from the received byte stream. Data types that may be sent in messages -- that is, types that may be passed as method arguments or return values -- must have associated routines that perform these three steps. We refer to these routines collectively as the serializers for a data type. The copier for a type stands alone, while the serializer and deserializer are a pair that work together. You can provide just a custom copier, or just a custom serializer and a custom deserializer, or you can provide custom implementations of all three. Serializers are registered for each supported data type at silo start-up and whenever an assembly is loaded. Registration is necessary for custom serializer routines for a type to be used. Serializer selection is based on the dynamic type of the object to be copied or serialized. For this reason, there is no need to create serializers for abstract classes or interfaces, because they will never be used. When to Consider Writing a Custom Serializer It is rare that a hand-crafted serializer routine will perform meaningfully better than the generated versions. If you are tempted to do so, you should first consider the following options: If there are fields or properties within your data types that don't have to be serialized or copied, you can mark them with the NonSerialized attribute. This will cause the generated code to skip these fields when copying and serializing. Use Immutable<T> & [Immutable] where possible to avoid copying immutable data. The section on Optimizing Copying below for details. If you're avoiding using the standard generic collection types, don't. The Orleans runtime contains custom serializers for the generic collections that use the semantics of the collections to optimize copying, serializing, and deserializing. These collections also have special \"abbreviated\" representations in the serialized byte stream, resulting in even more performance advantages. For instance, a Dictionary<string, string> will be faster than a List<Tuple<string, string>> . The most common case where a custom serializer can provide a noticeable performance gain is when there is significant semantic information encoded in the data type that is not available by simply copying field values. For instance, arrays that are sparsely populated may often be more efficiently serialized by treating the array as a collection of index/value pairs, even if the application keeps the data as a fully realized array for speed of operation. A key thing to do before writing a custom serializer is to make sure that the generated serializer is really hurting your performance. Profiling will help a bit here, but even more valuable is running end-to-end stress tests of your application with varying serialization loads to gauge the system-level impact, rather than the micro-impact of serialization. For instance, building a test version that passes no parameters to or results from grain methods, simply using canned values at either end, will zoom in on the impact of serialization and copying on system performance. Method 1: Adding Serialization Methods to the Type All serializer routines should be implemented as static members of the class or struct they operate on. The names shown here are not required; registration is based on the presence of the respective attributes, not on method names. Note that serializer methods need not be public. Unless you implement all three serialization routines, you should mark your type with the Serializable attribute so that the missing methods will be generated for you. Copier Copier methods are flagged with the Orleans.CopierMethod attribute: [CopierMethod] static private object Copy(object input, ICopyContext context) { ... } Copiers are usually the simplest serializer routines to write. They take an object, guaranteed to be of the same type as the type the copier is defined in, and must return a semantically-equivalent copy of the object. If, as part of copying the object, a sub-object needs to be copied, the best way to do so is to use the SerializationManager's DeepCopyInner routine: var fooCopy = SerializationManager.DeepCopyInner(foo, context); It is important to use DeepCopyInner, instead of DeepCopy, in order to maintain the object identity context for the full copy operation. Maintaining Object Identity An important responsibility of a copy routine is to maintain object identity. The Orleans runtime provides a helper class for this. Before copying a sub-object \"by hand\" (i.e., not by calling DeepCopyInner), check to see if it has already been referenced as follows: var fooCopy = context.CheckObjectWhileCopying(foo); if (fooCopy == null) { // Actually make a copy of foo context.RecordObject(foo, fooCopy); } The last line, the call to RecordObject , is required so that possible future references to the same object as foo references will get found properly by CheckObjectWhileCopying . Note that this should only be done for class instances, not struct instances or .NET primitives (strings, Uris, enums). If you use DeepCopyInner to copy sub-objects, then object identity is handled for you. Serializer Serialization methods are flagged with the SerializerMethod attribute: [SerializerMethod] static private void Serialize(object input, ISerializationContext context, Type expected) { ... } As with copiers, the \"input\" object passed to a serializer is guaranteed to be an instance of the defining type. The \"expected\" type may be ignored; it is based on compile-time type information about the data item, and is used at a higher level to form the type prefix in the byte stream. To serialize sub-objects, use the SerializationManager 's SerializeInner routine: SerializationManager.SerializeInner(foo, context, typeof(FooType)); If there is no particular expected type for foo, then you can pass null for the expected type. The BinaryTokenStreamWriter class provides a wide variety of methods for writing data to the byte stream. An instance of the class can be obtained via the context.StreamWriter property. See the class for documentation. Deserializer Deserialization methods are flagged with the DeserializerMethod attribute: [DeserializerMethod] static private object Deserialize(Type expected, IDeserializationContext context) { ... } The \"expected\" type may be ignored; it is based on compile-time type information about the data item, and is used at a higher level to form the type prefix in the byte stream. The actual type of the object to be created will always be the type of the class in which the deserializer is defined. To deserialize sub-objects, use the SerializationManager 's DeserializeInner routine: var foo = SerializationManager.DeserializeInner(typeof(FooType), context); Or, alternatively: var foo = SerializationManager.DeserializeInner<FooType>(context); If there is no particular expected type for foo, use the non-generic DeserializeInner variant and pass null for the expected type. The BinaryTokenStreamReader class provides a wide variety of methods for reading data from the byte stream. An instance of the class can be obtained via the context.StreamReader property. See the class for documentation. Method 2: Writing a Serializer Provider In this method, you implement Orleans.Serialization.IExternalSerializer and add it to the SerializationProviders property on both ClientConfiguration on the client and GlobalConfiguration on the silos. Configuration is detailed in the Serialization Providers section above. Implementation of IExternalSerializer follows the pattern described for serialization methods from Method 1 above with the addition of an Initialize method and an IsSupportedType method which Orleans uses to determine if the serializer supports a given type. This is the interface definition: public interface IExternalSerializer { /// <summary> /// Initializes the external serializer. Called once when the serialization manager creates /// an instance of this type /// </summary> void Initialize(Logger logger); /// <summary> /// Informs the serialization manager whether this serializer supports the type for serialization. /// </summary> /// <param name=\"itemType\">The type of the item to be serialized</param> /// <returns>A value indicating whether the item can be serialized.</returns> bool IsSupportedType(Type itemType); /// <summary> /// Tries to create a copy of source. /// </summary> /// <param name=\"source\">The item to create a copy of</param> /// <param name=\"context\">The context in which the object is being copied.</param> /// <returns>The copy</returns> object DeepCopy(object source, ICopyContext context); /// <summary> /// Tries to serialize an item. /// </summary> /// <param name=\"item\">The instance of the object being serialized</param> /// <param name=\"context\">The context in which the object is being serialized.</param> /// <param name=\"expectedType\">The type that the deserializer will expect</param> void Serialize(object item, ISerializationContext context, Type expectedType); /// <summary> /// Tries to deserialize an item. /// </summary> /// <param name=\"context\">The context in which the object is being deserialized.</param> /// <param name=\"expectedType\">The type that should be deserialized</param> /// <returns>The deserialized object</returns> object Deserialize(Type expectedType, IDeserializationContext context); } Method 3: Writing a Serializer for Individual Types In this method you write a new class annotated with an attribute [SerializerAttribute(typeof(TargetType))] , where TargetType is the type which is being serialized, and implement the 3 serialization routines. The rules for how to write those routines are identical to method 1. Orleans uses the [SerializerAttribute(typeof(TargetType))] to determine that this class is a serializer for TargetType and this attribute can be specified multiple times on the same class if it's able to serialize multiple types. Below is an example for such a class: public class User { public User BestFriend { get; set; } public string NickName { get; set; } public int FavoriteNumber { get; set; } public DateTimeOffset BirthDate { get; set; } } [Orleans.CodeGeneration.SerializerAttribute(typeof(User))] internal class UserSerializer { [CopierMethod] public static object DeepCopier(object original, ICopyContext context) { var input = (User) original; var result = new User(); // Record 'result' as a copy of 'input'. Doing this immediately after construction allows for // data structures which have cyclic references or duplicate references. // For example, imagine that 'input.BestFriend' is set to 'input'. In that case, failing to record // the copy before trying to copy the 'BestFriend' field would result in infinite recursion. context.RecordCopy(original, result); // Deep-copy each of the fields. result.BestFriend = (User)context.SerializationManager.DeepCopy(input.BestFriend); result.NickName = input.NickName; // strings in .NET are immutable, so they can be shallow-copied. result.FavoriteNumber = input.FavoriteNumber; // ints are primitive value types, so they can be shallow-copied. result.BirthDate = (DateTimeOffset)context.SerializationManager.DeepCopy(input.BirthDate); return result; } [SerializerMethod] public static void Serializer(object untypedInput, ISerializationContext context, Type expected) { var input = (User) untypedInput; // Serialize each field. SerializationManager.SerializeInner(input.BestFriend, context); SerializationManager.SerializeInner(input.NickName, context); SerializationManager.SerializeInner(input.FavoriteNumber, context); SerializationManager.SerializeInner(input.BirthDate, context); } [DeserializerMethod] public static object Deserializer(Type expected, IDeserializationContext context) { var result = new User(); // Record 'result' immediately after constructing it. As with with the deep copier, this // allows for cyclic references and de-duplication. context.RecordObject(result); // Deserialize each field in the order that they were serialized. result.BestFriend = SerializationManager.DeserializeInner<User>(context); result.NickName = SerializationManager.DeserializeInner<string>(context); result.FavoriteNumber = SerializationManager.DeserializeInner<int>(context); result.BirthDate = SerializationManager.DeserializeInner<DateTimeOffset>(context); return result; } } Serializing Generic Types The TargetType parameter of [Serializer(typeof(TargetType))] can be an open-generic type, for example, MyGenericType<> . In that case, the serializer class must have the same generic parameters as the target type. Orleans will create a concrete version of the serializer at runtime for every concrete MyGenericType<T> type which is serialized, for example, one for each of MyGenericType<int> and MyGenericType<string> . Hints for Writing Serializers and Deserializers Often the simplest way to write a serializer/deserializer pair is to serialize by constructing a byte array and writing the array length to the stream, followed by the array itself, and then deserialize by reversing the process. If the array is fixed-length, you can omit it from the stream. This works well when you have a data type that you can represent compactly and that doesn't have sub-objects that might be duplicated (so you don't have to worry about object identity). Another approach, which is the approach the Orleans runtime takes for collections such as dictionaries, works well for classes with significant and complex internal structure: use instance methods to access the semantic content of the object, serialize that content, and deserialize by setting the semantic contents rather than the complex internal state. In this approach, inner objects are written using SerializeInner and read using DeserializeInner. In this case, it is common to write a custom copier, as well. If you write a custom serializer, and it winds up looking like a sequence of calls to SerializeInner for each field in the class, you don't need a custom serializer for that class. Fallback Serialization Orleans supports transmission of arbitrary types at runtime and therefore the in-built code generator cannot determine the entire set of types which will be transmitted ahead of time. Additionally, certain types cannot have serializers generated for them because they are inaccessible (for example, private ) or have fields which are inaccessible (for example, readonly ). Therefore, there is a need for just-in-time serialization of types which were unexpected or could not have serializers generated ahead-of-time. The serializer responsible for these types is called the fallback serializer . Orleans ships with two fallback serializers: Orleans.Serialization.BinaryFormatterSerializer which uses .NET's BinaryFormatter ; and Orleans.Serialization.ILBasedSerializer which emits CIL instructions at runtime to create serializers which leverage Orleans' serialization framework to serialize each field. This means that if an inaccessible type MyPrivateType contains a field MyType which has a custom serializer, that custom serializer will be used to serialize it. The fallback serializer can be configured using the FallbackSerializationProvider property on both ClientConfiguration on the client and GlobalConfiguration on the silos. var cfg = new ClientConfiguration(); cfg.FallbackSerializationProvider = typeof(FantasticSerializer).GetTypeInfo(); var cfg = new GlobalConfiguration(); cfg.FallbackSerializationProvider = typeof(FantasticSerializer).GetTypeInfo(); Alternatively, the fallback serialization provider can be specified in XML configuration: <Messaging> <FallbackSerializationProvider type=\"GreatCompany.FantasticFallbackSerializer, GreatCompany.SerializerAssembly\"/> </Messaging> BinaryFormatterSerializer is the default fallback serializer. Exception Serialization Exceptions are serialized using the fallback serializer . Using the default configuration, BinaryFormatterSerializer is the fallback serializer and so the ISerializable pattern must be followed in order to ensure correct serialization of all properties in an exception type. Here is an example of an exception type with correctly implemented serialization: [Serializable] public class MyCustomException : Exception { public string MyProperty { get; } public MyCustomException(string myProperty, string message) : base(message) { this.MyProperty = myProperty; } public MyCustomException(string transactionId, string message, Exception innerException) : base(message, innerException) { this.MyProperty = transactionId; } // Note: This is the constructor called by BinaryFormatter during deserialization public MyCustomException(SerializationInfo info, StreamingContext context) : base(info, context) { this.MyProperty = info.GetString(nameof(this.MyProperty)); } // Note: This method is called by BinaryFormatter during serialization public override void GetObjectData(SerializationInfo info, StreamingContext context) { base.GetObjectData(info, context); info.AddValue(nameof(this.MyProperty), this.MyProperty); } } Optimize Copying Using Immutable Types Orleans has a feature that can be used to avoid some of the overhead associated with serializing messages containing immutable types. This section describes the feature and its application, starting with context on where it is relevant. Serialization in Orleans When a grain method is invoked, the Orleans runtime makes a deep copy of the method arguments and forms the request out of the copies. This protects against the calling code modifying the argument objects before the data is passed to the called grain. If the called grain is on a different silo, then the copies are eventually serialized into a byte stream and sent over the network to the target silo, where they are deserialized back into objects. If the called grain is on the same silo, then the copies are handed directly to the called method. Return values are handled the same way: first copied, then possibly serialized and deserialized. Note that all 3 processes, copying, serializing, and deserializing, respect object identity. In other words, if you pass a list that has the same object in it twice, on the receiving side you'll get a list with the same object in it twice, rather than with two objects with the same values in them. Optimizing Copying In many cases, the deep copying is unnecessary. For instance, a possible scenario is a web front-end that receives a byte array from its client and passes that request, including the byte array, on to a grain for processing. The front-end process doesn't do anything with the array once it has passed it on to the grain; in particular, it doesn't reuse the array to receive a future request. Inside the grain, the byte array is parsed to fetch the input data, but not modified. The grain returns another byte array that it has created to get passed back to the web client; it discards the array as soon as it returns it. The web front-end passes the result byte array back to its client, without modification. In such a scenario, there is no need to copy either the request or response byte arrays. Unfortunately, the Orleans runtime can't figure this out by itself, since it can't tell whether or not the arrays are modified later on by the web front-end or by the grain. In the best of all possible worlds, we'd have some sort of .NET mechanism for indicating that a value is no longer modified; lacking that, we've added Orleans-specific mechanisms for this: the Immutable<T> wrapper class and the [Immutable] attribute. Using Immutable<T> The Orleans.Concurrency.Immutable<T> wrapper class is used to indicate that a value may be considered immutable; that is, the underlying value will not be modified, so no copying is required for safe sharing. Note that using Immutable<T> implies that neither the provider of the value nor the recipient of the value will modify it in the future; it is not a one-sided commitment, but rather a mutual dual-side commitment. Using Immutable<T> is simple: in your grain interface, instead of passing T , pass Immutable<T> . For instance, in the above described scenario, the grain method that was: Task<byte[]> ProcessRequest(byte[] request); Becomes: Task<Immutable<byte[]>> ProcessRequest(Immutable<byte[]> request); To create an Immutable<T> , simply use the constructor: Immutable<byte[]> immutable = new Immutable<byte[]>(buffer); To get the value inside the immutable, use the .Value property: byte[] buffer = immutable.Value; Using [Immutable] For user-defined types, the [Orleans.Concurrency.Immutable] attribute can be added to the type. This instructs Orleans' serializer to avoid copying instances of this type. The following code snippet demonstrates using [Immutable] to denote an immutable type. This type will not be copied during transmission. [Immutable] public class MyImmutableType { public MyImmutableType(int value) { this.MyValue = value; } public int MyValue { get; } } Immutability in Orleans For Orleans' purposes, immutability is a rather strict statement: the contents of the data item will not be modified in any way that could change the item's semantic meaning, or that would interfere with another thread simultaneously accessing the item. The safest way to ensure this is to simply not modify the item at all: bitwise immutability, rather than logical immutability. In some cases it is safe to relax this to logical immutability, but care must be taken to ensure that the mutating code is properly thread-safe; because dealing with multithreading is complex, and uncommon in an Orleans context, we strongly recommend against this approach and recommend sticking to bitwise immutability. Serialization Best Practices Serialization serves two primary purposes in Orleans: As a wire format for transmitting data between grains and clients at runtime. As a storage format for persisting long-lived data for later retrieval. The serializers generated by Orleans are suitable for the first purpose due to their flexibility, performance, and versatility. They are not as suitable for the second purpose, since they are not explicitly version-tolerant. It is recommended that users configure a version-tolerant serializer such as Protocol Buffers for persistent data. Protocol Buffers is supported via Orleans.Serialization.ProtobufSerializer from the Microsoft.Orleans.OrleansGoogleUtils NuGet package. The best-practices for the particular serializer of choice should be used in order to ensure version-tolerance. Third-party serializers can be configured using the SerializationProviders configuration property as described above."
  },
  "docs/host/configuration_guide/server_configuration.html": {
    "href": "docs/host/configuration_guide/server_configuration.html",
    "title": "Server Configuration | Microsoft Orleans Documentation",
    "keywords": "Note If you want to start a local silo and a local client for development purposes, look at the Local Development Configuration page Server Configuration A silo is configured programmatically via SiloHostBuilder and a number of supplemental option classes. Option classes in Orleans follow the ASP.NET Options pattern, and can be loaded via files, environment variables, etc. There are several key aspects of silo configuration: Orleans clustering information Clustering provider Endpoints to use for silo-to-silo and client-to-silo communications Application parts This is an example of a silo configuration that defines cluster information, uses Azure clustering, and configures the application parts: var silo = new SiloHostBuilder() // Clustering information .Configure<ClusterOptions>(options => { options.ClusterId = \"my-first-cluster\"; options.ServiceId = \"AspNetSampleApp\"; }) // Clustering provider .UseAzureStorageClustering(options => options.ConnectionString = connectionString) // Endpoints .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) // Application parts: just reference one of the grain implementations that we use .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(ValueGrain).Assembly).WithReferences()) // Now create the silo! .Build(); Let's breakdown the steps used in this sample: Orleans clustering information [...] // Clustering information .Configure<ClusterOptions>(options => { options.ClusterId = \"my-first-cluster\"; options.ServiceId = \"AspNetSampleApp\"; }) [...] Here we do two things: Set the ClusterId to \"my-first-cluster\" : this is a unique ID for the Orleans cluster. All clients and silos that use this ID will be able to talk directly to each other. You can choose to use a different ClusterId for different deployments, though. Set the ServiceId to \"AspNetSampleApp\" : this is a unique ID for your application that will be used by some providers, such as persistence providers. This ID should remain stable and not change across deployments . Clustering provider [...] // Clustering provider .UseAzureStorageClustering(options => options.ConnectionString = connectionString) [...] Usually, a service built on Orleans is deployed on a cluster of nodes, either on dedicated hardware or in Azure. For development and basic testing, Orleans can be deployed in a single node configuration. When deployed to a cluster of nodes, Orleans internally implements a set of protocols to discover and maintain membership of Orleans silos in the cluster, including detection of node failures and automatic reconfiguration. For reliable management of cluster membership, Orleans uses Azure Table, SQL Server, or Apache ZooKeeper for synchronization of nodes. In this sample, we are using Azure Table as the membership provider. Endpoints var silo = new SiloHostBuilder() [...] // Endpoints .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) [...] An Orleans silo has two typical types of endpoint configuration: Silo-to-silo endpoints, used for communication between silos in the same cluster Client-to-silo endpoints (or gateway), used for communication between clients and silos in the same cluster In the sample, we are using the helper method .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) which sets the port used for silo-to-silo communication to 11111 and and the port for the gateway to 30000 . This method will detect which interface to listen to. This method should be sufficient in most cases, but you can customize it further if you need to. Here is an example of how to use an external IP address with some port-forwarding: [...] .Configure<EndpointOptions>(options => { // Port to use for Silo-to-Silo options.SiloPort = 11111; // Port to use for the gateway options.GatewayPort = 30000; // IP Address to advertise in the cluster options.AdvertisedIPAddress = IPAddress.Parse(\"172.16.0.42\"); // The socket used for silo-to-silo will bind to this endpoint options.GatewayListeningEndpoint = new IPEndPoint(IPAddress.Any, 40000); // The socket used by the gateway will bind to this endpoint options.SiloListeningEndpoint = new IPEndPoint(IPAddress.Any, 50000); }) [...] Internally, the silo will listen on 0.0.0.0:40000 and 0.0.0.0:50000 , but the value published in the membership provider will be 172.16.0.42:11111 and 172.16.0.42:30000 . Application parts [...] // Application parts: just reference one of the grain implementations that we use .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(ValueGrain).Assembly).WithReferences()) [...]; Although this step is not technically required (if not configured, Orleans will scan all assemblies in the current folder), developers are encouraged to configure this. This step will help Orleans to load user assemblies and types. These assemblies are referred to as Application Parts. All Grains, Grain Interfaces, and Serializers are discovered using Application Parts. Application Parts are configured using IApplicationPartsManager , which can be accessed using the ConfigureApplicationParts extension method on IClientBuilder and ISiloHostBuilder . The ConfigureApplicationParts method accepts a delegate, Action<IApplicationPartManager> . The following extension methods on IApplicationPartManager support common uses: AddApplicationPart(assembly) a single assembly can be added using this extension method. AddFromAppDomain() adds all assemblies currently loaded in the AppDomain . AddFromApplicationBaseDirectory() loads and adds all assemblies in the current base path (see AppDomain.BaseDirectory ). Assemblies added by the above methods can be supplemented using the following extension methods on their return type, IApplicationPartManagerWithAssemblies : WithReferences() adds all referenced assemblies from the added parts. This immediately loads any transitively referenced assemblies. Assembly loading errors are ignored. WithCodeGeneration() generates support code for the added parts and adds it to the part manager. Note that this requires the Microsoft.Orleans.OrleansCodeGenerator package to be installed and is commonly referred to as runtime code generation. Type discovery requires that the provided Application Parts include specific attributes. Adding the build-time code generation package ( Microsoft.Orleans.CodeGenerator.MSBuild or Microsoft.Orleans.OrleansCodeGenerator.Build ) to each project containing Grains, Grain Interfaces, or Serializers is the recommended approach for ensuring that these attributes are present. Build-time code generation only supports C#. For F#, Visual Basic, and other .NET languages, code can be generated during configuration time via the WithCodeGeneration() method described above. More info regarding code generation could be found in the corresponding section ."
  },
  "docs/host/configuration_guide/shutting_down_orleans.html": {
    "href": "docs/host/configuration_guide/shutting_down_orleans.html",
    "title": "Shutting down Orleans | Microsoft Orleans Documentation",
    "keywords": "This document explains how to gracefully shutdown an Orleans silo before application exit, first as a Console app, and then as a Docker container app. Graceful shutdown - Console app The following code shows how to gracefully shutdown an Orleans silo console app in response to the user pressing Ctrl+C, which generates the Console.CancelkeyPress event. Normally when that event handler returns, the application will exit immediately, causing a catastrophic Orleans silo crash and loss of in-memory state. But in the sample code below, we set a.Cancel = true; to prevent the application closing before the Orleans silo has completed its graceful shutdown. using Microsoft.Extensions.Logging; using Orleans.Configuration; using Orleans.Hosting; using System; using System.Net; using System.Threading; using System.Threading.Tasks; namespace MySiloHost { class Program { static readonly ManualResetEvent _siloStopped = new ManualResetEvent(false); static ISiloHost silo; static bool siloStopping = false; static readonly object syncLock = new object(); static void Main(string[] args) { SetupApplicationShutdown(); silo = CreateSilo(); silo.StartAsync().Wait(); /// Wait for the silo to completely shutdown before exiting. _siloStopped.WaitOne(); } static void SetupApplicationShutdown() { /// Capture the user pressing Ctrl+C Console.CancelKeyPress += (s, a) => { /// Prevent the application from crashing ungracefully. a.Cancel = true; /// Don't allow the following code to repeat if the user presses Ctrl+C repeatedly. lock (syncLock) { if (!siloStopping) { siloStopping = true; Task.Run(StopSilo).Ignore(); } } /// Event handler execution exits immediately, leaving the silo shutdown running on a background thread, /// but the app doesn't crash because a.Cancel has been set = true }; } static ISiloHost CreateSilo() { return new SiloHostBuilder() .Configure(options => options.ClusterId = \"MyTestCluster\") /// Prevent the silo from automatically stopping itself when the cancel key is pressed. .Configure<ProcessExitHandlingOptions>(options => options.FastKillOnProcessExit = false) .UseDevelopmentClustering(options => options.PrimarySiloEndpoint = new IPEndPoint(IPAddress.Loopback, 11111)) .ConfigureLogging(b => b.SetMinimumLevel(LogLevel.Debug).AddConsole()) .Build(); } static async Task StopSilo() { await silo.StopAsync(); _siloStopped.Set(); } } } Of course, there are many other ways of achieving the same goal. Below is shown a way, popular online, and misleading, that DOES NOT work properly. It does not work because it sets up a race condition between two methods trying to exit first: the Console.CancelKeyPress event handler method, and the static void Main(string[] args) method. When the event handler method finishes first, which happens at least half the time, the application will hang instead of exiting smoothly. class Program { static readonly ManualResetEvent _siloStopped = new ManualResetEvent(false); static ISiloHost silo; static bool siloStopping = false; static readonly object syncLock = new object(); static void Main(string[] args) { Console.CancelKeyPress += (s, a) => { Task.Run(StopSilo); /// Wait for the silo to completely shutdown before exiting. _siloStopped.WaitOne(); /// Now race to finish ... who will finish first? /// If I finish first, the application will hang! :( }; silo = CreateSilo(); silo.StartAsync().Wait(); /// Wait for the silo to completely shutdown before exiting. _siloStopped.WaitOne(); /// Now race to finish ... who will finish first? } static async Task StopSilo() { await silo.StopAsync(); _siloStopped.Set(); } } Graceful shutdown - Docker app To be completed."
  },
  "docs/host/configuration_guide/startup_tasks.html": {
    "href": "docs/host/configuration_guide/startup_tasks.html",
    "title": "Startup Tasks | Microsoft Orleans Documentation",
    "keywords": "Startup Tasks In many cases, some task needs to be performed automatically as soon as a silo becomes available. Startup Tasks provide this functionality. Some use cases include, but are not limited to: Starting background timers to perform periodic housekeeping tasks Pre-loading some cache grains with data downloaded from external backing storage Any exceptions that are thrown from a startup task during startup will be reported in the silo log and will stop the silo. This fail-fast approach is the standard way that Orleans handles silo start-up issues, and is intended to allow any problems with silo configuration and/or bootstrap logic to be easily detected during testing phases rather than being silently ignored and causing unexpected problems later in the silo lifecycle. Configuring Startup Tasks Startup tasks can be configured using the ISiloHostBuilder either by registering a delegate to be invoked during startup or by registering a implementation of IStartupTask . Example: Registering a delegate siloHostBuilder.AddStartupTask( async (IServiceProvider services, CancellationToken cancellation) => { // Use the service provider to get the grain factory. var grainFactory = services.GetRequiredService<IGrainFactory>(); // Get a reference to a grain and call a method on it. var grain = grainFactory.GetGrain<IMyGrain>(0); await grain.Initialize(); }); Example: Registering an IStartupTask implementation First we must define an implementation of IStartupTask : public class CallGrainStartupTask : IStartupTask { private readonly IGrainFactory grainFactory; public CallGrainStartupTask(IGrainFactory grainFactory) { this.grainFactory = grainFactory; } public async Task Execute(CancellationToken cancellationToken) { var grain = this.grainFactory.GetGrain<IMyGrain>(0); await grain.Initialize(); } } Then that implementation must be registered with the ISiloHostBuilder : siloHostBuilder.AddStartupTask<CallGrainStartupTask>();"
  },
  "docs/host/configuration_guide/typical_configurations.html": {
    "href": "docs/host/configuration_guide/typical_configurations.html",
    "title": "Typical Configurations | Microsoft Orleans Documentation",
    "keywords": "Typical Configurations Below are examples of typical configurations that can be used for development and production deployments. Local Development See Local Development Configuration Reliable Production Deployment Using Azure For a reliable production deployment using Azure, you need to use the Azure Table option for cluster membership. This configuration is typical of deployments to either on-premise servers, containers, or Azure virtual machine instances. The format of the DataConnection string is \"DefaultEndpointsProtocol=https;AccountName=<Azure storage account>;AccountKey=<Azure table storage account key>\" Silo configuration: // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; var silo = new SiloHostBuilder() .Configure<ClusterOptions>(options => { options.ClusterId = \"Cluster42\"; options.ServiceId = \"MyAwesomeService\"; }) .UseAzureStorageClustering(options => options.ConnectionString = connectionString) .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) .ConfigureLogging(builder => builder.SetMinimumLevel(LogLevel.Warning).AddConsole()) .Build(); Client configuration: // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; var client = new ClientBuilder() .Configure<ClusterOptions>(options => { options.ClusterId = \"Cluster42\"; options.ServiceId = \"MyAwesomeService\"; }) .UseAzureStorageClustering(options => options.ConnectionString = connectionString) .ConfigureLogging(builder => builder.SetMinimumLevel(LogLevel.Warning).AddConsole()) .Build(); Reliable Production Deployment Using SQL Server For a reliable production deployment using SQL server, a SQL server connection string needs to be supplied. Silo configuration: // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; var silo = new SiloHostBuilder() .Configure<ClusterOptions>(options => { options.ClusterId = \"Cluster42\"; options.ServiceId = \"MyAwesomeService\"; }) .UseAdoNetClustering(options => { options.ConnectionString = connectionString; options.Invariant = \"System.Data.SqlClient\"; }) .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) .ConfigureLogging(builder => builder.SetMinimumLevel(LogLevel.Warning).AddConsole()) .Build(); Client configuration: // TODO replace with your connection string const string connectionString = \"YOUR_CONNECTION_STRING_HERE\"; var client = new ClientBuilder() .Configure<ClusterOptions>(options => { options.ClusterId = \"Cluster42\"; options.ServiceId = \"MyAwesomeService\"; }) .UseAdoNetClustering(options => { options.ConnectionString = connectionString; options.Invariant = \"System.Data.SqlClient\"; }) .ConfigureLogging(builder => builder.SetMinimumLevel(LogLevel.Warning).AddConsole()) .Build(); Unreliable Deployment on a Cluster of Dedicated Servers For testing on a cluster of dedicated servers when reliability isn’t a concern you can leverage MembershipTableGrain and avoid dependency on Azure Table. You just need to designate one of the nodes as a Primary. On the silos: var primarySiloEndpoint = new IPEndpoint(PRIMARY_SILO_IP_ADDRESS, 11111); var silo = new SiloHostBuilder() .UseDevelopmentClustering(primarySiloEndpoint) .Configure<ClusterOptions>(options => { options.ClusterId = \"Cluster42\"; options.ServiceId = \"MyAwesomeService\"; }) .ConfigureEndpoints(siloPort: 11111, gatewayPort: 30000) .ConfigureLogging(logging => logging.AddConsole()) .Build(); On the clients: var gateways = new IPEndPoint[] { new IPEndPoint(PRIMARY_SILO_IP_ADDRESS, 30000), new IPEndPoint(OTHER_SILO__IP_ADDRESS_1, 30000), [...] new IPEndPoint(OTHER_SILO__IP_ADDRESS_N, 30000), }; var client = new ClientBuilder() .UseStaticClustering(gateways) .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"AdventureApp\"; }) .ConfigureLogging(logging => logging.AddConsole()) .Build();"
  },
  "docs/host/grain_directory.html": {
    "href": "docs/host/grain_directory.html",
    "title": "Grain Directory | Microsoft Orleans Documentation",
    "keywords": "Grain Directory What is the Grain Directory? Grains have stable logical identities and may get activated (instantiated) and deactivated many times over the life of the application, but at most one activation of grain exist at any point in time. Each time a grain gets activated, it may be placed on a different silo in the cluster. When a grain gets activated in the cluster, it gets registered in the global registry, Grain Directory. This ensures that subsequent invocations of that grain will be delivered to that activation of the grain, and that no other activations (instances) of that grain will be created. Grain Directory is responsible for keeping a mapping between a grain identity and where (which silo) its current activation is at. By default, Orleans uses a built-in distributed in-memory directory. This directory is eventually consistent and partitioned across all silos in the cluster in a form of a Distributed Hash Table. Starting with 3.2.0, Orleans also supports pluggable implementations of Grain Directory. Two such plugins are included in the 3.2.0 release: an Azure Table implementation: Microsoft.Orleans.GrainDirectory.AzureStorage (beta) a Redis Store implementation: Microsoft.Orleans.GrainDirectory.Redis (beta) You can configure which Grain Directory implementation to use on a per-grain type basis, and you can even inject your own implementation. Which Grain Directory should you use? We recommend to always start with the default one (built-in in-memory distributed directory). Even though it is eventually consistent and allows for occasional duplicate activation when cluster is unstable, the built-in directory is self-sufficient with no external dependencies, does not requires any configuration, and has been used in production the whole time. When you have some experience with Orleans and have a use case for Grain Directory a with stronger single-activation guarantee and/or want to minimize the number of grain that get deactivated when a silo in the cluster shuts down, consider using a storage-based implementation of Grain Directory, such as the Redis implementation. Try using it for one or a few grain types first, starting with those that are long-lived and have a significant amount of state or an expensive initialization process. Configuration Default Grain Directory configuration You don't have do to anything; the in-memory grain directory will be automatically used and partitioned across the cluster. Non-default Grain Directory configuration You need to specify name of the directory plugin to use via an attribute on the grain class and inject the directory plugin with that name during the silo configuration. Grain configuration Specifying the Grain Directory plugin name with the GrainDirectory attribute: [GrainDirectory(GrainDirectoryName = \"my-grain-directory\")] public class MyGrain : Grain, IMyGrain { [...] } Silo Configuration Here we configure the Redis Grain Directory implementation: siloBuilder.AddRedisGrainDirectory( \"my-grain-directory\", options => options.ConfigurationOptions = redisConfiguration); The Azure Grain Directory is configured like this: siloBuilder.AddAzureTableGrainDirectory( \"my-grain-directory\", options => options.ConnectionString = = azureConnectionString); You can configure multiple directories with different names to use for different grain classes: siloBuilder .AddRedisGrainDirectory( \"redis-directory-1\", options => options.ConfigurationOptions = redisConfiguration1) .AddRedisGrainDirectory( \"redis-directory-2\", options => options.ConfigurationOptions = redisConfiguration2) .AddAzureTableGrainDirectory( \"azure-directory\", options => options.ConnectionString = = azureConnectionString);"
  },
  "docs/host/heterogeneous_silos.html": {
    "href": "docs/host/heterogeneous_silos.html",
    "title": "Heterogeneous silos | Microsoft Orleans Documentation",
    "keywords": "Heterogeneous silos Overview On a given cluster, silos can support a different set of grain types: In this example the cluster supports grains of type A , B , C , D , E : Grain types A and B can be placed on Silo 1 and 2. Grain type C can be placed on Silo 1, 2 or 3. Grain type D can be only placed on Silo 3 Grain Type E can be only placed on Silo 4. All silos should reference interfaces of all grain types of the cluster, but grain classes should only be referenced by the silos that will host them. The client does not know which silo supports a given Grain Type. A given Grain Type implementation must be the same on each silo that supports it. The following scenario is NOT valid: On Silo 1 and 2: public class C: Grain, IMyGrainInterface { public Task SomeMethod() { … } } On Silo 3 public class C: Grain, IMyGrainInterface, IMyOtherGrainInterface { public Task SomeMethod() { … } public Task SomeOtherMethod() { … } } Configuration No configuration is needed, you can deploy different binaries on each silo in your cluster. However, if necessary, you can change the interval that silos and clients check for changes in types supported with the property TypeMapRefreshInterval from TypeManagementOptions For testing purposes, you can use the property ExcludedGrainTypes in GrainClassOptions , which is a list names of the types you want to exclude on the silos. Limitations Connected clients will not be notified if the set of supported Grain Types changed. In the previous example: If Silo 4 leaves the cluster, the client will still try to make calls to grain of type E . It will fail at runtime with a OrleansException. If the client was connected to the cluster before Silo 4 joined it, the client will not be able to make calls to grain of type E . It will fail will a ArgumentException Stateless grains are not supported: all silos in the cluster must support the same set of stateless grains. ImplicitStreamSubscription are not supported and thus only \"Explicit Subscriptions\" can be used in Orleans Streams."
  },
  "docs/host/monitoring/client_error_code_monitoring.html": {
    "href": "docs/host/monitoring/client_error_code_monitoring.html",
    "title": "Client Error Code Monitoring | Microsoft Orleans Documentation",
    "keywords": "Client Error Code Monitoring Group Log Type Log Code Values Threshold Description Azure Problems Warning or Error 100800 - 100899 Any Error or Warning Transient problems reading or writing to Azure table store will be logged as Warning. Transient read errors will automatically be retried. A final Error log message means there is a real problem connecting to Azure table storage. Gateway connectivity problems Warning or Error 100901 - 100904, 100912, 100913, 100921, 100923, 100158, 100161, 100178, , 101313 Any Error or Warning Problems connecting to gateways. No active gateways in the Azure table. Connection to active gateway lost. Grain call timeouts Warning 100157 Multiple Warnings logged in short space of time Grain-call timeout problems are generally caused by temporary network connectivity issues or silo restart / reboot problems. System should recover after a short time (depending on Liveness config settings) at which point Timeouts should clear. Ideally, monitoring for just the bulk log code 600157 variety of these warnings should be sufficient. Network Socket Problems Warning or Error 101000 to 101999, 100307, 100015, 100016 Any Error or Warning Socket disconnects are logged as Warning messages. Problems opening sockets or during message transmission are logged as Errors. Bulk log message compaction Any 500000 or higher Message summary based on bulk message threshold settings If multiple logs of the same log code occur within a designated time interval (the default is >5 within 1 minute) then additional log messages with that log code are suppressed and output as a \"bulk\" entry with log code equal to the original log code + 500000. So for example, multiple 100157 entries will show in the logs as 5 x 100157 + 1 x 600157 log entry per minute."
  },
  "docs/host/monitoring/index.html": {
    "href": "docs/host/monitoring/index.html",
    "title": "Runtime Monitoring | Microsoft Orleans Documentation",
    "keywords": "Runtime Monitoring Orleans output its runtime statistics and metrics through the ITelemetryConsumer interface. Application can register one or more telemetry consumers with for their silos and clients, to receives statistics and metrics that Orleans runtime periotically publishes. These can be consumers for popular telemetry analytics solutions or custom ones for any other destination and purpose. Three telemetry consumer are currently included in the Orleans codebase. They are released as separate NuGet packages: Microsoft.Orleans.OrleansTelemetryConsumers.AI for publishing to Application Insights . Microsoft.Orleans.OrleansTelemetryConsumers.Counters for publishing to Windows performance counters. The Orleans runtime continually updates a number of them. CounterControl.exe tool, included in the Microsoft.Orleans.CounterControl NuGet package, helps register necessary performance counter categories. It has to run with elevated privileges. The performance counters can be monitored using any of the standard monitoring tools. Microsoft.Orleans.OrleansTelemetryConsumers.NewRelic , for publishing to New Relic . To configure your silo and client to use telemetry consumers, silo configuration code looks like this: var siloHostBuilder = new SiloHostBuilder(); //configure the silo with AITelemetryConsumer siloHostBuilder.AddApplicationInsightsTelemetryConsumer(\"INSTRUMENTATION_KEY\"); client configuration code look like this: var clientBuilder = new ClientBuilder(); //configure the clientBuilder with AITelemetryConsumer clientBuilder.AddApplicationInsightsTelemetryConsumer(\"INSTRUMENTATION_KEY\");"
  },
  "docs/host/monitoring/silo_error_code_monitoring.html": {
    "href": "docs/host/monitoring/silo_error_code_monitoring.html",
    "title": "Silo Error Code Monitoring | Microsoft Orleans Documentation",
    "keywords": "Silo Error Code Monitoring Group Log Type Log Code Values Threshold Description Azure Problems Warning or Error 100800 - 100899 Any Error or Warning Transient problems reading or writing to Azure table store will be logged as Warning. Transient read errors will automatically be retried. A final Error log message means there is a real problem connecting to Azure table storage. Membership Connectivity Problems Warning or Error 100600 - 100699 Any Error or Warning Warning logs are an early indication of network connectivity problems and/or silo restart / migration. Ping timeouts and silo-dead votes will show up as Warning messages. Silo detecting it was voted dead will show as Error message. Grain call timeouts Warning 100157 Multiple Warnings logged in short space of time Grain-call timeout problems are generally caused by temporary network connectivity issues or silo restart / reboot problems. The system should recover after a short time (depending on Liveness config settings) at which point Timeouts should clear. Ideally, monitoring for just the bulk log code 600157 variety of these warnings should be sufficient. Silo Restart / Migration Warning 100601 or 100602 Any Warning Warning printed when silo detects it was restarted on same machine {100602) or migrated to different machine (100601) Network Socket Problems Warning or Error 101000 to 101999, 100307,100015, 100016 Any Error or Warning Socket disconnects are logged as Warning messages. Problems opening sockets or during message transmission are logged as Errors. Grain problems Warning or Error 101534 Any Error or Warning Detection of “stuck” requests for non-reentrant grains . The error code is reported every time a request takes longer than 5x request timeout time to execute."
  },
  "docs/host/powershell_client.html": {
    "href": "docs/host/powershell_client.html",
    "title": "PowerShell Client Module | Microsoft Orleans Documentation",
    "keywords": "PowerShell Client Module The Orleans PowerShell Client Module is a set of PowerShell Cmdlets that wraps GrainClient in a set of convenient commands making possible to interact with not just ManagementGrain but any IGrain just as a regular Orleans application can by using Powershell scripts. These Cmdlets enable a series of scenarios from start maintenance tasks, tests, monitoring or any other kind of automation by leveraging Powershell scripts. Here is how to use it: Installing the module From Source You can build from source the OrleansPSUtils project and just import it with: PS> Import-Module .\\projectOutputDir\\Orleans.psd1 Althought you can do that, there is a much easier and interesting way for doing that by installing it from PowerShell Gallery . From PowerShell Gallery Powershell modules today are easily shared just as Nuget packages but instead of nuget.org, they are hosted on PowerShell Gallery . To install it on a specific folder just run: PS> Save-Module -Name OrleansPSUtils -Path <path> To install it on your PowerShell modules path ( the recommended way ), just run: PS> Install-Module -Name OrleansPSUtils If you plan to use this module on an Azure Automation , just click on the button bellow: Using the module Regardless of the way you decide to install it, the first thing you need to do in order to actually use it is import the module on the current PowerShell session so the Cmdlets get available by running this: PS> Import-Module OrleansPSUtils Note : In case of building from source, you must import it as suggested on the Install section by using the path to the .psd1 instead of using the module name since it will not be on the $env:PSModulePath PowerShell runtime variable. Again, it is highly recommended that you install from PowerShell Gallery instead. After the module is imported (which means it is loaded on PowerShell session), you will have the following Cmdlets available: Start-GrainClient Stop-GrainClient Get-Grain Start-GrainClient This module is a wrapper around GrainClient.Initialize() and its overloads. Usage : Start-GrainClient The same as call GrainClient.Initialize() which will look for the known Orleans Client configuration file names Start-GrainClient [-ConfigFilePath] <string> [[-Timeout] <timespan>] Will use the provided file path as in GrainClient.Initialize(filePath) Start-GrainClient [-ConfigFile] <FileInfo> [[-Timeout] <timespan>] Use an instance of the System.FileInfo class representing the config file just as GrainClient.Initialize(fileInfo) Start-GrainClient [-Config] <ClientConfiguration> [[-Timeout] <timespan>] Use an instance of a Orleans.Runtime.Configuration.ClientConfiguration like in GrainClient.Initialize(config) Start-GrainClient [-GatewayAddress] <IPEndPoint> [[-OverrideConfig] <bool>] [[-Timeout] <timespan>] Takes a Orleans Cluster Gateway Address Endpoint Note : The Timeout parameter is optional and if it is informed and greater than System.TimeSpan.Zero , it will call Orleans.GrainClient.SetResponseTimeout(Timeout) internally. Stop-GrainClient Takes no parameters and when called, if the GrainClient is initialized will gracefuly uninitialize. Get-Grain Wrapper around GrainClient.GrainFactory.GetGrain<T>() and its overloads. The mandatory parameter is -GrainType and the -XXXKey for the current Grain key types supported by Orleans ( string , Guid , long ) and also the -KeyExtension that can be used on Grains with compound keys. This Cmdlet return a grain reference of the type passed by as parameter on -GrainType . Example: A simple example on calling MyInterfacesNamespace.IMyGrain.SayHeloTo grain method: PS> Import-Module OrleansPSUtils PS> $configFilePath = Resolve-Path(\".\\ClientConfig.xml\").Path PS> Start-GrainClient -ConfigFilePath $configFilePath PS> Add-Type -Path .\\MyGrainInterfaceAssembly.dll PS> $grainInterfaceType = [MyInterfacesNamespace.IMyGrain] PS> $grainId = [System.Guid]::Parse(\"A4CF7B5D-9606-446D-ACE9-C900AC6BA3AD\") PS> $grain = Get-Grain -GrainType $grainInterfaceType -GuidKey $grainId PS> $message = $grain.SayHelloTo(\"Gutemberg\").Result PS> Write-Output $message Hello Gutemberg! PS> Stop-GrainClient We plan to update this page as we introduce more Cmdlets like use Observers, Streams and other Orleans core features more natively on Powershell. We hope that this help people as a starting point for automation. As always, this is a work-in-progress and we love contributions! :) Please note that the intent is not to reimplement the whole client on PowerShell but instead, give IT and DevOps teams a way to interact with the Grains without need to implement a .Net application."
  },
  "docs/host/silo_lifecycle.html": {
    "href": "docs/host/silo_lifecycle.html",
    "title": "Silo Lifecycle | Microsoft Orleans Documentation",
    "keywords": "Silo Lifecycle Overview Orleans silo uses an observable lifecycle (See Orleans Lifecycle ) for ordered startup and shutdown of Orleans systems as well as application layer components. Stages Orleans Silo and Cluster Client use a common set of service lifecycle stages. public static class ServiceLifecycleStage { public const int First = int.MinValue; public const int RuntimeInitialize = 2000; public const int RuntimeServices = 4000; public const int RuntimeStorageServices = 6000; public const int RuntimeGrainServices = 8000; public const int ApplicationServices = 10000; public const int BecomeActive = Active-1; public const int Active = 20000; public const int Last = int.MaxValue; } First - First stage in service's lifecycle RuntimeInitialize - Initialize runtime environment. Silo initializes threading. RuntimeServices - Start runtime services. Silo initializes networking and various agents. RuntimeStorageServices - Initialize runtime storage. RuntimeGrainServices - Start runtime services for grains. This includes grain type management, membership service, and grain directory. ApplicationServices – Application layer services. BecomeActive – Silo joins the cluster. Active – Silo is active in the cluster and ready to accept workload. Last - Last stage in service's lifecycle Logging Due to the inversion of control, where participants join the lifecycle rather than the lifecycle having some centralized set of initialization steps, it’s not always clear from the code what the startup/shutdown order is. To help address this, logging has been added prior to silo startup to report what components are participating at each stage. These logs are recorded at Information log level on the Orleans.Runtime.SiloLifecycleSubject logger. For instance: Information, Orleans.Runtime.SiloLifecycleSubject, “Stage 2000: Orleans.Statistics.PerfCounterEnvironmentStatistics, Orleans.Runtime.InsideRuntimeClient, Orleans.Runtime.Silo” Information, Orleans.Runtime.SiloLifecycleSubject, “Stage 4000: Orleans.Runtime.Silo” Information, Orleans.Runtime.SiloLifecycleSubject, “Stage 10000: Orleans.Runtime.Versions.GrainVersionStore, Orleans.Storage.AzureTableGrainStorage-Default, Orleans.Storage.AzureTableGrainStorage-PubSubStore” Additionally, timing and error information are similarly logged for each component by stage. For instance: Information, Orleans.Runtime.SiloLifecycleSubject, “Lifecycle observer Orleans.Runtime.InsideRuntimeClient started in stage 2000 which took 33 Milliseconds.” Information, Orleans.Runtime.SiloLifecycleSubject, “Lifecycle observer Orleans.Statistics.PerfCounterEnvironmentStatistics started in stage 2000 which took 17 Milliseconds.” Silo Lifecycle Participation Application logic can take part in the silo’s lifecycle by registering a participating service in the silo’s service container. The service must be registered as an ILifecycleParticipant . public interface ISiloLifecycle : ILifecycleObservable { } public interface ILifecycleParticipant<TLifecycleObservable> where TLifecycleObservable : ILifecycleObservable { void Participate(TLifecycleObservable lifecycle); } Upon silo start, all participants ( ILifecycleParticipant<ISiloLifecycle> ) in the container will be given an opportunity to participate by calling their Participate(..) behavior. Once all have had the opportunity to participate, the silo’s observable lifecycle will start all stages in order. Example With the introduction of the silo lifecycle, bootstrap providers, which used to allow application developers to inject logic at the provider initialization phase, are no longer necessary, since application logic can now be injected at any stage of silo startup. Nonetheless, we added a ‘startup task’ façade to aid the transition for developers who had been using bootstrap providers. As an example of how components can be developed which take part in the silo’s lifecycle, we’ll look at the startup task façade. The startup task needs only to inherit from ILifecycleParticipant<ISiloLifecycle> and subscribe the application logic to the silo lifecycle at the specified stage. class StartupTask : ILifecycleParticipant<ISiloLifecycle> { private readonly IServiceProvider serviceProvider; private readonly Func<IServiceProvider, CancellationToken, Task> startupTask; private readonly int stage; public StartupTask( IServiceProvider serviceProvider, Func<IServiceProvider, CancellationToken, Task> startupTask, int stage) { this.serviceProvider = serviceProvider; this.startupTask = startupTask; this.stage = stage; } public void Participate(ISiloLifecycle lifecycle) { lifecycle.Subscribe<StartupTask>( this.stage, cancellation => this.startupTask(this.serviceProvider, cancellation)); } } From the above implementation, we can see that in the StartupTask’s Participate(..) call it subscribes to the silo lifecycle at the configured stage, passing the application callback rather than its own initialization logic. Components that need to be initialized at a given stage would provide their own callback, but the pattern is the same. Now that we have a StartupTask which will ensure that the application’s hook is called at the configured stage, we need to ensure that the StartupTask participates in the silo lifecycle. For this we need only register it in the container. We do this with an extension function on the SiloHost builder. public static ISiloHostBuilder AddStartupTask( this ISiloHostBuilder builder, Func<IServiceProvider, CancellationToken, Task> startupTask, int stage = ServiceLifecycleStage.Active) { builder.ConfigureServices(services => services.AddTransient<ILifecycleParticipant<ISiloLifecycle>>(sp => new StartupTask( sp, startupTask, stage))); return builder; } By registering the StartupTask in the silo’s service container as the marker interface ILifecycleParticipant<ISiloLifecycle> , this signals to the silo that this component needs to take part in the silo lifecycle."
  },
  "docs/implementation/cluster_management.html": {
    "href": "docs/implementation/cluster_management.html",
    "title": "Cluster Management in Orleans | Microsoft Orleans Documentation",
    "keywords": "Cluster Management in Orleans Orleans provides cluster management via a built-in membership protocol, which we sometimes refer to as Silo Membership . The goal of this protocol is for all silos (Orleans servers) to agree on the set of currently alive silos, detect failed silos, and allow new silos to join the cluster. The protocol relies on an external service to provide an abstraction of MembershipTable . MembershipTable is a flat No-SQL like durable table that we use for 2 purposes. First, it is used as a rendezvous point for silos to find each other and Orleans clients to find silos. Second, it is used to store the current membership view (list of alive silos) and helps coordinate the agreement on the membership view. We currently have 6 implementations of the MembershipTable : based on Azure Table Storage , SQL server, Apache ZooKeeper , Consul IO , AWS DynamoDB , and in-memory emulation for development. In addition to the MembershipTable each silo participates in fully distributed peer-to-peer membership protocol that detects failed silos and reaches agreement on a set alive silos. We start by describing the internal implementation of the Orleans's membership protocol below and later on describe the implementation of the MembershipTable . The Basic Membership Protocol: Upon startup every silo writes itself into a well-known MembershipTable (passed via config). A combination of silo identity ( ip:port:epoch ) and service deployment id are used as unique keys in the table. Epoch is just time in ticks when this silo started, and as such ip:port:epoch is guaranteed to be unique in a given Orleans deployment. Silos monitor each other directly, via application pings (\"are you alive\" heartbeats ). Pings are sent as direct messages from silo to silo, over the same TCP sockets that silos communicate. That way, pings fully correlate with actual networking problems and server health. Every silo pings X other silos. A silo picks whom to ping by calculating consistent hashes on other silos' identity, forming a virtual ring of all identities and picking X successor silos on the ring (this is a well-known distributed technique called consistent hashing and is widely used in many distributed hash tables, like Chord DHT ). If a silo S does not get Y ping replies from a monitored servers P, it suspects it by writing its timestamped suspicion into P’s row in the MembershipTable . If P has more than Z suspicions within K seconds, then S writes that P is dead into P’s row, and broadcasts a request for all silos to re-read the membership table (which they’ll do anyway periodically). In more details: 5.1 Suspicion is written to the MembershipTable , in a special column in the row corresponding to P. When S suspects P it writes: “at time TTT S suspected P”. 5.2 One suspicion is not enough to declare P as dead. You need Z suspicions from different silos in a configurable time window T, typically 3 minutes, to declare P as dead. The suspicion is written using optimistic concurrency control provided by the MembershipTable . 5.3 The suspecting silo S reads P's row. 5.4 If S is the last suspector (there have already been Z-1 suspectors within time period T, as written in the suspicion column), S decides to declare P as Dead. In this case, S adds itself to list of suspectors and also writes in P's Status column that P is Dead. 5.5 Otherwise, if S is not the last suspector, S just adds itself to the suspectors column. 5.6 In either case the write back uses the version number or etag that was read, so the updates to this row are serialized. In case the write has failed due to version/etag mismatch, S retries (read again, and try to write, unless P was already marked dead). 5.7 At a high level this sequence of \"read, local modify, write back\" is a transaction. However, we are not using storage transactions to do that. “Transaction” code executes locally on a server and we use optimistic concurrency provided by the MembershipTable to ensure isolation and atomicity. Every silo periodically reads the entire membership table for its deployment. That way silos learn about new silos joining and about other silos being declared dead. Configuration : we provide a default configuration, which was hand tuned during our production usage in Azure. Currently the default is: every silo is monitored by 3 other silos, 2 suspicions are enough to declare a silo dead, suspicions only from last 3 minutes (otherwise they are outdated). Pings are send every 10 seconds and you needs to miss 3 pings to suspect a silo. Enforcing Perfect Failure detection – it is theoretically possible that a silo will be declared dead if it lost communication with other silos, while the silo process itself is still running. To solve this problem once the silo is declared dead in the table it is considered dead by everyone, even if it is in fact not dead (just partitioned temporarily or heartbeat messages got lost). Everyone stops communicating with it and once it learns that it is dead (by reading its own new status from the table) it commits suicide and shuts down its process. As a result, there must be an infrastructure in place to restart the silo as a new process (a new epoch number is generated upon start). When it's hosted in Azure, that happens automatically. When it isn't, another infrastructure is required. For example, a Windows Service configured to auto restart on failure. Optimization to reduce the frequency of periodical table reads and speed up all silos learning about new joining silos and dead silos . Every time any silo writes anything successfully to the table (suspicion, new join, …) it also broadcasts to all other silos – “go and reread the table now”. The silo does NOT tell others what it wrote in the table (since this information could already be outdated/wrong), it just tells them to re-read the table. That way we learn very quickly about membership changes without the need to wait for the full periodic read cycle. We still need the periodic read, in case the “re-read the table” message gets lost. Properties of the Basic Membership Protocol and FAQ: Can handle any number of failures – our algorithm can handle any number of failures (that is, f<=n), including full cluster restart. This is in contrast with “traditional” Paxos based solutions, which require quorum, which is usually a majority. We have seen in production situations when more than half of the silos were down. Our system stayed functional, while Paxos based membership would not be able to make progress. Traffic to the table is very light - The actual pings go directly between servers and not to the table. This would generate a lot of traffic plus would be less accurate from the failure detection perspective - if a silo could not reach the table, it would miss to write its I am alive heartbeat and others would kill him. Tunable accuracy vs. completeness – both perfect and accurate failure detection is not possible in general . One usually wants an ability to tradeoff accuracy (don’t want to declare a silo that is really alive as dead) with completeness (want to declare dead a silo that is indeed dead as soon as possible). The configurable #votes to declare dead and #missed pings allows to trade those two. Scale - the basic protocol can handle thousands and probably even tens of thousands of servers. This is in contrast with traditional Paxos based solutions, such as group communication protocols, which are known not to scale beyond tens. Diagnostics - the table is also very convenient for diagnostics and troubleshooting. System administrator can instantaneously find in the table the current list of alive silos, as well as see the history of all killed silos and suspicions. This is especially useful when diagnosing problems. Why do we need reliable persistent storage for implementation of the MembershipTable ? - we use persistent storage (Azure table, SQL server, AWS DynamoDB, Apache ZooKeeper or Consul IO KV) for the MembershipTable for 2 purposes. First, it is used as a rendezvous point for silos to find each other and Orleans clients to find silos. Second, we use the reliable storage to help us coordinate the agreement on the membership view. While we perform failure detection directly in a peer to peer fashion between the silos, we store the membership view in a reliable storage and use the concurrency control mechanism provided by this storage to reach agreement of who is alive and who is dead. That way, in a sense, our protocol outsources the hard problem of distributed consensus to the cloud. In that we fully utilize the power of the underlying cloud platform, using it truly as \"Platform as a Service\". What happens if the table is not accessible for some time? (storage service is down, unavailable, or there are communication problems with it) – our protocol will NOT declare silos as dead by mistake in such a case. Currently operational silos will keep working without any problems. However, we won't be able to declare a silo dead (if we detected some silo is dead via missed pings we won’t be able to write this fact to the table) and also won't be able to allow new silos to join. So completeness will suffer, but accuracy will not - partitioning from the table will never cause us to declare silo as dead by mistake. Also, in case of a partial network partition (if some silos can access the table and some not), it could happen that we will declare a dead silo as dead, but it will take some time until all other silos learn about it. So detection could be delayed, but we will never wrongly kill someone due to table un-availability. Direct IAmAlive writes into the table for diagnostics only - in addition to heartbeats that are sent between the silos, each silo also periodically updates an \"I Am Alive\" column in his row in the table. This \"I Am Alive\" column is only used for manual troubleshooting and diagnostics and is not used by the membership protocol itself. It is usually written at much lower frequency (once every 5 minutes) and serves as a very useful tool for system administrators to check the liveness of the cluster or easily find out when the silo was last alive. Extension to totally order membership views: The basic membership protocol described above was later extended to support totally ordered membership views. We will briefly describe the reasons for this extension and how it is implemented. The extension does not change anything in the above design, just adds an additional property that all membership configurations are globally totally ordered. Why it is useful to totally order membership views? This allows serializing the joining of new silos to the cluster. That way, when a new silo joins the cluster it can validate two-way connectivity to every other silo that has already started. If some of the already joined silos do not answer it (potentially indicating a network connectivity problem with the new silo), the new silo is not allowed to join. This ensures that at least when a silo starts, there is a full connectivity between all silos in the cluster (this is implemented). Higher level protocols in the silo, such as distributed grain directory, can utilize the fact that membership views are ordered and use this information to perform smarter duplicate activations resolution. In particular, when directory finds out that 2 activations were created when membership was in flux, it may decide to deactivate the older activation that was created based on the now-outdated membership information (this is currently not implemented). Extended Membership Protocol: For implementation of this feature we utilize the support for transactions over multiple rows that is provided by the MembershipTable .. We add a membership-version row to the table that tracks table changes. When silo S wants to write suspicion or death declaration for silo P: 3.1 S reads the latest table content. If P is already dead, do nothing. Otherwise, 3.2 In the same transaction, write the changes to P's row as well as increment the version number and write it back to the table. 3.3 Both writes are conditioned with eTags. 3.4 If transaction aborts due to eTag mismatch on either P's row or on the version row, attempt again. All writes to the table modify and increment the version row. That way all writes to the table are serialized (via serializing the updates to the version row) and since silos only increment the version number, the writes are also totally ordered in increasing order. Scalability of the Extended Membership Protocol: In the extended version of the protocol all writes are serialized via one row. This can potentially hurt the scalability of the cluster managemenet protocol, since it increases the risk of conflicts between concurrent table writes. To partially mitigate this problem silos retry all their writes to the table by using exponential backoff. We have observed the extended protocols to work smoothly in production environment in Azure with up to 200 silos. However, we do think the protocol might have problems to scale beyond a thousand silos. In such large setups the updates to version row may be easily disabled, essentially maintaining the rest of the cluster managemenet protocol and giving up on the total ordering property. Please also note that we refer here to the scalability of the cluster management protocol, not the rest of Orleans. We believe that other parts of the Orleans runtime (messaging, distributed directory, grain hosting, client to gateway connectivity) are scalable way beyond hundreds of silos. Membership Table: As already mentioned, MembershipTable is used as a rendezvous point for silos to find each other and Orleans clients to find silos and also helps coordinate the agreement on the membership view. We currently have 6 implementation of the MembershipTable : based on Azure Table, SQL server, Apache ZooKeeper, Consul IO, AWS DynamoDB, and in-memory emulation for development. The interface for MembershipTable is defined in IMembershipTable . Azure Table Storage - in this implementation we use Azure deployment ID as partition key and the silo identity ( ip:port:epoch ) as row key. Together they guarantee a unique key per silo. For concurrency control we use optimistic concurrency control based on Azure Table ETags . Every time we read from the table we store the etag for every read row and use that eTag when we try to write back. etags are automatically assigned and checked by Azure Table service on every write. For multi-row transactions we utilize the support for batch transactions provided by Azure table , which guarantees serializale transactions over rows with the same partition key. SQL Server - in this implementation the configured deployment ID is used to distinguish between deployments and which silos belong to which deployments. The silo identity is defined as a combination of deploymentID, ip, port, epoch in appropriate tables and columns. The relational backend uses optimistic concurrency control and transactions, similar to the procedure of using ETags on Azure Table implementation. The relational implementation expects the database engine to generate the ETag used. In case of SQL Server, on SQL Server 2000 the generated ETag is one acquired from a call to NEWID() . On SQL Server 2005 and later ROWVERSION is used. Orleans reads and writes relational ETags as opaque VARBINARY(16) tags and stores them in memory as base64 encoded strings. Orleans supports multi-row inserts using UNION ALL (for Oracle including DUAL), which is currently used to insert statistics data. The exact implementation and rationale for SQL Server can be seen at CreateOrleansTables_SqlServer.sql . Apache ZooKeeper - in this implementation we use the configured deployment ID as a root node and the silo identity ( ip:port@epoch ) as its child node. Together they guarantee a unique path per silo. For concurrency control we use optimistic concurrency control based on the node version . Every time we read from the deployment root node we store the version for every read child silo node and use that version when we try to write back. Each time a node's data changes, the version number increases atomically by the ZooKeeper service. For multi-row transactions we utilize the multi method , which guarantees serializale transactions over silo nodes with the same parent deployment ID node. Consul IO - we used Consul's Key/Value store to impelement the membershop table. Refer to Consul-Deployment for more details. AWS DynamoDB - In this implementation we use the cluster Deployment ID as the Partition Key and Silo Identity ( ip-port-generation ) as the RangeKey making the record unity. The optimistic concurrency is made by the ETag attribute by making conditional writes on DynamoDB. The implementation logic is quite similar to Azure Table Storage. We only implemented the basic membership protocol (and not the extended protocol). In-memory emulation for development setup. We use a special system grain, called MembershipTableGrain , for that implementation. This grain lives on a designated primary silo, which is only used for a development setup . In any real production usage primary silo is not required . Configuration: Membership protocol is configured via the Liveness element in the Globals section in OrleansConfiguration.xml file. The default values were tuned in years of production usage in Azure and we believe they represent good default settings. There is no need in general to change them. Sample config element: <Liveness ProbeTimeout = \"5s\" TableRefreshTimeout =\"10s DeathVoteExpirationTimeout =\"80s\" NumMissedProbesLimit = \"3\" NumProbedSilos=\"3\" NumVotesForDeathDeclaration=\"2\" /> There are 4 types of liveness implemented. The type of the liveness protocol is configured via the SystemStoreType attribute of the SystemStore element in the Globals section in OrleansConfiguration.xml file. MembershipTableGrain - membership table is stored in a grain on primary silo. This is a development setup only . AzureTable - membership table is stored in Azure table. SqlServer - membership table is stored in a relational database. ZooKeeper - membership table is stored in a ZooKeeper ensemble . Consul - configured as Custom system store with MembershipTableAssembly = \"OrleansConsulUtils\" . Refer to Consul-Deployment for more details. DynamoDB - configured as a Custom system store with MembershipTableAssembly = \"OrleansAWSUtils\" . For all liveness types the common configuration variables are defined in Globals.Liveness element: ProbeTimeout - The number of seconds to probe other silos for their liveness or for the silo to send \"I am alive\" heartbeat messages about itself. Default is 10 seconds. TableRefreshTimeout - The number of seconds to fetch updates from the membership table. Default is 60 seconds. DeathVoteExpirationTimeout - Expiration time in seconds for death vote in the membership table. Default is 120 seconds NumMissedProbesLimi t - The number of missed \"I am alive\" heartbeat messages from a silo or number of un-replied probes that lead to suspecting this silo as dead. Default is 3. NumProbedSilos - The number of silos each silo probes for liveness. Default is 3. NumVotesForDeathDeclaration - The number of non-expired votes that are needed to declare some silo as dead (should be at most NumMissedProbesLimit). Default is 2. UseLivenessGossip - Whether to use the gossip optimization to speed up spreading liveness information. Default is true. IAmAliveTablePublishTimeout - The number of seconds to periodically write in the membership table that this silo is alive. Used only for diagnostics. Default is 5 minutes. NumMissedTableIAmAliveLimit - The number of missed \"I am alive\" updates in the table from a silo that causes warning to be logged. Does not impact the liveness protocol. Default is 2. MaxJoinAttemptTime - The number of seconds to attempt to join a cluster of silos before giving up. Default is 5 minutes. ExpectedClusterSize - The expected size of a cluster. Need not be very accurate, can be an overestimate. Used to tune the exponential backoff algorithm of retries to write to Azure table. Default is 20. Design Rationale: A natural question that might be asked is why not to rely completely on Apache ZooKeeper for the cluster membership implementation, potentially by using it's out of the box support for [group membership with ephemeral nodes] ( http://zookeeper.apache.org/doc/trunk/recipes.html#sc_outOfTheBox)? Why did we bother implementing our own membership protocol? There were primarily three reasons: 1) Deployment/Hosting in the Cloud - Zookeeper is not a hosted service (at least at the time of this writing July 2015 and definitely when we first implemented this protocol in the summer of 2011 there was no version of Zookeeper running as a hosted service by any major cloud provider). It means that in the Cloud environment Orleans customers would have to deploy/run/manage their own instance of a ZK cluster. This is just yet another unnecessary burden, that we did not want to force on our customers. By using Azure Table we rely on a hosted, managed service which makes our customers lives much simpler. Basically, in the Cloud, use Cloud as a Platform, not as an Infrastructure. On the other hand, when running on premises and managing your own servers, relying on ZK as an implementation of the MembershipTable is a viable option. 2) Direct failure detection - when using ZK's group membership with ephemeral nodes the failure detection is performed between the Orleans servers (ZK clients) and ZK servers. This may not necessarily correlate with the actual network problems between Orleans servers. Our desire was that the failure detection would accurately reflect the intra-cluster state of the communication. Specifically, in our design, if an Orleans silo cannot communicate with the MembershipTable it is not considered dead and can keep working. As opposite to that, have we used ZK group membership with ephemeral nodes a disconnection from a ZK server may cause an Orleans silo (ZK client) to be declared dead, while it may actually be alive and fully functional. 3) Portability and flexibility - as part of Orleans's philosophy, we do not want to force a strong dependence on any particular technology, but rather have a flexible design where different components can be easily switched with different implementations. This is exactly the purpuse that MembershipTable abstraction serves. Acknowledgements: We would to acknowledge the contribution of Alex Kogan to the design and implementation of the first version of this protocol. This work was done as part of summer internship in Microsoft Research in the Summer of 2011. The implementation of ZooKeeper based MembershipTable was done by Shay Hazor , the implementation of SQL MembershipTable was done by Veikko Eeva , the implementation of AWS DynamoDB MembershipTable was done by Gutemberg Ribeiro and the implementation of Consul based MembershipTable was done by Paul North ."
  },
  "docs/implementation/index.html": {
    "href": "docs/implementation/index.html",
    "title": "Implementation Details | Microsoft Orleans Documentation",
    "keywords": "Implementation Details Overview Orleans Lifecycle Some Orleans behaviors are sufficiently complex that they need ordered startup and shutdown. To address this, a general component lifecycle pattern has been introduced. Messaging Delivery Guarantees Orleans messaging delivery guarantees are at-most-once , by default. Optionally, if configured to do retries upon timeout, Orleans provides at-least-once delivery instead. Scheduler Orleans Scheduler is a component within the Orleans runtime responsible for executing application code and parts of the runtime code to ensure the single threaded execution semantics. Cluster Management Orleans provides cluster management via a built-in membership protocol, which we sometimes refer to as Silo Membership. The goal of this protocol is for all silos (Orleans servers) to agree on the set of currently alive silos, detect failed silos, and allow new silos to join the cluster. Streams Implementation This section provides a high level overview of Orleans Stream implementation. It describes concepts and details that are not visible on the application level. Load Balancing Load balancing, in a broad sense, is one of the pillars of the Orleans runtime. Unit Testing This section shows how to unit test your grains to make sure they behave correctly."
  },
  "docs/implementation/load_balancing.html": {
    "href": "docs/implementation/load_balancing.html",
    "title": "Load Balancing | Microsoft Orleans Documentation",
    "keywords": "Load Balancing Load balancing, in a broad sense, is one of the pillars of the Orleans runtime . Orleans runtime tries to make everything balanced, since balancing allows to maximize resource usage and avoid hotspots, which leads to better performance, as well as helps with elasticity. Load balancing in Orleans applies in multiple places. Below is a non-exhaustive list of places where the runtime performs balancing: Default actor placement strategy is random - new activations are placed randomly across silos. That results in a balanced placement and prevents hotspots for most scenarios. A more advanced ActivationCountPlacement tries to equalize the number of activations on all silos, which results in a more even distribution of activations across silos. This is especially important for elasticity. Grain Directory service is built on top of a Distributed Hash Table, which inherently is balanced. The directory service maps grains to activations, each silo owns part of the global mapping table, and this table is globally partitioned in a balanced way across all silos. We use consistent hashing with virtual buckets for that. Clients connect to all gateways and spread their requests across them, in a balanced way. Reminder service is a distributed partitioned runtime service. The assignment of which silo is responsible to serve which reminder is balanced across all silos via consistent hashing, just like in grain directory. Performance critical components within a silo are partitioned, and the work across them is locally balanced . That way the silo runtime can fully utilize all available CPU cores and not create in-silo bottlenecks. This applies to all local resources: allocation of work to threads, sockets, dispatch responsibilities, queues, etc. StreamQueueBalance balances the responsibility of pulling events from persistence queues across silos in the cluster. Also notice that balancing, in a broad sense, does not necessarily mean loss of locality . One can be balanced and still maintain a good locality. For example, when balancing means sharding/partitioning, you can partition responsibility for a certain logical task, while still maintaining locality within each partition. That applies both for local and distributed balancing. Refer to this presentation on Balancing Techniques in Orleans for more details."
  },
  "docs/implementation/messaging_delivery_guarantees.html": {
    "href": "docs/implementation/messaging_delivery_guarantees.html",
    "title": "Messaging Delivery Guarantees | Microsoft Orleans Documentation",
    "keywords": "Messaging Delivery Guarantees Orleans messaging delivery guarantees are at-most-once , by default. Optionally, if configured to do retries upon timeout, Orleans provides at-least-once deliv­ery instead. In more detail: Every message in Orleans has automatic timeout (the exact timeout can be configured). If the reply does not arrive on time, the return Task is broken with timeout exception. Orleans can be configured to do automatic retries upon timeout. By default it does NOT do automatic retries. Application code of course can also choose to do retries upon timeout. If the Orleans system is configured not to do automatic retries (default setting) and the application is not resending – Orleans provides at-most-once message delivery . A message will either be delivered once or not at all. It will never be delivered twice. In the system with retries (either by the runtime or by the application) the message may arrive multiple times. Orleans currently does nothing to durably store which messages already arrived and suppress the second delivery. (We believe this would be pretty costly.) So in a system with retries Orleans does NOT guarantee at most once delivery. If you keep retrying potentially indefinitely , the message will eventually arrive , thus providing at-least-once delivery guarantee. Notice that “will eventually arrive” is something that the runtime needs to guarantee. It does not come for free just by itself even if you keep retrying. Orleans provides eventual delivery since grains never go into any permanent failure state and a failed grain will eventually be re-activated on another silo. So to summarize : in the system without retries Orleans guarantees at-most-once message delivery. In the system with infinite retries Orleans guarantees at-least-once (and does NOT guarantee at-most-once). Note : In the Orleans technical report we accidentally only mentioned the 2nd option with automatic retries. We forgot to mention that by default with no retries, Orleans provides at-most-once delivery."
  },
  "docs/implementation/orleans_lifecycle.html": {
    "href": "docs/implementation/orleans_lifecycle.html",
    "title": "Orleans Lifecycle | Microsoft Orleans Documentation",
    "keywords": "Orleans Lifecycle Overview Some Orleans behaviors are sufficiently complex that they need ordered startup and shutdown. Some components with such behaviors include grains, silos, and clients. To address this, a general component lifecycle pattern has been introduced. This pattern consists of an observable lifecycle, which is responsible for signaling on stages of a component’s startup and shutdown, and lifecycle observers which are responsible for performing startup or shutdown operations at specific stages. See also Grain Lifecycle and Silo Lifecycle . Observable Lifecycle Components that need ordered startup and shutdown can use an observable lifecycle which allows other components to observe the LiveCycle and receive notification when a stage is reached during startup or shutdown. public interface ILifecycleObservable { IDisposable Subscribe(string observerName, int stage, ILifecycleObserver observer); } The subscribe call registers an observer for notification when a stage is reached while starting or stopping. The observer name is for reporting purposes. The stage indicated at which point in the startup/shutdown sequence the observer will be notified. Each stage of lifecycle is observable. All observers will be notified when the stage is reached when starting and stopping. Stages are started in ascending order and stopped in descending order. The observer can unsubscribe by disposing of the returned disposable. Lifecycle Observer Components which need to take part in another component’s lifecycle need provide hooks for their startup and shutdown behaviors and subscribe to a specific stage of an observable lifecycle. public interface ILifecycleObserver { Task OnStart(CancellationToken ct); Task OnStop(CancellationToken ct); } OnStart/OnStop will be called when the stage subscribed to is reached during startup/shutdown. Utilities For convenience, helper functions have been created for common lifecycle usage patterns. Extensions Extension functions exist for subscribing to observable lifecycle which do not require that the subscribing component implement ILifecycleObserver. Instead, these allow components to pass in lambdas or members function to be called at the subscribed stages. IDisposable Subscribe(this ILifecycleObservable observable, string observerName, int stage, Func<CancellationToken, Task> onStart, Func<CancellationToken, Task> onStop); IDisposable Subscribe(this ILifecycleObservable observable, string observerName, int stage, Func<CancellationToken, Task> onStart); Similar extension functions allow generic type arguments to be used in place of the observer name. IDisposable Subscribe<TObserver>(this ILifecycleObservable observable, int stage, Func<CancellationToken, Task> onStart, Func<CancellationToken, Task> onStop); IDisposable Subscribe<TObserver>(this ILifecycleObservable observable, int stage, Func<CancellationToken, Task> onStart); Lifecycle Participation Some extensibility points need a way of recognizing what components are interested in participating in a lifecycle. A lifecycle participant marker interface has been introduced for this purpose. More about how this is used will be covered when exploring silo and grain lifecycles. public interface ILifecycleParticipant<TLifecycleObservable> where TLifecycleObservable : ILifecycleObservable { void Participate(TLifecycleObservable lifecycle); } Example From our lifecycle tests, below is an example of a component that takes part in an observable lifecycle at multiple stages of the lifecycle. enum TestStages { Down, Initialize, Configure, Run, } class MultiStageObserver : ILifecycleParticipant<ILifecycleObservable> { public Dictionary<TestStages,bool> Started { get; } = new Dictionary<TestStages, bool>(); public Dictionary<TestStages, bool> Stopped { get; } = new Dictionary<TestStages, bool>(); private Task OnStartStage(TestStages stage) { this.Started[stage] = true; return Task.CompletedTask; } private Task OnStopStage(TestStages stage) { this.Stopped[stage] = true; return Task.CompletedTask; } public void Participate(ILifecycleObservable lifecycle) { lifecycle.Subscribe<MultiStageObserver>((int)TestStages.Down, ct => OnStartStage(TestStages.Down), ct => OnStopStage(TestStages.Down)); lifecycle.Subscribe<MultiStageObserver>((int)TestStages.Initialize, ct => OnStartStage(TestStages.Initialize), ct => OnStopStage(TestStages.Initialize)); lifecycle.Subscribe<MultiStageObserver>((int)TestStages.Configure, ct => OnStartStage(TestStages.Configure), ct => OnStopStage(TestStages.Configure)); lifecycle.Subscribe<MultiStageObserver>((int)TestStages.Run, ct => OnStartStage(TestStages.Run), ct => OnStopStage(TestStages.Run)); } }"
  },
  "docs/implementation/scheduler.html": {
    "href": "docs/implementation/scheduler.html",
    "title": "Scheduler | Microsoft Orleans Documentation",
    "keywords": "Scheduler Orleans Scheduler is a component within the Orleans runtime responsible for executing application code and parts of the runtime code to ensure the single threaded execution semantics . It implements a custom TPL Task scheduler. Orleans Task scheduler is a hierarchical 2 level scheduler. At the first level there is the global OrleansTaskScheduler that is responsible for execution of system activities. At the second level every grain activation has its own ActivationTaskScheduler , which provides the single threaded execution semantics. At a high level, the execution path is the following: A request arrives to the correct silo and the destination activation is found. A request is translated into a Task that is queued for execution by that activation, on its ActivationTaskScheduler. Any subsequent Task created as part of the grain method execution is natively enqueued to the same ActivationTaskScheduler, via the standard TaskScheduler mechanism. Every ActivationTaskScheduler has a queue of tasks queued for execution. Orleans Scheduler has a set of worker threads that are collectively used by all the activation schedulers. Those threads periodically scan all the scheduler queues for work to execute. A thread takes a queue (each queue is taken by one thread at a time) and starts executing Tasks in that queue in FIFO order. The combination of one thread at a time taking a queue and the thread executing Tasks sequentially is what provides the single threaded execution semantics. Work Items: Orleans uses a notion of Work Items to designate the entry point into the scheduler. Every new request is enqueued initially as a work item which simply wraps the execution of the first Task for that request. Work items simply provide more contextual information about the scheduling activity (the caller, the name of the activity, logging) and sometimes some extra work that has to be done on behalf of that scheduling activity (post invocation activity in Invoke work item). There are currently the following work item types: Invoke work item – this is the mostly frequently used work item type. It represents execution of an application request. Request/Response work items – executes a system request (request to a SystemTarget) TaskWorkItem – represent a Task queued to the top level OrleansTaskScheduler. Used instead of a direct Task just for convenience of data structures (more details below). WorkItemGroup – group of work items that share the same scheduler. Used to wrap a queue of Tasks for each ActivationTaskScheduler. ClosureWorkItem – a wrapper around a closure (arbitrary lambda) that is queued to the system context. Scheduling Context: Scheduling Context is a tag, just an opaque object that represents scheduling target – activation data, system target or system null context. High level Principles: Tasks are always queued to the correct scheduler 1.1 Tasks are never moved around from one scheduler to another. 1.2 We never create tasks on behalf of other tasks to execute them. 1.3 WorkItems are wrapped within Task (that is, in order to execute a work item, we create a Task whose lambda function will just run the work item lambda). By always going via tasks we ensure that any activity is executed via an appropriate Task scheduler. Tasks are executed on the scheduler where they were queued by using base.TryExecute (and not by RunSynchronously) There is a one to one mapping between ATS, WorkItem Group and Scheduling Context: 3.1 Activation Task Scheduler (ATS) is a custom TPL scheduler. We keep ATS thin and store all the data in WorkItemGroup. ATS points to its WorkItemGroup. 3.2 WorkItem Group is the actual holder (data object) of the activation Tasks. The Tasks are stored in a List - the queue of all tasks for its ATS. WorkItemGroup points back to its ATS. Data Flow and Execution of Tasks and Work items: The entry point is always a work item enqueued into OrleansTaskScheduler. It can be one of the Invoke/Request/Response/Closure WorkItem. Wrapped into a Task and enqueued into the correct ActivationTaskScheduler based on the context via Task.Start. A Task that is queued to its ActivationTaskScheduler is put into the WorkItemGroup queue. When a Task is put into a WorkItemGroup queue, WorkItemGroup makes sure it appears in OrleansTaskScheduler global RunQueue. RunQueue is the global queue of runnable WorkItemGroups, those that have at least one Task queued, and thus ready to be executed. Worker threads scan the RunQueue of OrleansTaskScheduler which hold WorkItemGroups and call WorkItemGroups.Execute WorkItemGroups.Execute scans the queue of its tasks and executes them via ActivationTaskScheduler.RunTask(Task) 6.1 ActivationTaskScheduler.RunTask(Task) calls base.TryExecute. 6.2 Task that were enqueued directly to the scheduler via TPL will just execute. 6.3 Tasks that wrap work items will call workItem.Execute which will execute the Closure work item delegate. Low level design – Work Items: Queueing work items to OrleansTaskScheduler is how the whole chain of execution for every request starts in the Orleans runtime. This is our entry point into the Scheduler. Work items are first submitted to OrleansTaskScheduler (since this is the interface presented to the rest of the system). 2.1 Only closure/invoke/resume work items can be submitted this way. 2.2 TaskWorkItem cannot be submitted to OrleansTaskScheduler directly (read more below on handling of TaskWorkItem). Every work item must be wrapped into Task and enqueued to the right scheduler via Task.Start. 3.1 This will make sure the TaskScheduler.Current is set correctly on any Task that is created implicitly during execution of this workItem. 3.2 Wrapping is done by creating a Task via WrapWorkItemAsTask that will execute the work item and enqueuing it to the right scheduler via Task.Start(scheduler). 3.3 Work items for the null context are queued to OrleansTaskScheduler. 3.4 Work items for non-null contexts are queued to ActivationTaskScheduler. Low level design – Queueing Tasks: Tasks are queued directly to the right scheduler 1.1 Tasks are queued implicitly by TPL via protected override void QueueTask(Task task) 1.2 A Task that has a non-null context is always enqueued to ActivationTaskScheduler 1.3 A Task that has the null context is always enqueued to OrleansTaskScheduler Queueing Tasks to ActivationTaskScheduler: 2.1 We never wrap a Task in another Task. A Task gets added directly to the WorkItem Group queue Queueing Tasks to OrleansTaskScheduler: 3.1 When a Task is enqueued to the OrleansTaskScheduler, we wrap it into a TaskWorkItem and put it into this scheduler’s queue of work items. 3.2 This is just a matter of data structures, nothing inherent about it: 3.3 OrleansTaskScheduler usually holds work item groups to schedule them, so its RunQueue has a BlockingCollection . 3.4 Since tasks to the null context are also queued to OrleansTaskScheduler, we reuse the same data structure, thus we have to wrap each Task in a TaskWorkItem. 3.5 We should be able to get rid of this wrapping completely by adjusting the RunQueue data structure. This may simplify the code a bit, but in general should not matter. Also, in the future we should move away from the null context anyway, so this issue will be gone anyway Inlining tasks: Since Tasks are always queued to the right scheduler, in theory it should always be safe to inline any Task."
  },
  "docs/implementation/streams_implementation/azure_queue_streams.html": {
    "href": "docs/implementation/streams_implementation/azure_queue_streams.html",
    "title": "Azure Queue Streams Implementation Details | Microsoft Orleans Documentation",
    "keywords": "Orleans Azure Queue Streams Implementation Details Each stream provider (Azure Queues, EventHub, SMS, SQS, ...) has it's own queue specific details and configuration. This section provides some details about the usage, configuration and implementation of Orleans Azure Queue Streams . This section is not comprehensive, and more details are available in the streaming tests, which contain most of the configuration options, specifically AQClientStreamTests , AQSubscriptionMultiplicityTests , and the extension functions for IAzureQueueStreamConfigurator and ISiloPersistentStreamConfigurator . Overview Orleans Azure Queue requires the package Microsoft.Orleans.Streaming.AzureStorage . The package contains - in addition to the implementation - also some extension methods that make the configuration at silo startup easier. The minimal configuration requires at least to specify the connection string, as example: hostBuilder .AddAzureQueueStreams(\"AzureQueueProvider\", configurator => { configurator.ConfigureAzureQueue( ob => ob.Configure(options => { options.ConnectionString = \"xxx\"; options.QueueNames = new List<string> { \"yourprefix-azurequeueprovider-0\" }; })); configurator.ConfigureCacheSize(1024); configurator.ConfigurePullingAgent(ob => ob.Configure(options => { options.GetQueueMsgsTimerPeriod = TimeSpan.FromMilliseconds(200); })); }) // a PubSubStore could be needed, as example Azure Table Storage .AddAzureTableGrainStorage(\"PubSubStore\", options => { options.ConnectionString = \"xxx\"; }) The pulling agents will pull repeatedly until there are no more messages on a queue, then delay for a configurable period before continuing to pull. This process occurs for each queue . Internally the pulling agents place messages in a cache (one cache per queue) for delivery to consumers, but will stop reading if the cache fills up. Messages are removed from the cache once consumers process the messages, so the read rate should roughly be throttled by the processing rate of the consumers. By default it uses 8 queues (see AzureQueueOptions ) and 8 related pulling agents, a delay of 100ms (see StreamPullingAgentOptions.GetQueueMsgsTimerPeriod ) and a cache size ( IQueueCache ) of 4096 messages (see SimpleQueueCacheOptions.CacheSize ). Configuration The default configuration should fit a production environment, but for special needs it's possible to configure the default behaviour. As example, in a development machine it's possible to reduce the number of the pulling agents to using just one queue. This can help to reduce CPU usage and resource pressure. hostBuilder .AddAzureQueueStreams<AzureQueueDataAdapterV2>(\"AzureQueueProvider\", optionsBuilder => optionsBuilder.Configure(options => { options.ConnectionString = \"xxx\"; options.QueueNames = new List<string> { \"yourprefix-azurequeueprovider-0\" }; })) Tuning In a production system can emerge the need of tuning over the default configuration. When tuning there are some factors that should be considered, and it's service specific. First, most of the settings are per queue, so for a large number of streams, the load on each queue can be reduced by configuring more queues. Since streams process messages in order per stream, the gating factor will be the number of events being sent on a single stream. A reasonable balance of cache time ( StreamPullingAgentOptions.GetQueueMsgsTimerPeriod ) vs visibility time ( AzureQueueOptions.MessageVisibilityTimeout ) is that the visibility should be configured to double the time messages are expected to be in the cache. Example Assuming a system with this characteristics: 100 streams, 10 queues, Each stream processing 60 messages per minute, Each message takes around 30ms to process, 1 minute worth of messages in cache (cache time). So we can calculate some parameters of the system: Streams/queue: Even balancing of streams across queues would be an ideal 10 streams/queue (100 streams / 10 queues). But since streams won't always be evenly balanced over the queues, doubling (or even tripling) the ideal is safer than expecting ideal distribution. Hence 20 streams/queue (10 streams/queue x 2 as safety factor) is probably reasonable. Messages/minute: This means each queue will be expected to process up to 1200 messages/minute (60 messages x 20 streams). Then we can determine the visibility time to use: Visibility time: The cache time (1 minute) is configured to hold 1 minute of messages (so 1200 messages, as we calculated messages/minute above). We assumed that each message takes 30 ms to process, then we can expect messages to spend up to 36 seconds in the cache (0.030 sec x 1200 msg = 36 sec), so the visibility time - doubled for safety - would need be over 72 seconds (36 sec of time in cache x 2). Accordingly, if we define a bigger cache, that would require a longer visibility time. Final considerations in a real world system: Since order is only per stream, and a queue consume many streams, it's likely that messages will be processed across multiple streams in parallel (as example: we have a grain for stream, which can run in parallel). This means we'll burn through the cache in far less time, but we planned for the worse case: it will give the system room to continue to function well even under intermittent delays and transient errors. So we can configure Azure Queue Streams using: hostBuilder .AddAzureQueueStreams(\"AzureQueueProvider\", configurator => { configurator.ConfigureAzureQueue( ob => ob.Configure(options => { options.ConnectionString = \"xxx\"; options.QueueNames = new List<string> { \"yourprefix-azurequeueprovider-1\", [...] \"yourprefix-azurequeueprovider-10\", }; options.MessageVisibilityTimeout = TimeSpan.FromSeconds(72); })); configurator.ConfigureCacheSize(1200); })"
  },
  "docs/implementation/streams_implementation/index.html": {
    "href": "docs/implementation/streams_implementation/index.html",
    "title": "Streams Implementation Details | Microsoft Orleans Documentation",
    "keywords": "Orleans Streams Implementation Details This section provides a high level overview of Orleans Stream implementation. It describes concepts and details that are not visible on the application level. If you only plan to use streams, you do not have to read this section. Terminology : We refer by the word \"queue\" to any durable storage technology that can ingest stream events and allows either to pull events or provides a push-based mechanism to consume events. Usually, to provide scalability, those technologies provide sharded/partitioned queues. For example, Azure Queues allow to create multiple queues, Event Hubs have multiple hubs, Kafka topics, ... Persistent Streams All Orleans Persistent Stream Providers share a common implementation PersistentStreamProvider . This generic stream provider needs be configured with a technology specific IQueueAdapterFactory . For instance, for testing purposes we have queue adapters that generate their own test data rather than reading the data from a queue. The code below shows how we configure a persistent stream provider to use our custom (generator) queue adapter. It does this by configuring the persistent stream provider with a factory function used to create the adapter. hostBuilder.AddPersistentStreams(StreamProviderName, GeneratorAdapterFactory.Create); When a stream producer generates a new stream item and calls stream.OnNext() , the Orleans Streaming Runtime invokes the appropriate method on the IQueueAdapter of that stream provider which enqueues the item directly onto the appropriate queue. Pulling Agents At the heart of the Persistent Stream Provider are the pulling agents. Pulling agents pull events from a set of durable queues and deliver them to the application code in grains that consumes them. One can think of the pulling agents as a distributed \"micro-service\" -- a partitioned, highly available, and elastic distributed component. The pulling agents run inside the same silos that host application grains and are fully managed by the Orleans Streaming Runtime. StreamQueueMapper and StreamQueueBalancer Pulling agents are parameterized with IStreamQueueMapper and IStreamQueueBalancer . IStreamQueueMapper provides a list of all queues and is also responsible for mapping streams to queues. That way, the producer side of the Persistent Stream Provider knows into which queue to enqueue the message. IStreamQueueBalancer expresses the way queues are balanced across Orleans silos and agents. The goal is to assign queues to agents in a balanced way, to prevent bottlenecks and support elasticity. When a new silo is added to the Orleans cluster, queues are automatically rebalanced across the old and new silos. StreamQueueBalancer allows customizing that process. Orleans has a number of built-in StreamQueueBalancers, to support different balancing scenarios (large and small number of queues) and different environments (Azure, on prem, static). Using the test generator example from above, the code below shows how one could configure the queue mapper and queue balancer. hostBuilder .AddPersistentStreams(StreamProviderName, GeneratorAdapterFactory.Create, providerConfigurator=>providerConfigurator .Configure<HashRingStreamQueueMapperOptions>(ob=>ob.Configure( options=>{ options.TotalQueueCount = 8; })) .UseDynamicClusterConfigDeploymentBalancer() ); The above code configures the GeneratorAdapter to use a queue mapper with 8 queues, and balances the queues across the cluster using the DynamicClusterConfigDeploymentBalancer . Pulling Protocol Every silo runs a set of pulling agents, every agent is pulling from one queue. Pulling agents themselves are implemented by an internal runtime component, called SystemTarget . SystemTargets are essentially runtime grains, are subject to single threaded concurrency, can use regular grain messaging, and are as lightweight as grains. In contrast to grains, SystemTargets are not virtual: they are explicitly created (by the runtime) and are not location transparent. By implementing pulling agents as SystemTargets, the Orleans Streaming Runtime can rely on built-in Orleans features and can scale to a very large number of queues, since creating a new pulling agent is as cheap as creating a new grain. Every pulling agent runs a periodic timer that pulls from the queue (by invoking IQueueAdapterReceiver ) GetQueueMessagesAsync() method. The returned messages are put in the internal per-agent data structure called IQueueCache . Every message is inspected to find out its destination stream. The agent uses the Pub Sub to find out the list of stream consumers that subscribed to this stream. Once the consumer list is retrieved, the agent stores it locally (in its pub-sub cache) so it does not need to consult with Pub Sub on every message. The agent also subscribes to the pub-sub to receive notification of any new consumers that subscribe to that stream. This handshake between the agent and the pub-sub guarantees strong streaming subscription semantics : once the consumer has subscribed to the stream it will see all events that were generated after it has subscribed . In addition, using StreamSequenceToken allows it to subscribe in the past. Queue Cache IQueueCache is an internal per-agent data structure that allows to decoupling dequeuing new events from the queue and delivering them to consumers. It also allows to decoupling delivery to different streams and to different consumers. Imagine a situation where one stream has 3 stream consumers and one of them is slow. If care is not taken, it is possible that this slow consumer will impact the agent's progress, slowing the consumption of other consumers of that stream, and even slowing the dequeuing and delivery of events for other streams. To prevent that and allow maximum parallelism in the agent, we use IQueueCache . IQueueCache buffers stream events and provides a way for the agent to deliver events to each consumer at its own pace. The per-consumer delivery is implemented by the internal component called IQueueCacheCursor , which tracks per-consumer progress. That way, each consumer receives events at its own pace: fast consumers receive events as quickly as they are dequeued from the queue, while slow consumers receive them later on. Once the message is delivered to all consumers, it can be deleted from the cache. Backpressure Backpressure in the Orleans Streaming Runtime applies in two places: bringing stream events from the queue to the agent and delivering the events from the agent to stream consumers . The latter is provided by the built-in Orleans message delivery mechanism. Every stream event is delivered from the agent to consumers via the standard Orleans grain messaging, one at a time. That is, the agents sends one event (or a limited size batch of events) to each individual stream consumer and awaits this call. The next event will not start being delivered until the Task for the previous event was resolved or broken. That way we naturally limit the per-consumer delivery rate to one message at a time. With regard to bringing stream events from the queue to the agent, Orleans Streaming provides a new special Backpressure mechanism. Since the agent decouples dequeuing of events from the queue and delivering them to consumers, it is possible that a single slow consumer will fall behind so much that the IQueueCache will fill up. To prevent IQueueCache from growing indefinitely, we limit its size (the size limit is configurable). However, the agent never throws away undelivered events. Instead, when the cache starts to fill up, the agents slow the rate of dequeuing events from the queue. That way, we can \"ride out\" the slow delivery periods by adjusting the rate at which we consume from the queue (\"backpressure\") and get back into fast consumption rate later on. To detect the \"slow delivery\" valleys the IQueueCache uses an internal data structure of cache buckets that tracks the progress of delivery of events to individual stream consumers. This results in a very responsive and self-adjusting system."
  },
  "docs/implementation/testing.html": {
    "href": "docs/implementation/testing.html",
    "title": "Unit Testing | Microsoft Orleans Documentation",
    "keywords": "Unit Testing This tutorial shows how to unit test your grains to make sure they behave correctly. There are two main ways to unit test your grains, and the method you choose will depend on the type of functionality you are testing. The Microsoft.Orleans.TestingHost NuGet package can be used to create test silos for your grains, or you can use a mocking framework like Moq to mock parts of the Orleans runtime that your grain interacts with. Using TestCluster The Microsoft.Orleans.TestingHost NuGet package contains TestCluster which can be used to create an in-memory cluster, comprised of two silos by default, which can be used to test grains. using System; using System.Threading.Tasks; using Orleans; using Orleans.TestingHost; using Xunit; namespace Tests { public class HelloGrainTests { [Fact] public async Task SaysHelloCorrectly() { var cluster = new TestCluster(); cluster.Deploy(); var hello = cluster.GrainFactory.GetGrain<IHelloGrain>(Guid.NewGuid()); var greeting = await hello.SayHello(); cluster.StopAllSilos(); Assert.Equal(\"Hello, World\", greeting); } } } Due to the overhead of starting an in-memory cluster you may wish to create a TestCluster and reuse it among multiple test cases. For example this can be done using xUnit's class or collection fixtures (see https://xunit.github.io/docs/shared-context.html for more details). In order to share a TestCluster between multiple test cases, first create a fixture type: public class ClusterFixture : IDisposable { public ClusterFixture() { this.Cluster = new TestCluster(); this.Cluster.Deploy(); } public void Dispose() { this.Cluster.StopAllSilos(); } public TestCluster Cluster { get; private set; } } Next create a collection fixture: [CollectionDefinition(ClusterCollection.Name)] public class ClusterCollection : ICollectionFixture<ClusterFixture> { public const string Name = \"ClusterCollection\"; } You can now reuse a TestCluster in your test cases: using System; using System.Threading.Tasks; using Orleans; using Xunit; namespace Tests { [Collection(ClusterCollection.Name)] public class HelloGrainTests { private readonly TestCluster _cluster; public HelloGrainTests(ClusterFixture fixture) { _cluster = fixture.Cluster; } [Fact] public async Task SaysHelloCorrectly() { var hello = _cluster.GrainFactory.GetGrain<IHelloGrain>(Guid.NewGuid()); var greeting = await hello.SayHell(); Assert.Equal(\"Hello, World\", greeting); } } } xUnit will call the Dispose method of the ClusterFixture type when all tests have been completed and the in-memory cluster silos will be stopped. TestCluster also has a constructor which accepts TestClusterOptions that can be used to configure the silos in the cluster. If you are using Dependency Injection in your Silo to make services available to Grains, you can use this pattern as well: public class ClusterFixture : IDisposable { public ClusterFixture() { var builder = new TestClusterBuilder(); builder.AddSiloBuilderConfigurator<TestSiloConfigurations>(); this.Cluster = builder.Build(); this.Cluster.Deploy(); } public void Dispose() { this.Cluster.StopAllSilos(); } public TestCluster Cluster { get; private set; } } public class TestSiloConfigurations : ISiloBuilderConfigurator { public void Configure(ISiloHostBuilder hostBuilder) { hostBuilder.ConfigureServices(services => { services.AddSingleton<T, Impl>(...); }); } } Using Mocks Orleans also makes it possible to mock many parts of system, and for many of scenarios this is the easiest way to unit test grains. This approach does have limitations (e.g. around scheduling reentrancy and serialization), and may require that grains include code used only by your unit tests. The Orleans TestKit provides an alternative approach which side-steps many of these limitations. For example, let us imagine that the grain we are testing interacts with other grains. In order to be able to mock those other grains we also need to mock the GrainFactory member of the grain under test. By default GrainFactory is a normal protected property, but most mocking frameworks require properties to be public and virtual to be able to mock them. So the first thing we need to do is make GrainFactory both public and virtual property: public new virtual IGrainFactory GrainFactory { get { return base.GrainFactory; } } Now we can create our grain outside of the Orleans runtime and use mocking to control the behaviour of GrainFactory : using System; using System.Threading.Tasks; using Orleans; using Xunit; using Moq; namespace Tests { public class WorkerGrainTests { [Fact] public async Task RecordsMessageInJournal() { var data = \"Hello, World\"; var journal = new Mock<IJournalGrain>(); var worker = new Mock<WorkerGrain>(); worker .Setup(x => x.GrainFactory.GetGrain<IJournalGrain>(It.IsAny<Guid>())) .Returns(journal.Object); await worker.DoWork(data) journal.Verify(x => x.Record(data), Times.Once()); } } } Here we create our grain under test, WorkerGrain , using Moq which means we can then override the behaviour of the GrainFactory so that it returns a mocked IJournalGrain . We can then verify that our WorkerGrain interacts with the IJournalGrain as we expect."
  },
  "docs/index.html": {
    "href": "docs/index.html",
    "title": "Introduction | Microsoft Orleans Documentation",
    "keywords": "Orleans是一个用于构建健壮、可伸缩的分布式应用程序的跨平台框架 Orleans建立在.NET开发人员生产力的基础上，并将其带入了分布式应用程序的世界，例如云服务。 Orleans可从单个本地服务器扩展到云中全局分布的高可用性应用程序。 Orleans采用了对象，接口，async/await和try/catch等熟悉的概念，并将其扩展到多服务器环境。 这样，它可以帮助具有单服务器应用程序经验的开发人员过渡到构建弹性，可扩展的云服务和其他分布式应用程序。 因此，Orleans通常被称为“分布式.NET”。 它是由 Microsoft Research 创建的，并介绍了 Virtual Actor Model 作为一种新方法来构建面向云时代的新一代分布式系统。 Orleans的核心贡献是它的编程模型，它在不限制功能，以及对开发人员施加繁重约束的情况下，降低了高并发分布式系统固有的复杂性。 Grains 任何Orleans应用程序的基本构建块都是 grain . Grains是由用户定义的身份、 行为和状态组成的实体。 grains标识是用户定义的键，使grains始终可供调用。 Grains可以通过强类型通信接口(contract)被其他Grains或Web前端等外部客户端调用。 每个grains都是实现一个或多个这些接口的类的一个实例。 Grains可以具有挥发性和/或持久化状态，可以存储在任何存储系统中。 因此，grains隐式地划分应用程序状态，从而实现自动可伸缩性并简化故障恢复。 当Grain处于活动状态时，Grain状态被保存在内存中，从而降低了延迟和数据存储的负载。 grains的实例化由Orleans运行时根据需要自动执行。 暂时不使用的grains会自动从内存中删除以释放资源。 这是有可能的，因为它们具有稳定的身份，允许调用grains，不管它们是否已经加载到内存中。 这还允许透明地从失败中恢复，因为调用方不需要知道在任何时间点在哪个服务器上实例化了一个grain。 Grains有一个受管理的生命周期，Orleans运行时负责激活/停用Grains，并根据需要存储/定位Grains。 这允许开发人员编写代码，就好像所有的grains总是在内存中一样。 总的来说，稳定的标识、有状态性和可管理的生命周期是构建在Orleans之上的系统可伸缩、高性能的核心因素，&可靠，不必强迫开发人员编写复杂的分布式系统代码。 示例：物联网云后端 考虑一个云后端 物联网 系统。 此应用程序需要处理传入的设备数据、筛选、聚合和处理这些信息，并允许向设备发送命令。 在Orleans，人们很自然地用一种Grains来模拟每一种设备，这种Grains变成了 数码双胞胎 它所对应的物理设备。 这些grains将最新的设备数据保存在内存中，这样就可以快速地查询和处理它们，而不需要直接与物理设备通信。 通过观察来自设备的时间序列数据流，grains可以检测条件的变化，例如测量值超过阈值，并触发一个动作。 一个简单的恒温器可以建模如下： public interface IThermostat : IGrainWithStringKey { Task<List<Command>> OnUpdate(ThermostatStatus update); } 从Web前端从恒温器到达的事件可以通过调用 OnUpdate 方法，它可以选择将命令返回给设备。 var thermostat = client.GetGrain<IThermostat>(id); return await thermostat.OnUpdate(update); 相同的恒温器grains可实现单独的接口，以便控制系统与： public interface IThermostatControl : IGrainWithStringKey { Task<ThermostatStatus> GetStatus(); Task UpdateConfiguration(ThermostatConfiguration config); } 这两个接口( IThermostat 和 IThermostatControl )由单个实现类实现： public class ThermostatGrain : Grain, IThermostat, IThermostatControl { private ThermostatStatus _status; private List<Command> _commands; public Task<List<Command>> OnUpdate(ThermostatStatus status) { _status = status; var result = _commands; _commands = new List<Command>(); return Task.FromResult(result); } public Task<ThermostatStatus> GetStatus() => Task.FromResult(_status); public Task UpdateConfiguration(ThermostatConfiguration config) { _commands.Add(new ConfigUpdateCommand(config)); return Task.CompletedTask; } } 上面的Grains类不会保持其状态。 文档 中提供了演示状态持久化的更彻底的示例。 Orleans运行时 Orleans运行时为应用程序运行时的主要组件是 silos ，负责寄存Grains。 通常，一组silos作为集群运行，以实现可伸缩性和容错性。 当作为集群运行时，silos相互协调以分配工作、检测并从故障中恢复。 运行时使集群中托管的grains能够像在单个进程中一样相互通信。 除了核心编程模型之外，silos还为grains提供了一组运行时服务，例如计时器、提醒(persistent timers)、持久化、事务、流等。 见 特色部分 下面是更多细节。 Web前端和其他外部客户端使用客户端库调用集群中的grains，该库自动管理网络通信。 为了简单起见，客户端也可以与silos在同一进程中共同托管。 Orleans与.NET Standard 2.0及更高版本兼容，运行在Windows、Linux和macOS上，采用完整的.NET Framework或.NET核心。 特征 持久化 Orleans提供了一个简单的持久化模型，确保在处理请求之前，状态对grain是可用的，并且保持一致性。 Grains可以有多个命名的持久化数据对象，例如，一个名为“profile”的用户概要文件，一个名为“inventory”的存储。 此状态可以存储在任何存储系统中。 例如，配置文件数据可以存储在一个数据库中，而库存存储在另一个数据库中。 当一个grain正在运行时，这个状态被保存在内存中，这样就可以在不访问存储器的情况下处理读请求。 当grains更新其状态时 state.WriteStateAsync() call确保备份存储的持久化和一致性得到更新。 有关详细信息，请参见 Grains持久化 文档。 分布式ACID事务 除了上述简单的持久性模型外，Grains还可以有 个事务性状态 。 多个谷物可以一起参与 ACID 事务，不管其最终的状态存储在哪里。 Orleans的事务是分布式和分散的(没有中央事务管理器或事务协调器)，并且 可串行隔离 . 有关Orleans交易的更多信息，请参阅 文档 以及 微软研究院技术报告 . 关于Orleans事务的更多信息，请参阅 文档 and Microsoft Research technical report 。 Streams 流帮助开发人员以近乎实时的方式处理一系列数据项。 Orleans的Streams 管理 ：在Grain或客户端发布到流或订阅流之前，不需要创建或注册流。 这使得流生产者和消费者之间以及与基础设施之间的更大程度的分离。 流处理是可靠的：grains可以存储检查点(游标)，并在激活期间或之后的任何时间重置为存储的检查点。 Streams支持向使用者批量传递消息，以提高效率和恢复性能。 流由排队服务支持，如Azure事件中心、Amazon Kinesis等。 可以将任意数量的流多路复用到较小数量的队列上，并且处理这些队列的责任在集群中均衡。 计时器&提醒 提醒是一种持久的Grains调度机制。 它们可用于确保在将来某个时间点完成某些操作，即使此时grains当前未激活。 计时器是非持久化的提醒物，可用于不需要可靠性的高频事件。 有关详细信息，请参见 计时器和提醒 文档。 灵活的Grains存储 当一个Grains在Orleans被激活时，运行时决定在哪个服务器(silos)上激活该Grains。 这叫做Grains安置。 Orleans的布局过程是完全可配置的：开发人员可以从一组现成的布局策略中进行选择，例如随机、首选本地和基于负载的，或者可以配置自定义逻辑。 这样就可以充分灵活地决定在哪里产生grains。 例如，Grains 可以放置在靠近资源的服务器上，靠近他们需要使用的资源或与他们交流的其他Grains。 有关详细信息，请参见 Grains持久化 文档。 Grains版本化&异构集群 应用程序代码会随着时间的推移而发展，以安全地解释这些更改的方式升级实时生产系统可能是一项挑战，尤其是在有状态的系统中。 Orleans的Grains接口可以选择性地进行版本控制。 集群维护了一个映射，映射出集群中的哪些Silo上有哪些grain实现以及这些实现的版本。 运行时将此版本信息与存储策略结合使用，以便在将调用路由到grains时做出存储决策。 除了安全地更新版本化的grains之外，这还支持异构集群，其中不同的silo具有不同的grain实现集。 有关详细信息，请参见 Grains版本化 文档。 弹性伸缩性&容错 Orleans的设计是弹性伸缩的。 当silos加入集群时，它能够接受新的激活，当silos离开集群时(由于规模缩小或机器故障)，在该silos上激活的Grains将根据需要在其余silos上重新激活。 一个Orleans集群可以缩小到一个silos。 支持弹性伸缩性的相同属性也支持容错：集群自动检测并从故障中快速恢复。 运行在任何地方 Orleans运行任何支持.NETCore或.NETFramework的地方。 这包括在Linux、Windows和macOS上托管，并部署到Kubernetes、虚拟机或物理机、本地或云中，以及PaaS服务(如Azure云服务)。 无状态工作者 无状态工作者是特殊标记的grains，没有任何关联状态，可以同时在多个silos上激活。 这样就可以提高无状态函数的并行性。 有关详细信息，请参见 无状态工作者Grains 文档。 Grains拦截器 许多Grains的共同逻辑可以表示为 Grains拦截器 。 Orleans支持用于入站和出站调用的过滤器。 过滤器的一些常见用例有：授权、日志记录和遥测以及错误处理。 请求上下文 元数据和其他信息可以通过使用 请求上下文 . 请求上下文可用于打孔分布式跟踪信息或任何其他用户定义的值。 请求上下文可以用于持有分布式追踪信息或任何其他用户定义的值。 入门 请看 入门教程 . 构建 在Windows上，运行 build.cmd 脚本在本地构建NuGet包，然后从中引用所需的NuGet包 /Artifacts/Release/* . 你可以跑了 Test.cmd 运行所有BVT测试，以及 TestAll.cmd 同时运行功能测试。 您可以运行 Test.cmd 来运行所有 BVT 测试， TestAll.cmd 同时运行功能测试。 在Linux和macOS上，运行 build.sh 脚本或 dotnet build ./OrleansCrossPlatform.sln 构建Orleans。 官方构建 最新的稳定，生产质量发布 在这里 . 夜间生成发布到 https://dotnet.myget.org/gallery/orleans-ci . 这些构建通过了所有的功能测试，但是没有像发布到NuGet的稳定版本或预发布版本那样进行彻底测试。 这些构建通过了所有功能测试，但是由于稳定的构建或预发布版本发布到Nuget而没有经过彻底测试。 在项目中使用夜间构建包 要在项目中使用夜间生成，请使用以下任一方法添加MyGet提要： 更改.csproj文件以包含此节： <RestoreSources> $(RestoreSources); https://dotnet.myget.org/F/orleans-ci/api/v3/index.json; </RestoreSources> 或 创建 NuGet.config文件 包含以下内容的解决方案目录中的文件： <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <packageSources> <clear /> <add key=\"orleans-ci\" value=\"https://dotnet.myget.org/F/orleans-ci/api/v3/index.json\" /> <add key=\"nuget\" value=\"https://api.nuget.org/v3/index.json\" /> </packageSources> </configuration> 社区 提问方式 在GitHub上打开问题 或者在 堆栈溢出 在Gitter上聊天 Orleans博客 跟随 @Orleans小姐 Orleans公告的Twitter帐户。 OrleansContrib-面向Orleans社区附加组件的GitHub组织 各种社区项目，包括监视、设计模式、存储提供程序等。 开发人员希望 为Orleans贡献代码更改 . 我们还鼓励您报告错误或通过启动新的 会话 在GitHub上。 许可证 本项目根据 MIT license . 快速链接 Microsoft研究项目主页 技术报告： 可编程性和可扩展性的分布式虚拟参与者 Orleans文件 Orleans的起源 Orleans创建于 微软研究并设计用于云计算 . 自2011年以来，它已被多家微软产品集团广泛应用于云计算和内部部署，其中最著名的是游戏工作室，如343 Industries和联盟作为Halo 4和5、Gears of War 4背后的云服务平台，以及其他一些。 自2011年以来，它已被多个Microsoft产品组广泛用于云中和内部，尤其是游戏工作室（例如343 Industries和The Coalition）作为Halo 4和5，Gears of War 4之后的云服务平台， 也被许多其他公司采用。 Orleans于2015年1月开放源码，吸引了许多开发商成立 是.NET生态系统中最具活力的开源社区之一 . 在开发人员社区和微软Orleans团队的积极合作中，每天都会添加和改进特性。 在开发者社区和Orleans团队微软公司的积极协作下，每天都增加和改进各种功能。 微软研究院继续与Orleans团队合作，推出新的主要功能，如 地理分布 , 索引 ，和 分布式事务 ，推动了最新技术的发展。 对于许多.NET开发人员来说，Orleans已经成为构建分布式系统和云服务的首选框架。"
  },
  "docs/migration/codegen.html": {
    "href": "docs/migration/codegen.html",
    "title": "Code Generation in Orleans 2.0 | Microsoft Orleans Documentation",
    "keywords": "Code Generation in Orleans 2.0 Code generation has been improved in Orleans 2.0, improving startup times and providing a more deterministic, debuggable experience. As with earlier versions, Orleans provides both build-time and run-time code generation. During Build - This is the recommended option and only supports C# projects. In this mode, code generation will run every time your project is compiled. A build task is injected into your project's build pipeline and the code is generated in the project's intermediate output directory. To activate this mode, add one of the packages Microsoft.Orleans.CodeGenerator.MSBuild or Microsoft.Orleans.OrleansCodeGenerator.Build to all projects which contain Grains, Grain interfaces, serializers, or types which require serializers. Differences between the packages and additional codegen information could be found in the corresponding Code Generation section. Additional diagnostics can be emitted at build-time by specifying value for OrleansCodeGenLogLevel in the target project's csproj file. For example, <OrleansCodeGenLogLevel>Trace</OrleansCodeGenLogLevel> . During Configuration - This is the only supported option for F#, Visual Basic, and other non-C# projects. This mode generates code during the configuration phase. To access this, see the Configuration documentation. Both modes generate the same code, however run-time code generation can only generate code for publicly accessible types."
  },
  "docs/migration/index.html": {
    "href": "docs/migration/index.html",
    "title": "Migration | Microsoft Orleans Documentation",
    "keywords": "Orleans 2.0 2.0 is a major release of Orleans with the main goal of making it .NET Standard 2.0 compatible and cross-platform (via .NET Core). As part of that effort, several modernizations of Orleans APIs were made to make it more aligned with how technologies like ASP.NET are configured and hosted today. Because it is compatible with .NET Standard 2.0, Orleans 2.0 can be used by applications targeting .NET Core or full .NET Framework. The emphasis of testing by the Core team for this release is on full .NET Framework to ensure that existing applications can easily migrate from 1.5 to 2.0, and with full backward compatibility. The most significant changes in 3.0 are as follows: Completely moved to programmatic configuration leveraging Dependency Injection with a fluid builder pattern API. The old API based on configuration objects and XML files is preserved for backward compatibility, but will not move forward and will get deprecated in the future. See more details in the Configuration section. Explicit programmatic specification of application assemblies that replaces automatic scanning of folders by the Orleans runtime upon silo or client initialization. Orleans will still automatically find relevant types, such as grain interfaces and classes, serializers, etc. in the specified assemblies, but it will no longer try to load every assembly it can find in the folder. An optional helper method for loading all assemblies in the folder is provided for backward compatibility: IApplicationPartManager.AddFromApplicationBaseDirectory() . See Configuration and Migration sections for more details. Overhaul of code generation. While mostly invisible for the developer, code generation became much more robust in handling serialization of various possible types. Special handling is required for F# assemblies. See the Code generation section for more details. Created a Microsoft.Orleans.Core.Abstractions NuGet package and moved/refactored several types into it. Grain code would most likely need to reference only these abstractions, whereas the silo host and client will reference more of the Orleans packages. We plan to update this package less frequently. Add support for Scoped services. This means that each grain activation gets its own scoped service provider, and Orleans registers a contextual IGrainActivationContext object that can be injected into a Transient or Scoped service to get access to activation specific information and grain activation lifecycle events. This is similar to how ASP.NET Core 2.0 creates a scoped context for each Request, but in the case of Orleans, it applies to the entire lifetime of a grain activation. See Service Lifetimes and Registration Options in the ASP.NET Core documentation for more information about service lifetimes. Migrated the logging infrastructure to use Microsoft.Extensions.Logging (same abstractions as ASP.NET Core 2.0). 2.0 includes a beta version of support for ACID distributed cross-grain transactions. The functionality will be ready for prototyping and development, and will graduate for production use sometime after the 2.0 release. See Transactions for more details."
  },
  "docs/migration/migration-1.5.html": {
    "href": "docs/migration/migration-1.5.html",
    "title": "Migration from Orleans 1.5 to 2.0 | Microsoft Orleans Documentation",
    "keywords": "Migration from Orleans 1.5 to 2.0 The bulk of the Orleans APIs stayed unchanged in 2.0 or implementation of those APIs were left in legacy classes for backward compatibility. At the same time, the newly introduced APIs provide some new capabilities or better ways of accomplishing those tasks. There are also more subtle differences when it comes to .NET SDK tooling and Visual Studio support that helps to be aware of. This document provides guidance for migrating application code from to Orleans 2.0. Visual Studio and Tooling requirements Orleans 2.0.0 is built on top of .NET Standard 2.0. Because of that, you need to upgrade development tools to ensure yourself a pleasant developing experience. We recommend to use Visual Studio 2017 or above to develop Orleans 2.0.0 applications. Based on our experience, version 15.5.2 and above works best. .NET Standard 2.0.0 is compatible with .NET 4.6.1 and above, .NET Core 2.0, and a list of other frameworks. Orleans 2.0.0 inherited that compatibility. For more information on .NET Standard compatibility with other framework, please refer to .NET Standard documentation : If you are developing a .NET Core or .NET application using Orleans, you will need to follow certain steps to set up your environment, such as installing .NET Core SDK. For more information, please refer to their documentation . Available options for configuration code Hosting Configuring and Starting a Silo (using the new SiloBuilder API and legacy ClusterConfiguration object) There's a number of new option classes in Orleans 2.0 that provide a new way for configuring a silo. To ease migration to the new API, there is a optional backward compatibility package, Microsoft.Orleans.Runtime.Legacy , that provides a bridge from the old 1.x configuration API to the new one. If you add Microsoft.Orleans.Runtime.Legacy package, a silo can still be configured programmatically via the legacy ClusterConfiguration object that can then be passed to SiloHostBuilder to build and start a silo. You still need to specify grain class assemblies via the ConfigureApplicationParts call. Here is an example of how a local silo can be configured in the legacy way: public class Program { public static async Task Main(string[] args) { try { var host = await StartSilo(); Console.WriteLine(\"Press Enter to terminate...\"); Console.ReadLine(); await host.StopAsync(); return 0; } catch (Exception ex) { Console.WriteLine(ex); return 1; } } private static async Task<ISiloHost> StartSilo() { // define the cluster configuration (temporarily required in the beta version, // will not be required by the final release) var config = ClusterConfiguration.LocalhostPrimarySilo(); // add providers to the legacy configuration object. config.AddMemoryStorageProvider(); var builder = new SiloHostBuilder() .UseConfiguration(config) // Add assemblies to scan for grains and serializers. // For more info read the Application Parts section .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(HelloGrain).Assembly) .WithReferences()) // Configure logging with any logging framework that supports Microsoft.Extensions.Logging. // In this particular case it logs using the Microsoft.Extensions.Logging.Console package. .ConfigureLogging(logging => logging.AddConsole()); var host = builder.Build(); await host.StartAsync(); return host; } } Configuring and Connecting a Client (using the new ClientBuilder API and legacy ClientConfiguration object) There's a number of new option classes in Orleans 2.0 that provide a new way for configuring a client. To ease migration to the new API, there is a optional backward compatibility package, Microsoft.Orleans.Core.Legacy , that provides a bridge from the old 1.x configuration API to the new one. If you added Microsoft.Orleans.Core.Legacy package, a client can still be configured programmatically via the legacy ClientConfiguration object that can then be passed to ClientBuilder to build and connect the client. You still need to specify grain interface assemblies via the ConfigureApplicationParts call. Here is an example of how a client can connect to a local silo, using legacy configuration: // define the client configuration (temporarily required in the beta version, // will not be required by the final release) var config = ClientConfiguration.LocalhostSilo(); var builder = new ClientBuilder() .UseConfiguration(config) // Add assemblies to scan for grains interfaces and serializers. // For more info read the Application Parts section .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(IHello).Assembly)) .ConfigureLogging(logging => logging.AddConsole()) var client = builder.Build(); await client.Connect(); Logging Orleans 2.0 uses the same logging abstractions as ASP.NET Core 2.0. You can find replacement for most Orleans logging feature in ASP.NET Core logging. Orleans specific logging feature, such as ILogConsumer and message bulking, is still maintained in Microsoft.Orleans.Logging.Legacy package, so that you still have the option to use them. But how to configure your logging with Orleans changed in 2.0. Let me walk you through the process of migration. In 1.5, logging configuration is done through ClientConfiguration and NodeConfiguration . You can configure DefaultTraceLevel , TraceFileName , TraceFilePattern , TraceLevelOverrides , TraceToConsole , BulkMessageLimit , LogConsumers , etc through it. In 2.0, logging configuration is consistent with ASP.NET Core 2.0 logging, which means most of the configuration is done through Microsoft.Extensions.Logging.ILoggingBuilder . To configure DefaultTraceLevel and TraceLevelOverrides , you need to apply log filtering to ILoggingBuilder . For example, to set trace level to 'Debug' on orleans runtime, you can use sample below, siloBuilder.AddLogging(builder=>builder.AddFilter(\"Orleans\", LogLevel.Debug)); You can configure log level for you application code in the same way. If you want to set a default minimum trace level to be Debug, use sample below siloBuilder.AddLogging(builder=>builder.SetMinimumLevel(LogLevel.Debug); For more information on log filtering, please see their docs on https://docs.microsoft.com/en-us/aspnet/core/fundamentals/logging ; To configure TraceToConsole to be true , you need to reference Microsoft.Extensions.Logging.Console package and then use AddConsole() extension method on ILoggingBuilder . The same with TraceFileName and TraceFilePattern , if you want to log messages to a file, you need to use AddFile(\"file name\") method on ILoggingBuilder . If you still want to use Message Bulking feature, You need to configure it through ILoggingBuilder as well. Message bulking feature lives in Microsoft.Orleans.Logging.Legacy package. So you need to add dependency on that package first. And then configure it through ILoggingBuilder . Below is an example on how to configure it with ISiloHostBuilder siloBuiler.AddLogging(builder => builder.AddMessageBulkingLoggerProvider(new FileLoggerProvider(\"mylog.log\"))); This method would apply message bulking feature to the FileLoggerProvider , with default bulking config. Since we are going to eventually deprecate and remove LogConsumer feature support in the future, we highly encourage you to migrate off this feature as soon as possible. There's couple approaches you can take to migrate off. One option is to maintain your own ILoggerProvider , which creates ILogger who logs to all your existing log consumers. This is very similar to what we are doing in Microsoft.Orleans.Logging.Legacy package. You can take a look at LegacyOrleansLoggerProvider and borrow logic from it. Another option is replace your ILogConsumer with existing implementation of ILoggerProvider on nuget which provides identical or similar functionality, or implement your own ILoggerProvider which fits your specfic logging requirement. And configure those ILoggerProvider s with ILoggingBuilder . But if you cannot migrate off log consumer in the short term, you can still use it. The support for ILogConsumer lives in Microsoft.Orleans.Logging.Legacy package. So you need to add dependency on that package first, and then configure Log consumers through extension method AddLegacyOrleansLogging on ILoggingBuilder . There's native AddLogging method on IServiceCollection provided by ASP.NET for you to configure ILoggingBuilder . We also wrap that method under extension method on ISiloHostBuilder and IClientBuilder . So you can call AddLogging method on silo builder and client builder as well to configure ILoggingBuilder . below is an example: var severityOverrides = new OrleansLoggerSeverityOverrides(); severityOverrides.LoggerSeverityOverrides.Add(typeof(MyType).FullName, Severity.Warning); siloBuilder.AddLogging(builder => builder.AddLegacyOrleansLogging(new List<ILogConsumer>() { new LegacyFileLogConsumer($\"{this.GetType().Name}.log\") }, severityOverrides)); You can use this feature if you invested in custom implementation of ILogConsumer and cannot convert them to implementation of ILoggerProvider in the short term. Logger GetLogger(string loggerName) method on Grain base class and IProviderRuntime , and Logger Log { get; } method on IStorageProvider are still maintained as a deprecated feature in 2.0. You can still use it in your process of migrating off orleans legacy logging. But we recommend you to migrate off them as soon as possible. Provider Configuration In Orleans 2.0, configuration of the included providers has been standardized to obtain Service ID and Cluster ID from the ClusterOptions configured for the silo or client. Service ID is a stable identifier of the service or application that the cluster represents. Service ID does not change between deployments and upgrades of clusters that implement the service over time. Unlike Service ID, Cluster ID stays the same only through the lifecycle of a cluster of silos. If a running cluster gets shut down, and a new cluster for the same service gets deployed, the new cluster will have a new and unique Cluster ID, but will maintain the Service ID of the old cluster. Service ID is often used as part of a key for persisting data that needs to have continuity throughout the life of the service. Examples are grain state, reminders, and queues of persistent streams. On the other hand, data within a cluster membership table only makes sense within the scope of its cluster, and hence is normally keyed off Cluster ID. Prior to 2.0, behavior of Orleans providers was sometimes inconsistent with regards to using Service ID and Cluster ID (that was also previously called Deployment ID). Because of this unifications and the overall change of provider configuration API, data written to storage by some providers may change location or key. An example of a provider that is sensitive to this change is Azure Queue stream provider. If you are migrating an existing service from 1.x to 2.0, and need to maintain backward compatibility with regards to location or keys of data persisted by the providers you are using in the service, please verify that the data will be where your service or provider expects it to be. If your service happen to depend on the incorrect usage of Service ID and Cluster ID by a 1.x provider, you can override ClusterOptions for that specific provider by calling ISiloHostBuilder.AddProviderClusterOptions() or IClientBuilder.AddProviderClusterOptions() and force it to read/write data from/to the 1.x location in storage"
  },
  "docs/migration/migration-azure-2.0.html": {
    "href": "docs/migration/migration-azure-2.0.html",
    "title": "Migration from Orleans 1.5 to 2.0 when using Azure | Microsoft Orleans Documentation",
    "keywords": "Migration from Orleans 1.5 to 2.0 when using Azure In Orleans 2.0, the configuration of silos and clients has changed. In Orleans 1.5 we used to have a monolith object that handled all the configuration pieces Providers were added to that configuration object, too. In Orleans 2.0, the configuration process is organizes around SiloHostBuilder , similar to how it is done in ASP.NET Core with the WebHostBuilder . In Orleans 1.5, the configuration for Azure looked like this: var config = AzureSilo.DefaultConfiguration(); config.AddMemoryStorageProvider(); config.AddAzureTableStorageProvider(\"AzureStore\", RoleEnvironment.GetConfigurationSettingValue(\"DataConnectionString\")); The AzureSilo class exposes a static method named DefaultConfiguration() that was used for loading configuration XML file. This way of configuring a silo is deprecated but still supported via the legacy support package . In Orleans 2.0, configuration is completely programmatic. The new configuration API looks like this: //Load the different settings from the services configuration var proxyPort = RoleEnvironment.CurrentRoleInstance.InstanceEndpoints[\"OrleansProxyEndpoint\"].IPEndpoint.Port; var siloEndpoint = RoleEnvironment.CurrentRoleInstance.InstanceEndpoints[\"OrleansSiloEndpoint\"].IPEndpoint; var connectionString = RoleEnvironment.GetConfigurationSettingValue(\"DataConnectionString\"); var deploymentId = RoleEnvironment.DeploymentId; var builder = new SiloHostBuilder() //Set service ID and cluster ID .Configure<ClusterOptions>(options => { options.ClusterId = deploymentId; options.ServiceIs = \"my-app\"; }) // Set silo name .Configure<SiloOptions>(options => options.SiloName = this.Name) //Then, we can configure the different endpoints .ConfigureEndpoints(siloEndpoint.Address, siloEndpoint.Port, proxyPort) //Then, we set the connection string for the storage .UseAzureStorageClustering(options => options.ConnectionString = connectionString) //If reminders are needed, add the service, the connection string is required .UseAzureTableReminderService(connectionString) //If Queues are needed, add the service, set the name and the Adapter, the one shown here //is the one provided with Orleans, but it can be a custom one .AddAzureQueueStreams<AzureQueueDataAdapterV2>(\"StreamProvider\", configurator => configurator.Configure(configure => { configure.ConnectionString = connectionString; })) //If Grain Storage is needed, add the service and set the name .AddAzureTableGrainStorage(\"AzureTableStore\"); AzureSilo to ISiloHost In Orleans 1.5, the AzureSilo class was the recommended way to host a silo in an Azure Worker Role. This is still supported via the Microsoft.Orleans.Hosting.AzureCloudServices NuGet package . public class WorkerRole : RoleEntryPoint { AzureSilo silo; public override bool OnStart() { // Do other silo initialization – for example: Azure diagnostics, etc return base.OnStart(); } public override void OnStop() { silo.Stop(); base.OnStop(); } public override void Run() { var config = AzureSilo.DefaultConfiguration(); config.AddMemoryStorageProvider(); config.AddAzureTableStorageProvider(\"AzureStore\", RoleEnvironment.GetConfigurationSettingValue(\"DataConnectionString\")); // Configure storage providers silo = new AzureSilo(); bool ok = silo.Start(config); silo.Run(); // Call will block until silo is shutdown } } Orleans 2.0 provides a more flexible and modular API for configuring and hosting a silo via SiloHostBuilder and ISiloHost . public class WorkerRole : RoleEntryPoint { private ISiloHost host; private ISiloHostBuilder builder; private readonly CancellationTokenSource cancellationTokenSource = new CancellationTokenSource(); private readonly ManualResetEvent runCompleteEvent = new ManualResetEvent(false); public override void Run() { try { this.RunAsync(this.cancellationTokenSource.Token).Wait(); runCompleteEvent.WaitOne(); } finally { this.runCompleteEvent.Set(); } } public override bool OnStart() { //builder is the SiloHostBuilder from the first section // Build silo host, so that any errors will restart the role instance this.host = this.builder.Build(); return base.OnStart(); } public override void OnStop() { this.cancellationTokenSource.Cancel(); this.runCompleteEvent.WaitOne(); this.host.StopAsync().Wait(); base.OnStop(); } private Task RunAsync(CancellationToken cancellationToken) { return this.host.StartAsync(cancellationToken); } }"
  },
  "docs/resources/best_practices.html": {
    "href": "docs/resources/best_practices.html",
    "title": "Best Practices | Microsoft Orleans Documentation",
    "keywords": "Best Practices Orleans was built with the goal to greatly simplify building of distributed scalable applications, especially for the cloud. Orleans invented the Virtual Actor Model as an evolution of the Actor Model optimized for the cloud scenarios. Grains (virtual actors) are the base building blocks of an Orleans-based application. They encapsulate state and behavior of application entities and maintain their lifecycle. The programming model of Orleans and the characteristics of its runtime fit some types of applications better than others. This document is intended to capture some of the tried and proven application patterns that work well in Orleans. Orleans should be considered when: Significant number (hundreds, millions, billions, and even trillions) of loosely coupled entities. To put the number in perspective, Orleans can easily create a grain for every person on Earth in a small cluster, so long as a subset of that total number is active at any point in time. Examples: user profiles, purchase orders, application/game sessions, stocks Entities are small enough to be single-threaded Example: Determine if stock should be purchased based on current price Workload is interactive Example: request-response, start/monitor/complete More than one server is expected or may be required Orleans runs on a cluster which is expanded by adding servers to expand the cluster Global coordination is not needed or on a smaller scale between a few entities at a time Scalability and performance of execution is achieved by parallelizing and distributed a large number of mostly independent tasks with no single point of synchronization. Orleans is not the best fit when: Memory must be shared between entities Each grain maintains its own states and should not be shared. A small number of large entities that may be multithreaded A microservice may be a better option when supporting complex logic in a single service Global coordination and/or consistency is needed Such global coordination would severely limit performance of an Orleans-based application. Orleans was built to easily scale to a global scale without the need of in-depth manual coordination. Operations that run for a long time Batch jobs, Single Instruction Multiple Data (SIMD) tasks This depends on the need of the application and may be a fit for Orleans Grains Overview : Grains resemble objects. However, they are distributed, virtual, and asynchronous. They are loosely coupled, isolated, and primarily independent Each grain is encapsulated which also maintains its own state independently of other grains Grains fail independently Avoid chatty communication between grains Direct memory use is significantly less expensive than message passing Highly chatty grains may be better combined as a single grain Complexity/Size of arguments and serialization need to be considered Deserializing twice may be more expensive than resending a binary message Avoid bottleneck grains Single coordinator/Registry/Monitor Do staged aggregation if required Asynchronicity : No thread blocking: All items must be Async (Task Asynchronous Programming (TAP)) await is the best syntax to use when composing async operations Common Scenarios: Return a concrete value: return Task.FromResult(value); Return a Task of the same type: return foo.Bar(); Await a Task and continue execution: var x = await bar.Foo(); var y = DoSomething(x); return y; Fan-out: var tasks = new List<Task>(); foreach(var grain in grains) { tasks.Add(grain.Foo()) } await Task.WhenAll(tasks); DoMoreWork(); Implementation of Grains : Never perform a thread-blocking operation within a grain. All operations other than local computations must be explicitly asynchronous. Examples: Synchronously waiting for an IO operation or a web service call, locking, running an excessive loop that is waiting for a condition, etc. When to use a [StatelessWorker] Functional operations such as: decryption, decompression, and before forwarding for processing When only local grains are required in multiple activations Example: Performs well with staged aggregation within local silo first Grains are non-reentrant by default Deadlock can occur due to call cycles Examples: The grain calls itself Grains A calls B while C is also calling A (A->B->C->A) Grain A calls Grain B as Grain B is calling Grain A (A->B->A) Timeouts are used to automatically break deadlocks Attribute [Reentrant] can be used to allow the grain class reentrant Reentrant is still single-threaded however, it may interleave (divide processing/memory between tasks) Handling interleaving increases risk by being error prone Inheritance Grain classes inherit from the Grain base class. Grain intrerfaces (one or more) can be added to each grain. Disambiguation may be needed to implement the same interface in multiple grain classes Generics are supported Grain State Persistence Orleans’ grain state persistence APIs are designed to be easy-to-use and provide extensible storage functionality. Tutorial: Needs to be created Overview : Orleans.IGrainState is extended by a .NET interface which contains fields that should be included in the grain’s persisted state. Grains are persisted by using IPersistentState<TState> is extended by the grain class that adds a strongly typed State property into the grain’s base class. The initial State.ReadStateAsync() automatically occurs prior to ActiveAsync() has been called for a grain. When the grain’s state object’s data is changed, then the grain should call State.WriteStateAsync() Typically, grains call State.WriteStateAsync() at the end of grain method to return the Write promise. The Storage provider could try to batch Writes that may increase efficiency, but behavioral contract and configurations are orthogonal (independent) to the storage API used by the grain. A timer is an alternative method to write updates periodically. The timer allows the application to determine the amount of “eventual consistency”/statelessness allowed. Timing (immediate/none/minutes) can also be controlled as to when to update. PersistetState classes, like other grain classes, can only be associated with one storage provider. [StorageProvider(ProviderName=”name”)] attribute associates the grain class with a particular provider <StorageProvider> will need to be added to the Silo config file which should also include the corresponding “name” from [StorageProvider(ProviderName=”name”)] A composite storage provider can be used with SharedStorageProvider Storage Providers Built-in Storage Providers Orleans.Storage houses all of the built-in storage providers. The namespace is: OrleansProviders.dll MemoryStorage (Data stored in memory without durable persistence) is used only for debugging and unit testing. AzureTableStorage Configure the Azure storage account information with an optional DeleteStateOnClear (hard or soft deletions) Orleans serializer efficiently stores JSON data in one Azure table cell Data size limit == max size of the Azure column which is 64kb of binary data Community contributed code that extends the use of multiple table columns which increases the overall maximum size to 1mb. Storage Provider Debugging Tips TraceOverride Verbose3 will log much more information about storage operations. Update silo config file LogPrefix=”Storage” for all providers, or specific type using “Storage.Memory” / ”Storage.Azure” / “Storage.Shard” How to deal with Storage Operation Failures Grains and storage providers can await storage operations and retry failures as needed Unhandled failures will propagate back to the caller and will be seen by the client as a broken promise Other than the initial read, there is not a concept that automatically destroys activations if a storage operation fails Retrying a failing storage is not a default feature for built-in storage providers Grain Persistence Tips Grain Size Optimal throughput is achieved by using multiple smaller grains rather than a few larger grains. However, the best practice of choosing a grain size and type is base on the application domain model . Example: Users, Orders, etc. External Changing Data Grain are able to re-read the current state data from storage by using State.ReadStateAsyc() A timer can also be used to re-read data from storage periodically as well The functional requirements could be based on a suitable “staleness” of the information Example: Content Cache Grain Adding and Removing Fields The storage provider will determine the effects of adding and removing additional fields from its persisted state. Azure table does not support schemas and should automatically adjust to the additional fields. Writing Custom Providers Storage providers are simple to write which is also a significant extension element for Orleans Tutorial: need tutorial The API GrainState API contract drives the storage API contract (Write, Clear, ReadStateAsync()) The storage behavior is typically configurable (Batch writing, Hard or Soft Deletions, etc.) and defined by the storage provider Cluster Management Orleans automatically manages clusters Failed nodes --that is that can fail and join at any moment-- are automatically handled by Orleans The same silo instance table that is created for the clustering protocol can also be used for diagnostics. The table keeps a history of all of the silos in the cluster. There are also configuration options of an aggressive or a more lenient failure detection Failures can happen at any time and are a normal occurrence In the event a silo fails, the grains that were activated on the failed silo will automatically be reactived later on other silos within the cluster. Grains have an ability to timeout. A retry solution such as Polly can assist with retries. Orleans provides a message delivery guaruntee where each message is delivered at-most-once. It is a responsibility of the caller to retry any failed calls if needed. Common practice is to retry from end-to-end from the client/front end Deployment and Production Management Scaling out and in Monitor the Service-Level Agreement (SLA) Add or Remove instances Orleans automatically rebalances and takes advantage of the new hardware. However, activated grains are not rebalanced when a new silo is added to the cluster. Logging and Testing Logging, Tracing, and Monitoring Inject logging Dependency injection public HelloGrain(ILogger<HelloGrain> logger) {this.logger = logger;} Microsoft.Extensions.Logging is utilized for functional and flexible logging Testing Microsoft.Orleans.TestingHost NuGet package contains TestCluster which can be used to create an in-memory cluster, comprised of two silos by default, which can be used to test grains. Additional information can be found here Troubleshooting Use Azure table-based membership for development and testing Works with Azure Storage Emulator for local troubleshooting OrleansSiloInstances table displays the state of the cluster Use unique deployment Ids (partition keys) in order to keep it simple Silo isn’t starting Check OrleansSiloInstances to determine if the silo registered there. Make sure that firewall is open for TCP ports: 11111 and 30000 Check the logs, including the extra log that contains startup errors Frontend (Client) cannot connect to the silo cluster The client must be hosted in the same service as the silos Check OrleansSiloInstances to make sure the silos (gateways) are registered Check the client log to make sure that the gateways match the ones listed in the OrleansSiloInstances’ table Check the client log to validate that the client was able to connect to one or more of the gateways"
  },
  "docs/resources/contributing.html": {
    "href": "docs/resources/contributing.html",
    "title": "Contributing to Orleans | Microsoft Orleans Documentation",
    "keywords": "Contributing to Orleans Some notes and guidelines for developers who want to contribute to Orleans. Contributing To This Project Here are some pointers for anyone looking for mini-features and work items that would make a positive contribution to Orleans. These are just a few ideas, so if you think of something else that would be useful, then spin up a discussion thread on GitHub to discuss the proposal, and go for it! Orleans GitHub Repository Pull requests are always welcome! Intern and Student Projects Some suggestions for possible intern / student projects. Documentation Guidelines A style guide for writing documentation for this site. Code Contributions This project uses the same contribution process as the other DotNet projects on GitHub. DotNet Project Contribution Guidelines Guidelines and workflow for contributing to DotNet projects on GitHub. DotNet CLA Contribution License Agreement for DotNet projects on GitHub. .NET Framework Design Guidelines Some basic API design rules, coding standards, and style guide for .NET Framework APIs. Coding Standards and Conventions We try not to be too OCD about coding style wars, but in case of disputes we do fall back to the core principles in the two \".NET Coding Standards\" books used by the other DotNet OSS projects on GitHub: C# Coding Style Guide .NET Framework Design Guidelines There are lots of other useful documents on the .NET CoreCLR and .NET Core Framework documentation sites which are worth reading, although most experienced C# developers will probably have picked up many of those best-practices by osmosis, particularly around performance and memory management. Source Code Organization Orleans has not religiously followed a \"One Class Per File\" rule, but instead we have tried to use pragmatic judgment to maximize the change of \"code understand-ability\" for developers on the team. If lots of small-ish classes share a \"common theme\" and/or are always dealt with together, then it is OK to place those into one source code file in most cases. See for example the various \"log consumer\" classes were originally placed in single source file, as they represented a single unit of code comprehension. As a corollary, it is much easier to find the source code for a class if it is in a file with the same name as the class [similar to Java file naming rules], so there is a tension and value judgment here between code find-ability and minimizing / constraining the number of projects in a solution and files within a project [which both have direct impact on the Visual Studio \"Opening\" and \"Building\" times for large projects]. Code search tools in VS and ReSharper definitely help here. Dependencies and Inter-Project References One topic that we are very strict about is around dependency references between components and sub-systems. Component / Project References References between projects in a solution must always use \" Project References \" rather than \" DLL References \" to ensure that component build relationships are known to the build tools. Right : <ProjectReference Include=\"..\\Orleans\\Orleans.csproj\"> <Project>{BC1BD60C-E7D8-4452-A21C-290AEC8E2E74}</Project> <Name>Orleans</Name> </ProjectReference> Wrong : <Reference Include=\"Orleans\" > <HintPath>..\\Orleans\\bin\\Debug\\Orleans.dll</HintPath> </Reference> In order to help ensure we keep inter-project references clean, then on the build servers [and local Build.cmd script] we deliberately use side-by-side input .\\src and output .\\Binaries directories rather than the more normal in-place build directory structure (eg. [PROJ]\\bin\\Release ) used by VS on local dev machines. Unified Component Versions We use the same unified versions of external component throughout the Orleans code base, and so should never need to add bindingRedirect entries in App.config files. Also, in general it should almost never be necessary to have Private=True elements in Orleans project files, except to override a conflict with a Windows / VS \"system\" component. Some package management tools can occasionally get confused when making version changes, and sometimes think that we are using multiple versions of the same assembly within a solution, which of course we never do. We long for the day when package management tools for .NET can make version changes transactionally! Until then, it is occasionally necessary to \"fix\" the misguided actions of some .NET package management tools by hand-editing the .csproj files (they are just XML text files) back to sanity and/or using the \"Discard Edited Line\" functions that most good Git tools such as Atlassian SourceTree provide. Using \"sort\" references and unified component versions avoids creating brittle links between Orleans run-time and/or external components, and has proved highly effective in the last several years at reducing stress levels for the Orleans Team during important deployment milestones. :)"
  },
  "docs/resources/documentation_guidelines.html": {
    "href": "docs/resources/documentation_guidelines.html",
    "title": "Documentation Guidelines | Microsoft Orleans Documentation",
    "keywords": "Documentation Guidelines The Orleans documentation is built in Markdown . We use a few simple conventions to ensure a homogeneous style throughout the full set of documents. These standards are being introduced. If you have issues with these guidelines then raise an issue or a Pull Request. If you find documentation that fails to meet the guidelines, then make a fix and submit a pull request. Also if you are using windows 10 you can go to the store and find free MarkDown editors like this Structure Language The documentation will follow US-English spelling. Desktop tools like http://markdownpad.com and Visual Studio Code have spell checking features. Paragraph structure Each sentence should be written on a single line, and only one sentence per line. This makes merging changes easier and helps identify verbose language. Paragraphs in Markdown are just one or more lines of consecutive text followed by one or more blank lines. Headings Headings should be used to structure a document. Avoid using other emphasis features like ALLCAPS, Italics or bold to identify a new topic. Using a header is not only more consistent, but also allows linking to the header. Footers At the end of a page, it is helpful to link to the next logical page in the documentation. If the page is the last in a sub-section, then linking back to the index page is useful. Styles Code formatting Blocks of example code should be formatted with the triple back tick format followed by the language. [StorageProvider(ProviderName=\"store1\")] public class MyGrain<IMyGrainState> { ... } Which will render as [StorageProvider(ProviderName=\"store1\")] public class MyGrain<IMyGrainState> ... { ... } Inline code should be marked with a single backtick (`). This include references to: type names e.g. Task<T> variable names e.g. game namespaces e.g. Orleans.Storage.AzureTableStorage If showing text that is an output (e.g. text file content or console output) you can either use the triple back tick without specifying a language or you can indent the content. For example: 1 said: Welcome to my team! 0 said: Thanks! 1 said: Thanks! 0 said: Thanks! File names and paths When referencing a filename, directory/folder or URI then use standard italics to format. This can be done by surrounding the string with either with a single asterisk ( * ) or a single underscore ( _ ) Examples: OrleansRuntimeInterfaces.dll C:\\Binaries ../src/Grain.cs Tables Markdown supports tabular data . Tables could be used to structure data so that is is easily consumable for the reader. Suffix Unit ms millisecond(s) s second(s) m minute(s) Links When referencing another concept, provide a link to that concept. Forward and backward references within a page can be linked via the header. e.g. link back to Structure Links to other documents can either link to the page or to a sub-section/header within the page. External links should be exposed as the full link. e.g. https://github.com/dotnet/roslyn Contribution The Orleans documentation is managed as Markdown files in a Git repository hosted on GitHub in the gh-pages branch . See the GitHub Pages documentation on how to use the gh-pages branch convention for \"Project site\" documents."
  },
  "docs/resources/frequently_asked_questions.html": {
    "href": "docs/resources/frequently_asked_questions.html",
    "title": "Frequently Asked Questions | Microsoft Orleans Documentation",
    "keywords": "Frequently Asked Questions Availability Can I freely use Orleans in my project? Absolutely. The source code has been released under the MIT license . NuGet packages are published on nuget.org . Is Orleans production ready? I heard it's a research project. Orleans, indeed, initially started as a research project within Microsoft Research. It later grew into a product and has been used in production within Microsoft since 2011, and by other companies after it was publicly released in 2015. Orleans is definitely production ready, and powers many highly available systems and cloud services. Does Microsoft support Orleans? Source code of Orleans has been released under an MIT license on GitHub . Microsoft continues to invest in Orleans and accepts community contributions to the codebase. Positioning Is Orleans a server product? How do I run Orleans? Orleans is a framework, a set of libraries, that helps you build an application. Orleans-based applications can be run in various hosting environments, in the Cloud or on on-premises clusters or even on a single machine. It is the responsibility of application developer to build, deploy, and run an Orleans-based application in their target hosting environment. Where can I run Orleans? Orleans can run in any environment where .NET application can run. Prior to Orleans 2.0, it required full .NET Framework. Starting with 2.0, Orleans conforms to .NET Standard 2.0, and hence can run on .NET Core in Windows and non-Windows environments that support .NET Core. Is Orleans built for Azure? No. We believe that you should be able to run Orleans anywhere you need, the way you need. Orleans is very flexible, and has a number of optional providers that help host it in cloud environment, such as Azure, AWS or GCP, or on on-premises clusters, with a choice of technologies to support Orleans' clustering protocol. What is the difference between Orleans and other actor languages and frameworks, such as Erlang or Akka? While based on the same base principles of the Actor Model, Orleans took a step forward, and introduced a notion of Virtual Actors that greatly simplifies developer's experience and is much more suitable for cloud services and high-scale systems. Design How big or how small should a grain be in my application? The grain isolation model makes them very good at representing independent isolated contexts of state and computation. In most cases, grains naturally map to such application entities as users, sessions, accounts. Those entities are generally isolated from each other, can be accessed and updated independently, and expose a well defined set of supported operations. This works well with the intuitive \"one entity - one grain\" modeling. An application entity may be too big to be efficiently represented by a single grain if it encapsulates too much state, and as a result has to handle a high rate of requests to it. Even though a single grain can generally handle up to a few thousand trivial calls per second, the rule of thumb is to be wary of individual grain receiving hundreds of requests per second. That may be a sign of the grain being too large, and decomposing it into a set of smaller grains may lead to a more stable and balanced system. An application entity may be too small to be a grain if that would cause constant interaction of other grains with it, and as a result, cause too much of a messaging overhead. In such cases, it may make more sense to make those closely interacting entities part of a single grain, so that they would invoke each other directly. How should you avoid grain hot spots? The throughput of a grain is limited by a single thread that its activation can execute on. Therefore, it is advisable to avoid designs where a single grain receives a disproportionate share of requests or is involved in processing requests to other grains. There are various patterns that help prevent overloading of a single grain even when logically it is a central point of communication. For example, if a grain is an aggregator of some counters or statistics that are reported by a large number of grains on a regular basis, one proven approach is to add a controlled number of intermediate aggregator grains and assign each of the reporting grains (using a modulo on a key or a hash) to an intermediate aggregator, so that the load is more or less evenly distributed across all intermediate aggregator grains that in their turn periodically report partial aggregates to the central aggregator grain. How To How do I tear down a grain? In general there is no need for application logic to force deactivation of a grain, as the Orleans runtime automatically detects and deactivates idle activations of a grain to reclaim system resources. Letting Orleans do that is more efficient because it batches deactivation operations instead of executing them one by one. In the rare cases when you think you do need to expedite deactivation of a grain, the grain can do that by calling the base.DeactivateOnIdle() method. Can I tell Orleans where to activate a grain? It is possible to do so using restrictive placement strategies, but we generally consider this a rather advanced pattern that requires careful consideration. By doing what the question suggests, the application would take on the burden of resource management without necessarily having enough information about the global state of the system to do so well. This is especially counter-productive in cases of silo restarts, which in cloud environments may happen on a regular basis for OS patching. Thus, specific placement may have a negative impact on your application's scalability as well as resilience to system failure. That being said, for the rare cases where the application indeed knows where a particular grain should be activated, for example, if it has a knowledge of the locality of grain's persistent state, in 1.5.0 we introduced custom placement policies and directors. How do you version grains or add new grain classes and interfaces? You can add silos with new grain classes or new versions of existing grain classes to a running cluster. Can I Connect to Orleans silos from the public Internet? Orleans is designed to be hosted as the back-end part of a service, and you are expected to create a front-end tier to which external clients will connect. It can be an HTTP based Web API project, a socket server, a SignalR server or anything else fits the needs of the application. You can connect to Orleans from the Internet if you expose TCP endpoints of silos to it, but it is not a good practice from the security point of view. What happens if a silo fails before my grain call returns a response for my call? In case of a silo failure in the middle of a grain call, you'll receive an exception that you can catch in your code and retry or do something else to handle the error according to your application logic. The grain that failed with the silo will get automatically re-instantiated upon a next call to it. The Orleans runtime does not eagerly recreate grains from a failed silo because many of them may not be needed immediately or at all. Instead, the runtime recreates such grains individually and only when a new request arrives for a particular grain. For each grain it picks one of the available silos as a new host. The benefit of this approach is that the recovery process is performed only for grains that are actually being used and it is spread in time and across all available silos, which improves the responsiveness of the system and the speed of recovery. Note also that there is a delay between the time when a silo fails and when the Orleans cluster detects the failure. The delay is a configurable tradeoff between the speed of detection and the probability of false positives. During this transition period all calls to the grain will fail, but after the detection of the failure the grain will be created, upon a new call to it, on another silo, so it will be eventually available. What happens if a grain call takes too long to execute? Since Orleans uses a cooperative multi-tasking model, it will not preempt the execution of a grain automatically but Orleans generates warnings for long executing grain calls so you can detect them. Cooperative multi-tasking has a much better throughput compared to preemptive multi-tasking. Keep in mind that grain calls should not execute any long running tasks like IO operations synchronously and should not block on other tasks to complete. All waiting should be done asynchronously using the await keyword or other asynchronous waiting mechanisms. Grains should return as soon as possible to let other grains execute for maximum throughput."
  },
  "docs/resources/index.html": {
    "href": "docs/resources/index.html",
    "title": "Resources | Microsoft Orleans Documentation",
    "keywords": "Resources Contributing Some notes and guidelines for developers who want to contribute to Orleans. Documentation Guidelines The Orleans documentation is built in Markdown. We use a few simple conventions to ensure a homogeneous style throughout the full set of documents. Links Links to articles by members of the Orleans team and others. Presentations A collection of PowerPoint presentations about topics including Orleans Best Practices, Balancing Techniques, and Streaming."
  },
  "docs/resources/links.html": {
    "href": "docs/resources/links.html",
    "title": "Links | Microsoft Orleans Documentation",
    "keywords": "Links By Orleans team Orleans Architecture: Principles and Approach I Episode 142: Microsoft Research project Orleans simplify development of scalable cloud services Orleans: Thinking Big and Small Available Now: Preview of Project “Orleans” – Cloud Services at Scale Orleans: Distributed Virtual Actors for Programmability and Scalability By others Introducing Orleans Microsoft Orleans v2.0 - A comprehensive guide for beginners and experts alike (PowerPoint) A First Look at Project Orleans A Second Look at Project Orleans Project Orleans: An Introduction Introduction To Project Orleans Introduction to Orleans Project Orleans: Different Than Erlang, Designed for a Broad Group of Developers Two Reasons You May Want to Use Microsoft’s Project Orleans Hatay Tuna & Christian Martinez - Applied Actor Model with Orleans Actor Programming with Orleans: What’s Different? Orleans – a “cloud native” runtime built for #azure Project Orleans - Actor Model framework A look at Microsoft Orleans through Erlang-tinted glasses Using Codename “Orleans” in Enterprise Applications Beyond the introduction Grains, Grains and more Grains Fine-graining your Orleans Grains inside the IoT universe Monitorable Grains Aggregating Results in Orleans Creating RESTful Services using Orleans Tackle Distribution, High Throughput and Low-Latency with Orleans – A “cloud native” Runtime Built for #Azure Saving state only once in a while in #ProjectOrleans Using Orleans for building scalable cloud applications Orleans in an IoT universe Orleans Preview & Halo 4 Using Project “Orleans” in Halo Orleans & Thinking Outside the Box John Azariah & Mahesh Krishnan - Immutability, State and Scale - Functional, Distributed Applications in Azure last edited: 5 June 2018"
  },
  "docs/resources/nuget_packages.html": {
    "href": "docs/resources/nuget_packages.html",
    "title": "Orleans NuGet Packages | Microsoft Orleans Documentation",
    "keywords": "Orleans NuGet packages Key Packages There are 5 key NuGet packages you will need to use in most scenarios: Microsoft Orleans Core Abstractions PM> Install-Package Microsoft.Orleans.Core.Abstractions Contains Orleans.Core.Abstractions.dll, which defines Orleans public types that are needed for developing application code (grain interfaces and classes). This package is needs to be directly or indirectly referenced by any Orleans project. Add it to your projects that define grain interfaces and classes. Microsoft Orleans Build-time Code Generation Microsoft.Orleans.OrleansCodeGenerator.Build . PM> Install-Package Microsoft.Orleans.OrleansCodeGenerator.Build Appeared in Orleans 1.2.0. Build time support for grain interfaces and implementation projects. Add it to your grain interfaces and implementation projects to enable code generation of grain references and serializers. Microsoft.Orleans.CodeGenerator.MSBuild . PM> Install-Package Microsoft.Orleans.CodeGenerator.MSBuild Appeared as part of Orleans 2.1.0 . An alternative to the Microsoft.Orleans.OrleansCodeGenerator.Build package. Leverages Roslyn for code analysis to avoid loading application binaries and improves support for incremental builds, which should result in shorter build times. Microsoft Orleans Server Libraries PM> Install-Package Microsoft.Orleans.Server A meta-package for easily building and starting a silo. Includes the following packages: Microsoft.Orleans.Core.Abstractions Microsoft.Orleans.Core Microsoft.Orleans.OrleansRuntime Microsoft.Orleans.OrleansProviders Microsoft Orleans Client Libraries PM> Install-Package Microsoft.Orleans.Client A meta-package for easily building and starting an Orleans client (frontend). Includes the following packages: Microsoft.Orleans.Core.Abstractions Microsoft.Orleans.Core Microsoft.Orleans.OrleansProviders Microsoft Orleans Core Library PM> Install-Package Microsoft.Orleans.Core Contains implementation for most Orleans public types used by application code and Orleans clients (frontends). Reference it for building libraries and client applications that use Orleans types but don't deal with hosting or silos. Included in Microsoft.Orleans.Client and Microsoft.Orleans.Server meta-packages, and is referenced, directly or indirectly, by most other packages. Hosting Microsoft Orleans Runtime PM> Install-Package Microsoft.Orleans.OrleansRuntime Library for configuring and starting a silo. Reference it in your silo host project. Included in Microsoft.Orleans.Server meta-package. Microsoft Orleans Runtime Abstractions PM> Install-Package Microsoft.Orleans.Runtime.Abstractions Contains interfaces and abstractions for types implemented in Microsoft.Orleans.OrleansRuntime. Microsoft Orleans Hosting on Azure Cloud Services PM> Install-Package Microsoft.Orleans.Hosting.AzureCloudServices Contains helper classes for hosting silos and Orleans clients as Azure Cloud Services (Worker Roles and Web Roles). Microsoft Orleans Service Fabric Hosting Support PM> Install-Package Microsoft.Orleans.Hosting.ServiceFabric Contains helper classes for hosting silos as a stateless Service Fabric service. Clustering Providers The below packages include plugins for persisting cluster membership data in various storage technologies. Microsoft Orleans clustering provider for Azure Table Storages PM> Install-Package Microsoft.Orleans.Clustering.AzureStorage Includes the plugin for using Azure Tables for storing cluster membership data. Microsoft Orleans clustering provider for ADO.NET Providers PM> Install-Package Microsoft.Orleans.Clustering.AdoNet Includes the plugin for using ADO.NET for storing cluster membership data in one of the supported databases. Microsoft Orleans Consul Utilities PM> Install-Package Microsoft.Orleans.OrleansConsulUtils Includes the plugin for using Consul for storing cluster membership data. Microsoft Orleans ZooKeeper Utilities PM> Install-Package Microsoft.Orleans.OrleansZooKeeperUtils Includes the plugin for using ZooKeeper for storing cluster membership data. Microsoft Orleans clustering provider for AWS DynamoDB PM> Install-Package Microsoft.Orleans.Clustering.DynamoDB Includes the plugin for using AWS DynamoDB for storing cluster membership data. Reminder Providers The below packages include plugins for persisting reminders in various storage technologies. Microsoft Orleans Reminders Azure Table Storage PM> Install-Package Microsoft.Orleans.Reminders.AzureStorage Includes the plugin for using Azure Tables for storing reminders. Microsoft Orleans Reminders ADO.NET Providers PM> Install-Package Microsoft.Orleans.Reminders.AdoNet Includes the plugin for using ADO.NET for storing reminders in one of the supported databases. Microsoft Orleans reminders provider for AWS DynamoDB PM> Install-Package Microsoft.Orleans.Reminders.DynamoDB Includes the plugin for using AWS DynamoDB for storing reminders. Grain Storage Providers The below packages include plugins for persisting grain state in various storage technologies. Microsoft Orleans Persistence Azure Storage PM> Install-Package Microsoft.Orleans.Persistence.AzureStorage Includes the plugins for using Azure Tables or Azure Blobs for storing grain state. Microsoft Orleans Persistence ADO.NET Providers PM> Install-Package Microsoft.Orleans.Persistence.AdoNet Includes the plugin for using ADO.NET for storing grain state in one of the supported databases. Microsoft Orleans Persistence DynamoDB PM> Install-Package Microsoft.Orleans.Persistence.DynamoDB Includes the plugin for using AWS DynamoDB for storing grain state. Stream Providers The below packages include plugins for delivering streaming events. Microsoft Orleans ServiceBus Utilities PM> Install-Package Microsoft.Orleans.OrleansServiceBus Includes the stream provider for Azure Event Hubs. Microsoft Orleans Streaming Azure Storage PM> Install-Package Microsoft.Orleans.Streaming.AzureStorage Includes the stream provider for Azure Queues. Microsoft Orleans Streaming AWS SQS PM> Install-Package Microsoft.Orleans.Streaming.SQS Includes the stream provider for AWS SQS service. Microsoft Orleans Google Cloud Platform Utilities PM> Install-Package Microsoft.Orleans.OrleansGCPUtils Includes the stream provider for GCP PubSub service. Additional Packages Microsoft Orleans Code Generation PM> Install-Package Microsoft.Orleans.OrleansCodeGenerator Includes the run time code generator. Microsoft Orleans Event-Sourcing PM> Install-Package Microsoft.Orleans.EventSourcing Contains a set of base types for creating grain classes with event-sourced state. Development and Testing Microsoft Orleans Providers PM> Install-Package Microsoft.Orleans.OrleansProviders Contains a set of persistence and stream providers that keep data in memory. Intended for testing. In general, not recommended for production use, unless data loss is care of a silo failure is acceptable. Microsoft Orleans Testing Host Library PM> Install-Package Microsoft.Orleans.TestingHost Includes the library for hosting silos and clients in a testing project. Serializers Microsoft Orleans Bond Serializer PM> Install-Package Microsoft.Orleans.Serialization.Bond Includes support for Bond serializer . Microsoft Orleans Google Utilities PM> Install-Package Microsoft.Orleans.OrleansGoogleUtils Includes Google Protocol Buffers serializer. Microsoft Orleans protobuf-net Serializer PM> Install-Package Microsoft.Orleans.ProtobufNet Includes protobuf-net version of Protocol Buffers serializer. Telemetry Microsoft Orleans Telemetry Consumer - Performance Counters PM> Install-Package Microsoft.Orleans.OrleansTelemetryConsumers.Counters Windows Performance Counters implementation of Orleans Telemetry API. Microsoft Orleans Telemetry Consumer - Azure Application Insights PM> Install-Package Microsoft.Orleans.OrleansTelemetryConsumers.AI Includes the telemetry consumer for Azure Application Insights. Microsoft Orleans Telemetry Consumer - NewRelic PM> Install-Package Microsoft.Orleans.OrleansTelemetryConsumers.NewRelic Includes the telemetry consumer for NewRelic. Tools Microsoft Orleans Performance Counter Tool PM> Install-Package Microsoft.Orleans.CounterControl Includes OrleansCounterControl.exe, which registers Windows performance counter categories for Orleans statistics and for deployed grain classes. Requires elevation. Can be executed in Azure as part of a role startup task. Transactions Microsoft Orleans Transactions support PM> Install-Package Microsoft.Orleans.Transactions Includes support for cross-grain transactions (beta). Microsoft Orleans Transactions on Azure PM> Install-Package Microsoft.Orleans.Transactions.AzureStorage Includes a plugin for persisting transaction log in Azure Table (beta)."
  },
  "docs/resources/orleans_architecture_principles_and_approach_I.html": {
    "href": "docs/resources/orleans_architecture_principles_and_approach_I.html",
    "title": "Orleans Architecture - Principles and Approach I | Microsoft Orleans Documentation",
    "keywords": "Now that Orleans is (finally) available as open source, it's important to be clear about the goals and principles that has motivated the design decisions behind Orleans so that new changes either fit within that framework or explicitly and intentionally revise those goals and principles. About the time I joined the Orleans project, we agreed that the goal was to produce a framework that would allow mainstream developers to easily build scalable distributed (cloud) applications. To break this down a bit: The target audience shouldn't exclude programmers who haven't done distributed systems development . We want to enable all developers, whether cloud experts or cloud beginners, to focus on their application logic and features -- which is to say, what actually provides business value -- rather than on generic distributed systems issues. The goal is to allow them to build cloud applications easily . Easily means that they shouldn't have to think about distribution any more than is absolutely required. Easily also means that Orleans should present as familiar a façade to the developer as possible; in a .NET context, that means C# objects and interfaces. Those applications should be \"scalable by default\" . Since our target users aren't necessarily distributed systems experts, we want to provide them a framework that will lead them to build scalable applications without explicitly thinking about it. This means that the framework has to make a lot of decisions for them in order to guarantee an acceptable degree of scalability, even if that means that the scalability isn't optimal for every application. We supplemented this goal with a set of architectural principles: We're focused on the 80% case . There are certainly applications that Orleans isn't appropriate for; that's OK. There are applications that Orleans is a reasonable fit for, but where you can get somewhat better performance by a bunch of hand-tuning that Orleans doesn't allow; that's OK too. The 80% that Orleans fits well and performs well enough on covers a lot of interesting applications, and we'd rather do a great job on 80% than a lousy job on 99%. Scalability is paramount . We'll trade off raw performance if that gets us better scaling. Availability is paramount . A cloud application should be like a utility: always there when you want it. Detect and fix problems , don't assume you can 100% prevent them. At cloud scale, bad things happen often, and even impossible bad things happen, just less often. This has led us to what is often termed \"recovery-oriented computing\", rather than trying to be fault-tolerant; our experience has shown that fault tolerance is fragile and often illusory. Even mathematically proven protocols are no protection against random bit flips in memory or disk controllers that fail while reporting success -- both real examples I've seen in production in my career. The above has led us to certain practices: API-first design : if we don't know how we're going to expose a feature to the developer, then we don't build it. Of course, the best way is for a feature have no developer exposure at all... Make it easy to do the right thing : keep things as simple as possible (but no simpler), don't provide a hammer if a screwdriver is the right tool. As one of our early adopters put it, we try to help our customers \"fall into the pit of success\". If there is a standard pattern that will work well for 80% of the applications out there, then don't worry about enabling every possible alternative. Orleans' embrace of asynchrony is a good example of this. Make it easy for developers to extend the framework without breaking it . Custom serialization and persistence providers are a couple of examples of this. Some sort of custom task scheduling extension would be an anti-example. Follow the principle of least surprise : as much as possible, things should be as familiar, but everything should behave the way it looks. The next post will start applying these principles to the current Orleans design and walk through the motivations for some specific decisions we made. Thanks for reading! Alan Geller Alan Geller, http://research.microsoft.com/en-us/people/ageller/ , works on quantum computing at Microsoft Research. He was one of the primary architects of Orleans from 2008 until 2012. Earlier, he was the platform architect for Amazon Web Services from 2004 to 2008, and before that built a wide variety of large-scale production distributed systems in telecommunications and financial services."
  },
  "docs/resources/orleans_thinking_big_and_small.html": {
    "href": "docs/resources/orleans_thinking_big_and_small.html",
    "title": "Orleans - Thinking Big and Small | Microsoft Orleans Documentation",
    "keywords": "TL;DR: You don’t need hundreds of servers to benefit from Orleans. A handful is enough. As we just announced availability of the Project Orleans as a public preview ( Available Now: Preview of Project “Orleans” – Cloud Services at Scale ), some of the initial questions and discussions at //build/ were around what type of services the Orleans programming model is suitable for. I heard statements that Orleans is for super-high scale systems. While technically correct, they felt incomplete to me, and compelled me to write this post. Applicability Spectrum One extreme of the Orleans applicability spectrum is a single machine application. Some people see isolation of actors and safe concurrency as big enough benefits that they are worth the price of message passing. That’s not the use case we optimized for while building Orleans, but it’s a legitimate usage pattern, just not very interesting in the cloud context. At the other end of the spectrum we find massive deployments that span thousands of servers. We tested Orleans on deployments of hundreds of servers, and I’m sure it will run fine on thousands, even if that will require some configuration tweaks. However, I’m personally rather skeptical about how many products actually need a single cloud service spanning thousands of servers as opposed to running multiple related services interacting with each other where each service instance is deployed on tens or hundreds of servers. Distributed system – same problems regardless of the size The moment a system moves from a single server to multiple servers, developers face very much the same set of challenges, regardless of its size -- whether it's a 3-5, 30-50 or 300-500 server system. They now have to deal with distribution of their computations, coordination between them, scalability, fault tolerance and reconfigurations, diagnostics, etc. They are building a distributed system now, which is never easy. And building a stateful distributed system is even harder. Orleans was designed to help with building such systems by providing an easy to use set of abstractions that greatly simplifies developers’ lives and helps them avoid common distributed systems pitfalls. The distributed runtime was built to perform most of the heavy lifting. Developers can equally benefit from these features of Orleans when building services of different sizes because the problems Orleans solves for them are really the same. The abstraction of grains simplifies reasoning about your system while encouraging fine-grain partitioning of state for scalability. The virtual actor feature helps with resource management and fault tolerance. Automatic propagation of exceptions minimizes error handling code without losing failures. The distributed runtime takes care of server failures, messaging, routing, single-threaded execution, and other system level guarantees. You don’t need hundreds of servers to start reaping the developer productivity gains. Elasticity Predicting load for your future system is hard and often simply impossible. Every startup dreams of getting slashdotted one day, which is a blessing for the business and a curse for the system. Or your CMO may like your BI data so much that she suddenly wants to have it in 5 second aggregates instead of 30 minutes. Building for high load that may never materialize is expensive. The Orleans model helps solve the elasticity problem by encouraging designing your system in a scalable way, so that you can start with a small deployment and stay small or scale out big if needed without changing your application code. Bottom Line You should be able to benefit from Orleans the moment you go from a single-server setup to a distributed system, whether it’s 2 or 3 servers or thousands of them. You can even start building your single-server solution with Orleans if you believe you may need one day scale it out or make fault tolerant. The beauty here is that your code won’t need to change. Just add more servers and your grains will spread across them. -Sergey Bykov"
  },
  "docs/resources/presentations/index.html": {
    "href": "docs/resources/presentations/index.html",
    "title": "Orleans Presentations | Microsoft Orleans Documentation",
    "keywords": "Orleans Best Practices A collection of tips and trick to help design, build, and run an Orleans-based application. Orleans Presentation from the 28th International Symposium on Distributed Computing (DISC 2014) Orleans Presentation from the 15th International Workshop on High Performance Transaction Systems (HPTS 2013) Balancing Techniques in Orleans Uniform API is 42 - Virtual Meetup #3 Orleans at FreeBay - Virtual Meetup #4 Orleans Streaming - Virtual Meetup #5 - May 2015 Geo Distributed Orleans - Virtual Meetup #6 - October 2015 Orleankka Functional API for Orleans - Virtual Meetup #7 Orleans Roadmap - Virtual Meetup #8 - January 2016 Orleans Networking discussion- Virtual Meetup #8.5 - February 2016 Orleans on Service Fabric - Virtual Meetup #9 Part 1 - February 2016 Orleans with YAMS - Virtual Meetup #9 Part 2 - February 2016 Walk In Distributed Systems Park With Orleans Orleans at Microsoft by Reuben Bond - August 2020 (video)"
  },
  "docs/resources/student_projects.html": {
    "href": "docs/resources/student_projects.html",
    "title": "Student Projects | Microsoft Orleans Documentation",
    "keywords": "Student Projects We suggest 2 types of projects for students: The first type includes exploratory, open-ended, research-oriented projects with the goal of enabling new capabilities in Orleans. These projects would usually have broad scope and would be suitable for M.S. or Ph.D. student or advanced undergraduate students in their last year of studies. The end goal of these projects would be to contribute ideas and design to Orleans. We do not necessarily expect the code produced in these projects to be directly contributed to this repository, however this would be nice. The second type includes ideas for student education . These are either ideas for interesting applications that can be built on top of Orleans or some new capabilities for Orleans. These projects are suitable to be given in advanced undergraduate or graduate courses, where students learn about Cloud Computing and modern distributed technologies and want to gain real-world hands-on experience in building Cloud applications. We do not expect the code produced in these projects to be contributed directly to this repository. Research projects: Auto-scale. In this project students can start by exploring the existing auto-scaling mechanisms for controlling resource allocation in Windows Azure ( Autoscaling Application Block ). The next step involves exploring various statistics and resource consumption metrics collected by Orleans, and using them as an input for Azure Autoscaling. An advanced stage of this project may involve improving the internal Orleans mechanisms for reacting to elasticity changes, for example by implementing live actor migration to reduce the time taken to utilize new resources. Auto-generated front-ends for Orleans-based cloud services . This project seamlessly extends the Orleans actor model into the HTTP world. The ramp-up part of the project includes dynamically generating HTTP endpoints for actors based on their .NET interfaces and metadata. The main part involves automatically generating front-ends to support web sockets and bi-directional streaming of data, which requires complex code generation with optimizations for high performance. It also requires attention to fault tolerance, to maintain high availability of streaming sessions across server reboots and client reconnects and migration -- a significant research challenge. Storage provider for Entity Framework . This project involves enabling Orleans objects to store their state in a database and to subsequently query it. This might include adding support for Orleans object persistence on SQL Azure Database using Entity Framework (EF), which is Microsoft's open-source object-relational mapper for .NET, and exposing that data via LINQ queries. The implementation can be evaluated and tuned using standard database benchmarks and/or custom Orleans' applications. Distributed system benchmark . Define a list of benchmarks suitable for distributed systems like Orleans. The benchmark applications may be analogous in spirit to the TPC database benchmark or UCB \"Parallel Dwarfs\" implemented here and may be used to characterize the performance and scalability of distributed frameworks. Consider developing a new benchmark targeted for Orleans, for example, to compare the performance of storage providers. Declarative dataflow language over streams . Define and build a Trident-Storm like declarative language over Orleans streams. Develop an optimizer that configures the stream processing to minimize overall cost. Programming model for client devices . Extend Orleans to client devices, such as sensors, phones, tablets, and desktops. Enable grain logic to execute on the client. Potentially support tier splitting, that is, dynamically deciding which parts of the code execute on the device and which is offloaded to the cloud. Queries over grain/actor classes, secondary indices . Build a distributed, scalable, and reliable grain index. This includes formally defining the query model and implementing the distributed index. The index itself can be implemented as Orleans grains and/or stored in a database. Large scale simulations . Orleans is a great fit for building large scale simulations. Explore the usage of Orleans for different simulations, for example, protein interactions, network simulations, simulated annealing, etc. Course projects: Internet Of Things applications . For example, the application could enable sensors/devices to report their state to the cloud, where each device is represented in the cloud by an Orleans actor. Users can connect to the actor that represents their device via a web browser and check its status or control it. This project involves mastering a number of modern cloud technologies, including Windows Azure , Orleans, WebApi or ASP.NET, SignalR for streaming commands back from the cloud to the device, and writing a sensor/device/phone app. Twitter-like large scalable chat service in the cloud based on Orleans . Each user could be represented by an Orleans Actor, which contains its list of followers. Faceboook-like social app based on Orleans . Each user could be represented by an Orleans Actor, which includes a list of friends and wall on which friends can write. Simple storage provider . Add a storage provider for a storage system, such as a key-value store or database system. A simple one could use the Orleans serializer , as in the existing Azure Table storage provider . A more sophisticated one would map state variables of an Orleans class to fine-grained structures of the storage system. A complex one is the Entity Framework storage provider mentioned above under Research Projects . Compare the performance of different storage providers for different types and sizes of actor state. Comparison with other distributed application frameworks . Take a sample application written for another application framework, such as Google App Engine or Akka , and translate it into Orleans. Summarize the relative strengths and weaknesses of each framework by comparing the apps. Concluded Research projects: Below are a number of examples of previous successful research projects. Distributed log analysis, correlation and debugging . Debugging large-scale distributed systems is a challenging task due to enormous amounts of data and complex dynamic interactions between the distributed components, running on different processes and different machines. The goal of this project was to analyze prior art on this topic, propose a solution, and then implement prototype tools for collecting, correlating and analyzing application error log file data across a multi-machine distributed application runtime environment. This involved exploring the problem space from a variety of perspectives, including: a. Approaches to efficient logging, collection and analysis of failure information from various log-capture mechanisms in a distributed Orleans runtime environment. b. Possible applications of machine learning to find log patterns that signal serious production issues, and then detecting these patterns in near real time as a production monitoring utility. c. Ways to help individual developers perform real-time debugging of run-time issues with their applications. This project was performed successfully and result in a published paper PAD: Performance Anomaly Detection in Multi-Server Distributed Systems and a proof of concept implementation of a distributed log analysis tool. Horton - Distributed Graph Database . Horton was a research project with a goal to build a system to store, manage and query large-scale distributed graphs. It was implemented entirely as an Orleans application. The project resulted in a number of publications and a number of very successful student projects."
  },
  "docs/streaming/index.html": {
    "href": "docs/streaming/index.html",
    "title": "Orleans Streams | Microsoft Orleans Documentation",
    "keywords": "Orleans Streams Orleans v.1.0.0 added support for streaming extensions to the programing model. Streaming extensions provide a set of abstractions and APIs that make thinking about and working with streams simpler and more robust. Streaming extensions allow developers to write reactive applications that operate on a sequence of events in a structured way. The extensibility model of stream providers makes the programming model compatible with and portable across a wide range of existing queuing technologies, such as Event Hubs , ServiceBus , Azure Queues , and Apache Kafka . There is no need to write special code or run dedicated processes to interact with such queues. Why should I care? If you already know all about Stream Processing and are familiar with technologies like Event Hubs , Kafka , Azure Stream Analytics , Apache Storm , Apache Spark Streaming , and Reactive Extensions (Rx) in .NET , you may be asking why should you care. Why do we need yet another Stream Processing System and how Actors are related to Streams? \"Why Orleans Streams?\" is meant to answer that question. Programming Model There are a number of principles behind Orleans Streams Programming Model: Orleans streams are virtual . That is, a stream always exists. It is not explicitly created or destroyed, and it can never fail. Streams are identified by stream IDs, which are just logical names comprised of GUIDs and strings. Orleans Streams allow you to decouple generation of data from its processing, both in time and space . That means that the stream producer and the stream consumer may be on different servers or in different time zones, and will withstand failures. Orleans streams are lightweight and dynamic . Orleans Streaming Runtime is designed to handle a large number of streams that come and go at a high rate. Orleans stream bindings are dynamic . Orleans Streaming Runtime is designed to handle cases where grains connect to and disconnect from streams at a high rate. Orleans Streaming Runtime transparently manages the lifecycle of stream consumption . After an application subscribes to a stream, it will then receive the stream's events, even in the presence of failures. Orleans streams work uniformly across grains and Orleans clients . Programming APIs Applications interact with streams via APIs that are very similar to the well-known Reactive Extensions (Rx) in .NET , by using Orleans.Streams.IAsyncStream<T> that implements Orleans.Streams.IAsyncObserver<T> and Orleans.Streams.IAsyncObservable<T> interfaces. In a typical example below, a device generates some data, which is sent as an HTTP request to the service running in the Cloud. The Orleans client running in the front-end server receives this HTTP call and publishes the data into a matching device stream: public async Task OnHttpCall(DeviceEvent deviceEvent) { // Post data directly into the device's stream. IStreamProvider streamProvider = GrainClient.GetStreamProvider(\"MyStreamProvider\"); IAsyncStream<DeviceEventData> deviceStream = streamProvider.GetStream<DeviceEventData>(deviceEvent.DeviceId, \"MyNamespace\"); await deviceStream.OnNextAsync(deviceEvent.Data); } In another example below, a chat user (implemented as Orleans Grain) joins a chat room, gets a handle to a stream of chat messages generated by all others users in this room, and subscribes to it. Notice that the chat user does not need to know about the chat room grain itself (there might not be such a grain in our system) or about other users in that group that produce messages. Needless to say, to publish to the chat stream, users don't need to know who is currently subscribed to the stream. This demonstrates how chat users can be completely decoupled in time and space. public class ChatUser: Grain { public async Task JoinChat(Guid chatGroupId) { IStreamProvider streamProvider = base.GetStreamProvider(\"MyStreamProvider\"); IAsyncStream<string> chatStream = streamProvider.GetStream<string>(chatGroupId, \"MyNamespace\"); await chatStream.SubscribeAsync(async (message, token) => Console.WriteLine(message)) } } Quick Start Sample The Quick Start Sample is a good quick overview of the overall workflow of using streams in the application. After reading it, you should read the Streams Programming APIs to get a deeper understanding of the concepts. Streams Programming APIs A Streams Programming APIs provides a detailed description of the programming APIs. Stream Providers Streams can come via physical channels of various shapes and forms and can have different semantics. Orleans Streaming is designed to support this diversity via the concept of Stream Providers , which is an extensibility point in the system. Orleans currently has implementations of two stream providers: TCP based Simple Message Stream Provider and Azure Queue based Azure Queue Stream Provider . More details on Stream Providers can be found at Stream Providers . Stream Semantics Stream Subscription Semantics : Orleans Streams guarantee Sequential Consistency for Stream Subscription operations. Specifically, when a consumer subscribes to a stream, once the Task representing the subscription operation was successfuly resolved, the consumer will see all events that were generated after it has subscribed. In addition, Rewindable streams allow you to subscribe from an arbitrary point in time in the past by using StreamSequenceToken (more details can be found here ). Individual Stream Events Delivery Guarantees : Individual event delivery guarantees depend on individual stream providers. Some provide only best-effort at-most-once delivery (such as Simple Message Streams (SMS)), while others provide at-least-once delivery (such as Azure Queue Streams). It is even possible to build a stream provider that will guarantee exactly-once delivery (we don't have such a provider yet, but it is possible to build one). Events Delivery Order : Event order also depends on a particular stream provider. In SMS streams, the producer explicitly controls the order of events seen by the consumer by controlling the way it publishes them. Azure Queue streams do not guarantee FIFO order, since the underlying Azure Queues do not guarantee order in failure cases. Applications can also control their own stream delivery ordering by using StreamSequenceToken . Streams Implementation The Orleans Streams Implementation provides a high-level overview of the internal implementation. Code Samples More examples of how to use streaming APIs within a grain can be found here . We plan to create more samples in the future. More Material Orleans Virtual Meetup about Streams Orleans Streaming Presentation from Virtual Meetup"
  },
  "docs/streaming/stream_providers.html": {
    "href": "docs/streaming/stream_providers.html",
    "title": "Orleans Stream Providers | Microsoft Orleans Documentation",
    "keywords": "Stream Providers Streams can come in different shapes and forms. Some streams may deliver events over direct TCP links, while others deliver events via durable queues. Different stream types may use different batching strategies, different caching algorithms, or different back pressure procedures. To avoid constraining streaming applications to only a subset of those behavioral choices, Stream Providers are extensibility points to Orleans Streaming Runtime that allow users to implement any type of stream. This extensibility point is similar in spirit to Orleans Storage Providers . Orleans currently ships with many stream providers, including : Simple Message Stream Provider and Azure Queue Stream Provider . Simple Message Stream Provider Simple Message Stream Provider, also known as the SMS provider, delivers events over TCP by utilizing regular Orleans grain messaging. Since events in SMS are delivered over unreliable TCP links, SMS does not guarantee reliable event delivery and does not automatically resend failed messages for SMS streams. By default the producer's call to stream.OnNextAsync returns a Task that represents the processing status of the stream consumer, which tells the producer whether the consumer successfully received and processed the event. If this Task fails, the producer can decide to send the same event again, thus achieving reliability on the application level. Although stream message delivery is best effort, SMS streams themselves are reliable. That is, the subscriber-to-producer binding performed by Pub-Sub is fully reliable. Azure Queue (AQ) Stream Provider Azure Queue (AQ) Stream Provider delivers events over Azure Queues. On the producer side, AQ Stream Provider enqueues events directly into Azure Queue. On the consumer side, AQ Stream Provider manages a set of pulling agents that pull events from a set of Azure Queues and deliver them to application code that consumes them. One can think of the pulling agents as a distributed \"micro-service\" -- a partitioned, highly available, and elastic distributed component. The pulling agents run inside the same silos that host application grains. Thus, there is no need to run separate Azure worker roles to pull from the queues. The existence of pulling agents, their management, backpressure, balancing the queues between them, and handing off queues from a failed agent to another agent are fully managed by Orleans Streaming Runtime and are transparent to application code that uses streams. Queue Adapters Different stream providers that deliver events over durable queues exhibit similar behavior and are subject to a similar implementation. Therefore, we provide a generic extensible PersistentStreamProvider that allows developers to plug in different types of queues without writing a completely new stream provider from scratch. PersistentStreamProvider uses an IQueueAdapter component, which abstracts specific queue implementation details and provides means to enqueue and dequeue events. All the rest is handled by the logic inside the PersistentStreamProvider . Azure Queue Provider mentioned above is also implemented this way: it is an instance of PersistentStreamProvider that uses an AzureQueueAdapter . Next Orleans Streams Implementation Details"
  },
  "docs/streaming/streams_programming_APIs.html": {
    "href": "docs/streaming/streams_programming_APIs.html",
    "title": "Orleans Streams Programming APIs | Microsoft Orleans Documentation",
    "keywords": "Orleans Streams Programming APIs Applications interact with streams via APIs that are very similar to the well known Reactive Extensions (Rx) in .NET . The main difference is that Orleans stream extensions are asynchronous , to make processing more efficient in Orleans' distributed and scalable compute fabric. Async Stream An application starts by using a stream provider to get a handle to a stream. You can read more about stream providers here , but for now you can think of it as stream factory that allows implementers to customize streams behavior and semantics: IStreamProvider streamProvider = base.GetStreamProvider(\"SimpleStreamProvider\"); IAsyncStream<T> stream = streamProvider.GetStream<T>(Guid, \"MyStreamNamespace\"); An application can get a reference to the stream provider either by calling the GetStreamProvider method on the Grain class when inside a grain, or by calling the GrainClient.GetStreamProvider() method when on the client. Orleans.Streams.IAsyncStream<T> is a logical, strongly-typed handle to a virtual stream . It is similar in spirit to Orleans Grain Reference. Calls to GetStreamProvider and GetStream are purely local. The arguments to GetStream are a GUID and an additional string that we call a stream namespace (which can be null). Together the GUID and the namespace string comprise the stream identity (similar in sprit to the arguments to GrainFactory.GetGrain ). The combination of GUID and namespace string provide extra flexibility in determining stream identities. Just like grain 7 may exist within the Grain type PlayerGrain and a different grain 7 may exist within the grain type ChatRoomGrain , Stream 123 may exist with the stream namespace PlayerEventsStream and a different stream 123 may exist within the stream namespace ChatRoomMessagesStream . Producing and Consuming IAsyncStream<T> implements both Orleans.Streams.IAsyncObserver<T> and Orleans.Streams.IAsyncObservable<T> interfaces. That way an application can use the stream either to produce new events into the stream by using Orleans.Streams.IAsyncObserver<T> or to subscribe to and consume events from a stream by using Orleans.Streams.IAsyncObservable<T> . public interface IAsyncObserver<in T> { Task OnNextAsync(T item, StreamSequenceToken token = null); Task OnCompletedAsync(); Task OnErrorAsync(Exception ex); } public interface IAsyncObservable<T> { Task<StreamSubscriptionHandle<T>> SubscribeAsync(IAsyncObserver<T> observer); } To produce events into the stream, an application just calls await stream.OnNextAsync<T>(event) To subscribe to a stream, an application calls StreamSubscriptionHandle<T> subscriptionHandle = await stream.SubscribeAsync(IAsyncObserver) The argument to SubscribeAsync can either be an object that implements the IAsyncObserver interface or a combination of lambda functions to process incoming events. More options for SubscribeAsync are available via AsyncObservableExtensions class. SubscribeAsync returns a StreamSubscriptionHandle<T> , which is an opaque handle that can be used to unsubscribe from the stream (similar in spirit to an asynchronous version of IDisposable ). await subscriptionHandle.UnsubscribeAsync() It is important to note that the subscription is for a grain, not for an activation . Once the grain code is subscribed to the stream, this subscription surpasses the life of this activation and stays durable forever, until the grain code (potentially in a different activation) explicitly unsubscribes. This is the heart of a virtual stream abstraction : not only do all streams always exist, logically, but also a stream subscription is durable and lives beyond a particular physical activation that created the subscription. Multiplicity An Orleans stream may have multiple producers and multiple consumers. A message published by a producer will be delivered to all consumers that were subscribed to the stream before the message was published. In addition, the consumer can subscribe to the same stream multiple times. Each time it subscribes it gets back a unique StreamSubscriptionHandle<T> . If a grain (or client) is subscribed X times to the same stream, it will receive the same event X times, once for each subscription. The consumer can also unsubscribe from an individual subscription. It can find all its current subscriptions by calling: IList<StreamSubscriptionHandle<T>> allMyHandles = await IAsyncStream<T>.GetAllSubscriptionHandles() Recovering From Failures If the producer of a stream dies (or its grain is deactivated), there is nothing it needs to do. The next time this grain wants to produce more events it can get the stream handle again and produce new events in the same way. Consumer logic is a little bit more involved. As we said before, once a consumer grain is subscribed to a stream, this subscription is valid until the grain explicitly unsubscribes. If the consumer of the stream dies (or its grain is deactivated) and a new event is generated on the stream, the consumer grain will be automatically re-activated (just like any regular Orleans grain is automatically activated when a message is sent to it). The only thing that the grain code needs to do now is to provide an IAsyncObserver<T> to process the data. The consumer basically needs to re-attach processing logic as part of the OnActivateAsync method. To do that it can call: StreamSubscriptionHandle<int> newHandle = await subscriptionHandle.ResumeAsync(IAsyncObserver) The consumer uses the previous handle it got when it first subscribed in order to \"resume processing\". Notice that ResumeAsync merely updates an existing subscription with the new instance of IAsyncObserver logic and does not change the fact that this consumer is already subscribed to this stream. How does the consumer get an old subscriptionHandle? There are 2 options. The consumer may have persisted the handle it was given back from the original SubscribeAsync operation and can use it now. Alternatively, if the consumer does not have the handle, it can ask the IAsyncStream<T> for all its active subscription handles, by calling: IList<StreamSubscriptionHandle<T>> allMyHandles = await IAsyncStream<T>.GetAllSubscriptionHandles() The consumer can now resume all of them, or unsubscribe from some if it wishes to. COMMENT: If the consumer grain implements the IAsyncObserver interface directly ( public class MyGrain<T> : Grain, IAsyncObserver<T> ), it should in theory not be required to re-attach the IAsyncObserver and thus will not need to call ResumeAsync . The streaming runtime should be able to automatically figure out that the grain already implements IAsyncObserver and will just invoke those IAsyncObserver methods. However, the streaming runtime currently does not support this and the grain code still needs to explicitly call ResumeAsync , even if the grain implements IAsyncObserver directly. Supporting this is on our TODO list. Explicit and Implicit Subscriptions By default, a stream consumer has to explicitly subscribe to the stream. This subscription would usually be triggered by some external message that the grain (or client) receives that instructs it to subscribe. For example, in a chat service when a user joins a chat room his grain receives a JoinChatGroup message with the chat name, which will cause the user grain to subscribe to this chat stream. In addition, Orleans Streams also support \"Implicit Subscriptions\" . In this model the grain does not explicitly subscribe to the stream. This grain is subscribed automatically, implicitly, just based on its grain identity and an ImplicitStreamSubscription attribute. Implicit subscriptions' main value is allowing the stream activity to trigger the grain activation (hence triggering the subscription) automatically. For example, using SMS streams, if one grain wanted to produce a stream and another grain process this stream, the producer would need to know the identity of the consumer grain and make a grain call to it telling it to subscribe to the stream. Only after that can it start sending events. Instead, using implicit subscriptions, the producer can just start producing events to a stream, and the consumer grain will automatically be activated and subscribe to the stream. In that case, the producer doesn't care at all who is reading the events Grain implementation class of type MyGrainType can declare an attribute [ImplicitStreamSubscription(\"MyStreamNamespace\")] . This tells the streaming runtime that when an event is generated on a stream whose identity is GUID XXX and \"MyStreamNamespace\" namespace, it should be delivered to the grain whose identity is XXX of type MyGrainType . That is, the runtime maps stream <XXX, MyStreamNamespace> to consumer grain <XXX, MyGrainType> . The presence of ImplicitStreamSubscription causes the streaming runtime to automatically subscribe this grain to a stream and deliver the stream events to it. However, the grain code still needs to tell the runtime how it wants events to be processed. Essentially, it needs to attach the IAsyncObserver . Therefore, when the grain is activated, the grain code inside OnActivateAsync needs to call: IStreamProvider streamProvider = base.GetStreamProvider(\"SimpleStreamProvider\"); IAsyncStream<T> stream = streamProvider.GetStream<T>(this.GetPrimaryKey(), \"MyStreamNamespace\"); StreamSubscriptionHandle<T> subscription = await stream.SubscribeAsync(IAsyncObserver<T>); Writing Subscription Logic Below are the guidelines on how to write the subscription logic for various cases: explicit and implicit subscriptions, rewindable and non-rewindable streams. The main difference between explicit and implicit subscriptions is that for implicit the grain always has exactly one implicit subscription for every stream namespace; there is no way to create multiple subscriptions (there is no subscription multiplicity), there is no way to unsubscribe, and the grain logic always only needs to attach the processing logic. That also means that for implicit subscriptions there is never a need to Resume a subscription. On the other hand, for explicit subscriptions, one needs to Resume the subscription, otherwise if the grain subscribes again it will result in the grain being subscribed multiple times. Implicit Subscriptions: For implicit subscriptions the grain needs to subscribe to attach the processing logic. This should be done in the grain's OnActivateAsync method. The grain should simply execute await stream.SubscribeAsync(OnNext ...) in its OnActivateAsync method. That will cause this particular activation to attach the OnNext function to process that stream. The grain can optionally specify the StreamSequenceToken as an argument to SubscribeAsync , which will cause this implicit subscription to start consuming from that token. There is never a need for implicit subscription to call ResumeAsync . public async override Task OnActivateAsync() { var streamProvider = GetStreamProvider(PROVIDER_NAME); var stream = streamProvider.GetStream<string>(this.GetPrimaryKey(), \"MyStreamNamespace\"); await stream.SubscribeAsync(OnNextAsync) } Explicit Subscriptions: For explicit subscriptions, a grain must call SubscribeAsync to subscribe to the stream. This creates a subscription, as well as attaches the processing logic. The explicit subscription will exist until the grain unsubscribes, so if a grain gets deactivated and reactivated, the grain is still explicitly subscribed, but no processing logic will be attached. In this case the grain needs to re-attach the processing logic. To do that, in its OnActivateAsync , the grain first needs to find out what subscriptions it has, by calling stream.GetAllSubscriptionHandles() . The grain must execute ResumeAsync on each handle it wishes to continue processing or UnsubscribeAsync on any handles it is done with. The grain can also optionally specify the StreamSequenceToken as an argument to the ResumeAsync calls, which will cause this explicit subscription to start consuming from that token. public async override Task OnActivateAsync() { var streamProvider = GetStreamProvider(PROVIDER_NAME); var stream = streamProvider.GetStream<string>(this.GetPrimaryKey(), \"MyStreamNamespace\"); var subscriptionHandles = await stream.GetAllSubscriptionHandles(); if (!subscriptionHandles.IsNullOrEmpty()) subscriptionHandles.ForEach(async x => await x.ResumeAsync(OnNextAsync)); } Stream Order and Sequence Tokens The order of event delivery between an individual producer and an individual consumer depends on the stream provider. With SMS the producer explicitly controls the order of events seen by the consumer by controlling the way the producer publishes them. By default (if the FireAndForget option for SMS provider is set to false) and if the producer awaits every OnNextAsync call, the events arrive in FIFO order. In SMS it is up to the producer to decide how to handle delivery failures that will be indicated by a broken Task returned by the OnNextAsync call. Azure Queue streams do not guarantee FIFO order, since the underlying Azure Queues do not guarantee order in failure cases. (They do guarantee FIFO order in failure-free executions.) When a producer produces the event into Azure Queue, if the enqueue operation fails, it is up to the producer to attempt another enqueue and later on deal with potential duplicate messages. On the delivery side, the Orleans Streaming runtime dequeues the event from the queue and attempts to deliver it for processing to consumers. The Orleans Streaming runtime deletes the event from the queue only upon successful processing. If the delivery or processing fails, the event is not deleted from the queue and will automatically re-appear in the queue later. The Streaming runtime will try to deliver it again, thus potentially breaking the FIFO order. The above behavior matches the normal semantics of Azure Queues. Application Defined Order : To deal with the above ordering issues, an application can optionally specify its own ordering. This is achieved via a StreamSequenceToken , which is an opaque IComparable object that can be used to order events. A producer can pass an optional StreamSequenceToken to the OnNext call. This StreamSequenceToken will be passed all the way to the consumer and will be delivered together with the event. That way, an application can reason and reconstruct its order independently of the streaming runtime. Rewindable Streams Some streams only allow an application to subscribe to them starting at the latest point in time, while other streams allow \"going back in time\". The latter capability is dependent on the underlying queuing technology and the particular stream provider. For example, Azure Queues only allow consuming the latest enqueued events, while EventHub allows replaying events from an arbitrary point in time (up to some expiration time). Streams that support going back in time are called Rewindable Streams . The consumer of a rewindable stream can pass a StreamSequenceToken to the SubscribeAsync call. The runtime will deliver events to it starting from that StreamSequenceToken . A null token means the consumer wants to receive events starting from the latest. The ability to rewind a stream is very useful in recovery scenarios. For example, consider a grain that subscribes to a stream and periodically checkpoints its state together with the latest sequence token. When recovering from a failure, the grain can re-subscribe to the same stream from the latest checkpointed sequence token, thereby recovering without losing any events that were generated since the last checkpoint. Event Hubs provider is rewindable. You can find its code here . SMS and Azure Queue providers are not rewindable. Stateless Automatically Scaled-Out Processing By default Orleans Streaming is targeted to support a large number of relatively small streams, each processed by one or more stateful grains. Collectively, the processing of all the streams together is sharded among a large number of regular (stateful) grains. The application code controls this sharding by assigning stream ids and grain ids and by explicitly subscribing. The goal is sharded stateful processing . However, there is also an interesting scenario of automatically scaled-out stateless processing . In this scenario an application has a small number of streams (or even one large stream) and the goal is stateless processing. An example is a global stream of events, where the processing involves decoding each event and potentially forwarding it to other streams for further stateful processing. The stateless scaled-out stream processing can be supported in Orleans via StatelessWorker grains. Current Status of Stateless Automatically Scaled-Out Processing: This is not yet implemented. An attempt to subscribe to a stream from a StatelessWorker grain will result in undefined behavior. We are considering to support this option . Grains and Orleans Clients Orleans streams work uniformly across grains and Orleans clients . That is, exactly the same APIs can be used inside a grain and in an Orleans client to produce and consume events. This greatly simplifies the application logic, making special client-side APIs, such as Grain Observers, redundant. Fully Managed and Reliable Streaming Pub-Sub To track stream subscriptions, Orleans uses a runtime component called Streaming Pub-Sub which serves as a rendezvous point for stream consumers and stream producers. Pub Sub tracks all stream subscriptions, persists them, and matches stream consumers with stream producers. Applications can choose where and how the Pub-Sub data is stored. The Pub-Sub component itself is implemented as grains (called PubSubRendezvousGrain ), which use Orleans Declarative Persistence. PubSubRendezvousGrain uses the storage provider named PubSubStore . As with any grain, you can designate an implementation for a storage provider. For Streaming Pub-Sub you can change the implementation of the PubSubStore at silo construction time using the silo host builder: The following configures Pub-Sub to store its state in Azure tables. hostBuilder.AddAzureTableGrainStorage(\"PubSubStore\", options=>{ options.ConnectionString = \"Secret\"; }); That way Pub-Sub data will be durably stored in Azure Table. For initial development you can use memory storage as well. In addition to Pub-Sub, the Orleans Streaming Runtime delivers events from producers to consumers, manages all runtime resources allocated to actively used streams, and transparently garbage collects runtime resources from unused streams. Configuration In order to use streams you need to enable stream providers via the silo host or cluster client builders. You can read more about stream providers here . Sample stream provider setup: hostBuilder.AddSimpleMessageStreamProvider(\"SMSProvider\") .AddAzureQueueStreams<AzureQueueDataAdapterV2>(\"AzureQueueProvider\", optionsBuilder => optionsBuilder.Configure( options=>{ options.ConnectionString = \"Secret\"; })) .AddAzureTableGrainStorage(\"PubSubStore\", options=>{ options.ConnectionString = \"Secret\"; }); Next Orleans Stream Providers"
  },
  "docs/streaming/streams_quick_start.html": {
    "href": "docs/streaming/streams_quick_start.html",
    "title": "Orleans Streams Quick Start | Microsoft Orleans Documentation",
    "keywords": "Orleans Streams Quick Start This guide will show you a quick way to set up and use Orleans Streams. To learn more about the details of the streaming features, read other parts of this documentation. Required Configurations In this guide we'll use a Simple Message based Stream which uses grain messaging to send stream data to subscribers. We will use the in-memory storage provider to store lists of subscriptions, so it is not a wise choice for real production applications. On the silo, where hostBuilder is an ISiloHostBuilder hostBuilder.AddSimpleMessageStreamProvider(\"SMSProvider\") .AddMemoryGrainStorage(\"PubSubStore\"); On the cluster client, where clientBuilder is an IClientBuilder clientBuilder.AddSimpleMessageStreamProvider(\"SMSProvider\"); NOTE By default, messages that are passed over the Simple Message Stream are considered immutable, and may be passed my reference to other grains. To turn off this behavior, you must config the SMS provider to turn off OptimizeForImmutableData siloBuilder .AddSimpleMessageStreamProvider(\"SMSProvider\", (options) => options.OptimizeForImmutableData = false); Now we can create streams, send data using them as producers and also receive data as subscribers. Producing Events Producing events for streams is relatively easy. You should first get access to the stream provider which you defined in the config above ( SMSProvider ) and then choose a stream and push data to it. //Pick a GUID for a chat room grain and chat room stream var guid = some guid identifying the chat room //Get one of the providers which we defined in our config var streamProvider = GetStreamProvider(\"SMSProvider\"); //Get the reference to a stream var stream = streamProvider.GetStream<int>(guid, \"RANDOMDATA\"); As you can see, our stream has a GUID and a namespace. This will make it easy to identify unique streams. For example, the namespace for a chat room can be \"Rooms\" and the GUID can be the owning RoomGrain's GUID. Here we use the GUID of some known chat room. Using the OnNext method of the stream we can push data to it. Let's do it inside a timer, using random numbers. You could use any other data type for the stream as well. RegisterTimer(s => { return stream.OnNextAsync(new System.Random().Next()); }, null, TimeSpan.FromMilliseconds(1000), TimeSpan.FromMilliseconds(1000)); Subscribing and receiving streaming data For receiving data, we can use implicit/explicit subscriptions, which are fully described in other pages of the manual. Here we use implicit subscriptions, which are easier. When a grain type wants to implicitly subscribe to a stream, it uses the attribute ImplicitStreamSubscription (namespace)] . For our case we'll define a ReceiverGrain like this: [ImplicitStreamSubscription(\"RANDOMDATA\")] public class ReceiverGrain : Grain, IRandomReceiver Whenever data is pushed to the streams of the namespace RANDOMDATA, as we have in the timer, a grain of type ReceiverGrain with the same GUID of the stream will receive the message. Even if no activations of the grain currently exist, the runtime will automatically create a new one and send the message to it. In order for this to work, we need to complete the subscription process by setting our OnNext method for receiving data. To do so, our ReceiverGrain should call something like this in its OnActivateAsync //Create a GUID based on our GUID as a grain var guid = this.GetPrimaryKey(); //Get one of the providers which we defined in config var streamProvider = GetStreamProvider(\"SMSProvider\"); //Get the reference to a stream var stream = streamProvider.GetStream<int>(guid, \"RANDOMDATA\"); //Set our OnNext method to the lambda which simply prints the data. This doesn't make new subscriptions, because we are using implicit subscriptions via [ImplicitStreamSubscription]. await stream.SubscribeAsync<int>(async (data, token) => Console.WriteLine(data)); We are all set! Now the only requirement is that something trigger our producer grain's creation, and then it will register the timer and start sending random ints to all interested parties. Again, this guide skips lots of details and is only good for showing the big picture. Read other parts of this manual and other resources on RX to gain a good understanding of what is available and how. Reactive programming can be a very powerful approach to solve many problems. You could for example use LINQ in the subscriber to filter numbers and do all sorts of interesting stuff. Next Orleans Streams Programming APIs"
  },
  "docs/streaming/streams_why.html": {
    "href": "docs/streaming/streams_why.html",
    "title": "Why Orleans Streams? | Microsoft Orleans Documentation",
    "keywords": "Why Orleans Streams? There are already a wide range of technologies that allow you to build stream processing systems. Those include systems to durably store stream data (e.g., Event Hubs and Kafka ) and systems to express compute operations over stream data (e.g., Azure Stream Analytics , Apache Storm , and Apache Spark Streaming ). Those are great systems that allow you to build efficient data stream processing pipelines. Limitations of Existing Systems However, those systems are not suitable for fine-grained free-form compute over stream data . The Streaming Compute systems mentioned above all allow you to specify a unified data-flow graph of operations that are applied in the same way to all stream items . This is a powerful model when data is uniform and you want to express the same set of transformation, filtering, or aggregation operations over this data. But there are other use cases where you need to express fundamentally different operations over different data items. And in some of them as part of this processing you occasionally need to make an external call, such as invoke some arbitrary REST API. The unified data-flow stream processing engines either do not support those scenarios, support them in a limited and constrained way, or are inefficient in supporting them. This is because they are inherently optimized for a large volume of similar items, and usually limited in terms of expressiveness, processing . Orleans Streams target those other scenarios. Motivation It all started with requests from Orleans users to support returning a sequence of items from a grain method call. As you can imagine, that was only the tip of the iceberg. They actually needed much more than that. A typical scenario for Orleans Streams is when you have per user streams and you want to perform different processing for each user , within the context of an individual user. We may have millions of users but some of them are interested in weather and can subscribe to weather alerts for a particular location, while some are interested in sports events; somebody else is tracking status of a particular flight. Processing those events requires different logic, but you don't want to run two independent instances of stream processing. Some users are interested in only a particular stock and only if a certain external condition applies, a condition that may not necessarily be part of the stream data (and thus needs to be checked dynamically at runtime as part of processing). Users change their interests all the time, hence their subscriptions to specific streams of events come and go dynamically, thus the streaming topology changes dynamically and rapidly . On top of that, the processing logic per user evolves and changes dynamically as well, based on user state and external events . External events may modify the processing logic for a particular user. For example, in a game cheating detection system, when a new way to cheat is discovered the processing logic needs to be updated with the new rule to detect this new violation. This needs to be done of course without disrupting the ongoing processing pipeline . Bulk data-flow stream processing engines were not built to support such scenarios. It goes almost without saying that such a system has to run on a number of network-connected machines, not on a single node. Hence, the processing logic has to be distributed in a scalable and elastic manner across a cluster of servers. New Requirements We identified 4 basic requirements for our Stream Processing system that will allow it to target the above scenarios. Flexible stream processing logic Support for highly dynamic topologies Fine-grained stream granularity Distribution Flexible stream processing logic We want the system to support different ways of expressing the stream processing logic. The existing systems we mentioned above require the developer to write a declarative data-flow computation graph, usually by following a functional programming style. This limits the expressiveness and flexibility of the processing logic. Orleans streams are indifferent to the way processing logic is expressed. It can be expressed as a data-flow (e.g., by using Reactive Extensions (Rx) in .NET ); as a functional program; as a declarative query; or in a general imperative logic. The logic can be stateful or stateless, may or may not have side effects, and can trigger external actions. All power goes to the developer. Support for dynamic topologies We want the system to allow for dynamically evolving topologies. The existing systems we mentioned above are usually limited to only static topologies that are fixed at deployment time and cannot evolve at runtime. In the following example of a dataflow expression everything is nice and simple until you need to change it. Stream.GroupBy(x=> x.key).Extract(x=>x.field).Select(x=>x+2).AverageWindow(x, 5sec).Where(x=>x > 0.8) * Change the threshold condition in the Where filter, add an additional Select statement or add another branch in the data-flow graph and produce a new output stream. In existing systems this is not possible without tearing down the entire topology and restarting the data-flow from scratch. Practically, those systems will checkpoint the existing computation and will be able to restart from the latest checkpoint. Still, such a restart is disruptive and costly to an online service that produces results in real time. Such a restart becomes especially impractical when we are talking about a large number of such expressions being executed with similar but different (per-user, per-device, etc.) parameters and that continually change. We want the system to allow for evolving the stream processing graph at runtime, by adding new links or nodes to the computation graph, or by changing the processing logic within the computation nodes. Fine grained stream granularity In the existing systems, the smallest unit of abstraction is usually the whole flow (topology). However, many of our target scenarios require an individual node/link in the topology to be a logical entity by itself. That way each entity can be potentially managed independently. For example, in the big stream topology comprising multiple links, different links can have different characteristics and can be implemented over different physical transports. Some links can go over TCP sockets, while others over reliable queues. Different links can have different delivery guarantees. Different nodes can have different checkpointing strategies, and their processing logic can be expressed in different models or even different languages. Such flexibility is usually not possible in existing systems. The unit of abstraction and flexibility argument is similar to a comparison of SoA (Service Oriented Architectures) vs. Actors. Actor systems allow more flexibility, since each actor is essentially an independently managed ''tiny service''. Similarly, we want the stream system to allow for such fine grained control. Distribution And of course, our system should have all the properties of a \"good distributed system\" . That includes: Scalability - supports large number of streams and compute elements. Elasticity - allows to add/remove resources to grow/shrink based on load. Reliability - be resilient to failures Efficiency - use the underlying resources efficiently Responsiveness - enable near real time scenarios. These were the requirements we had in mind for building Orleans Streaming . Clarificaton : Orleans currently does not directly support writing declarative dataflow expressions like in the example above. The current Orleans Streaming APIs are more low level building blocks, as described here . Providing declarative dataflow expressions is our future goal. Next Orleans Streams Programming APIs"
  },
  "docs/tutorials_and_samples/Adventure.html": {
    "href": "docs/tutorials_and_samples/Adventure.html",
    "title": "Adventure | Microsoft Orleans Documentation",
    "keywords": "Adventure 一个简单的多人文本冒险游戏，其灵感来自老式的、基于文本的冒险游戏。 说明书 在 Visual Studio 打开 OrleansAdventure.sln 项目。 你可以 在这里 找到他。 启动“AdventureSetup”项目。 当AdventureSetup运行成功后，启动“AdventureClient”项目。 然后系统会提示您在命令行中输入您的姓名。 进入并开始游戏。 概述 AdventureSetup程序从 AdventureConfig.txt 中读取游戏配置(\"地图\")。 它设置了一系列的“房间”，如森林、海滩、洞穴、空地等。 这些位置连接到其他房间，以模拟游戏的位置和布局。 该示例配置仅描述了少数位置。 房间里可以放钥匙、剑等“东西”。 AdventureClient程序设置您的播放器，并提供一个简单的基于文本的用户界面，允许您玩游戏。 您可以使用简单的命令语言在房间中移动并与事物进行交互，例如说“go north”或“take brass key”。 为什么使用Orleans？ Orleans允许游戏通过非常简单的C#代码来描述游戏，同时允许它扩展到大型多人游戏。 为了使这个动机有意义，房间的迷宫需要非常大，并且需要同时支持大量玩家。 使用Orleans的一个优点是，该服务可以应对增量而设计，以小规模运行它的开销并不显著，而且您可以确信，当需要时它将是可以扩展的。 它是如何建模的？ 玩家和房间被建模为Grains。 这些Grains使我们能够用每个Grains模型状态和功能来分发游戏。 像密钥这样的东西被建模为“plain old objects”——它们实际上只是简单的不可变的数据结构，并且可以在房间里和玩家之间移动，所以它们不需要设计为Grains。 可能的改进 把地图弄得非常、非常大 让铜钥匙打开一些东西 允许玩家互相留言 使食物和饮用水成为可能和有实际的作用。"
  },
  "docs/tutorials_and_samples/custom_grain_storage.html": {
    "href": "docs/tutorials_and_samples/custom_grain_storage.html",
    "title": "Custom Grain Storage | Microsoft Orleans Documentation",
    "keywords": "Custom Grain Storage Writing a Custom Grain Storage In the tutorial on declarative actor storage, we looked at allowing grains to store their state in an Azure table using one of the built-in storage providers. While Azure is a great place to squirrel away your data, there are many alternatives. In fact, there are so many that there was no way to support them all. Instead, Orleans is designed to let you easily add support for your own form of storage by writing a grain storage. In this tutorial, we'll walk through how to write a simple file-based grain storage. A file system is not the best place to store grains states as it is local, there can be issues with file locks and the last update date is not sufficient to prevent inconsistency. But it's an easy example to help us illustrate the implementation of a Grain Storage . Getting Started An Orleans grain storage is a class that implements IGrainStorage which is included in Microsoft.Orleans.Core NuGet package . We also inherit from ILifecycleParticipant<ISiloLifecycle> which will allow us to subscribe to a particular event in the lifecycle of the silo. We start by creating a class named FileGrainStorage . using Orleans; using System; using Orleans.Storage; using Orleans.Runtime; using System.Threading.Tasks; namespace GrainStorage { public class FileGrainStorage : IGrainStorage, ILifecycleParticipant<ISiloLifecycle> { private readonly string _storageName; private readonly FileGrainStorageOptions _options; private readonly ClusterOptions _clusterOptions; private readonly IGrainFactory _grainFactory; private readonly ITypeResolver _typeResolver; private JsonSerializerSettings _jsonSettings; public FileGrainStorage(string storageName, FileGrainStorageOptions options, IOptions<ClusterOptions> clusterOptions, IGrainFactory grainFactory, ITypeResolver typeResolver) { _storageName = storageName; _options = options; _clusterOptions = clusterOptions.Value; _grainFactory = grainFactory; _typeResolver = typeResolver; } public Task ClearStateAsync(string grainType, GrainReference grainReference, IGrainState grainState) { throw new NotImplementedException(); } public Task ReadStateAsync(string grainType, GrainReference grainReference, IGrainState grainState) { throw new NotImplementedException(); } public Task WriteStateAsync(string grainType, GrainReference grainReference, IGrainState grainState) { throw new NotImplementedException(); } public void Participate(ISiloLifecycle lifecycle) { throw new NotImplementedException(); } public void Participate(ISiloLifecycle lifecycle) { throw new NotImplementedException(); } } } Prior starting the implementation, we create an option class containing the root directory where the grains states files will be stored under. For that we will create an options file FileGrainStorageOptions : public class FileGrainStorageOptions { public string RootDirectory { get; set; } } The create a constructor containing two fields, storageName to specify which grains should write using this storage [StorageProvider(ProviderName = \"File\")] and directory which would be the directory where the grain states will be saved. IGrainFactory , ITypeResolver will be used in the next section where we will initilize the storage. We also take two options as argument, our own FileGrainStorageOptions and the ClusterOptions . Those will be needed for the implementation of the storage functionalities. We also need JsonSerializerSettings as we are serializing and deserializing in Json format. Json is an implementation detail, it is up to the developer to decide what serialization/deserialization protocol would fit the application. Another common format is binary format. Initializing the storage To initialize the storage, we register an Init function on the ApplicationServices lifecycle. public void Participate(ISiloLifecycle lifecycle) { lifecycle.Subscribe(OptionFormattingUtilities.Name<FileGrainStorage>(_storageName), ServiceLifecycleStage.ApplicationServices, Init); } The Init function is used to set the _jsonSettings which will be used to configure the Json serializer. At the same time we create the folder to store the grains states if it does not exist yet. private Task Init(CancellationToken ct) { // Settings could be made configurable from Options. _jsonSettings = OrleansJsonSerializer.UpdateSerializerSettings(OrleansJsonSerializer.GetDefaultSerializerSettings(_typeResolver, _grainFactory), false, false, null); var directory = new System.IO.DirectoryInfo(_rootDirectory); if (!directory.Exists) directory.Create(); return Task.CompletedTask; } We also provide a common function to construct the filename ensuring uniqueness per service, grain Id and grain type. private string GetKeyString(string grainType, GrainReference grainReference) { return $\"{_clusterOptions.ServiceId}.{grainReference.ToKeyString()}.{grainType}\"; } Reading State To read a grain state, we get the filename using the function we previously defined and combine it to the root directory coming from the options. public async Task ReadStateAsync(string grainType, GrainReference grainReference, IGrainState grainState) { var fName = GetKeyString(grainType, grainReference); var path = Path.Combine(_options.RootDirectory, fName); var fileInfo = new FileInfo(path); if (!fileInfo.Exists) { grainState.State = Activator.CreateInstance(grainState.State.GetType()); return; } using (var stream = fileInfo.OpenText()) { var storedData = await stream.ReadToEndAsync(); grainState.State = JsonConvert.DeserializeObject(storedData, _jsonSettings); } grainState.ETag = fileInfo.LastWriteTimeUtc.ToString(); } We use the fileInfo.LastWriteTimeUtc as a ETag which will be used by other functions for inconsistency checks to prevent data loss. Note that for the deserialization, we use the _jsonSettings which was set on the Init function. This is important to be able to serialize/deserialize properly the state. Writing State Writing the state is similar to reading the state. public async Task WriteStateAsync(string grainType, GrainReference grainReference, IGrainState grainState) { var storedData = JsonConvert.SerializeObject(grainState.State, _jsonSettings); var fName = GetKeyString(grainType, grainReference); var path = Path.Combine(_options.RootDirectory, fName); var fileInfo = new FileInfo(path); if (fileInfo.Exists && fileInfo.LastWriteTimeUtc.ToString() != grainState.ETag) { throw new InconsistentStateException($\"Version conflict (WriteState): ServiceId={_clusterOptions.ServiceId} ProviderName={_storageName} GrainType={grainType} GrainReference={grainReference.ToKeyString()}.\"); } using (var stream = new StreamWriter(fileInfo.Open(FileMode.Create, FileAccess.Write))) { await stream.WriteAsync(storedData); } fileInfo.Refresh(); grainState.ETag = fileInfo.LastWriteTimeUtc.ToString(); } Similarly as reading, we use _jsonSettings to write the state. The current ETag is used to check against the last updated time in UTC of the file. If the date is different, it means that another activation of the same grain changed the state concurrently. In this situation, we throw an InconsistentStateException which will result in the current activation being killed to prevent overwritting the state previously saved by the other activated grain. Clearing State Clearing the state would be deleting the file if the file exists. public Task ClearStateAsync(string grainType, GrainReference grainReference, IGrainState grainState) { var fName = GetKeyString(grainType, grainReference); var path = Path.Combine(_options.RootDirectory, fName); var fileInfo = new FileInfo(path); if (fileInfo.Exists) { if (fileInfo.LastWriteTimeUtc.ToString() != grainState.ETag) { throw new InconsistentStateException($\"Version conflict (ClearState): ServiceId={_clusterOptions.ServiceId} ProviderName={_storageName} GrainType={grainType} GrainReference={grainReference.ToKeyString()}.\"); } grainState.ETag = null; grainState.State = Activator.CreateInstance(grainState.State.GetType()); fileInfo.Delete(); } return Task.CompletedTask; } For the same reason as WriteState , we check for inconsistency before proceeding to delete the file and reset the ETag, we check if the current ETag is the same as the last write time UTC. Putting it Together After that we will create a factory which will allow us to scope the options setting to the provider name and at the same time create an instance of the FileGrainStorage to ease the registration to the service collection. public static class FileGrainStorageFactory { internal static IGrainStorage Create(IServiceProvider services, string name) { IOptionsSnapshot<FileGrainStorageOptions> optionsSnapshot = services.GetRequiredService<IOptionsSnapshot<FileGrainStorageOptions>>(); return ActivatorUtilities.CreateInstance<FileGrainStorage>(services, name, optionsSnapshot.Get(name), services.GetProviderClusterOptions(name)); } } Lastly to register the grain storage, we create an extension on the ISiloHostBuilder which internally register the grain storage as a named service using .AddSingletonNamedService(...) , an extension provided by Orleans.Core . public static class FileSiloBuilderExtensions { public static ISiloHostBuilder AddFileGrainStorage(this ISiloHostBuilder builder, string providerName, Action<FileGrainStorageOptions> options) { return builder.ConfigureServices(services => services.AddFileGrainStorage(providerName, options)); } public static IServiceCollection AddFileGrainStorage(this IServiceCollection services, string providerName, Action<FileGrainStorageOptions> options) { services.AddOptions<FileGrainStorageOptions>(providerName).Configure(options); return services .AddSingletonNamedService(providerName, FileGrainStorageFactory.Create) .AddSingletonNamedService(providerName, (s, n) => (ILifecycleParticipant<ISiloLifecycle>)s.GetRequiredServiceByName<IGrainStorage>(n)); } } Our FileGrainStorage implements two interfaces, IGrainStorage and ILifecycleParticipant<ISiloLifecycle> therefore we need to register two named services for each interfaces: return services .AddSingletonNamedService(providerName, FileGrainStorageFactory.Create) .AddSingletonNamedService(providerName, (s, n) => (ILifecycleParticipant<ISiloLifecycle>)s.GetRequiredServiceByName<IGrainStorage>(n)); This enables us to add the file storage using the extension on the ISiloHostBuilder : var silo = new SiloHostBuilder() .UseLocalhostClustering() .AddFileGrainStorage(\"File\", opts => { opts.RootDirectory = \"C:/TestFiles\"; }) .Build(); Now we will be able to decorate our grains with the provider [StorageProvider(ProviderName = \"File\")] and it will store in the grain state in the root directory set in the options."
  },
  "docs/tutorials_and_samples/Hello-World.html": {
    "href": "docs/tutorials_and_samples/Hello-World.html",
    "title": "Hello World | Microsoft Orleans Documentation",
    "keywords": "Hello World 运行Hello World示例 运行此示例的一种方法是从以下位置下载HelloWorld的本地副本 Samples / 2.0 / HelloWorld /文件夹 。 打开两个命令提示符窗口，然后在每个窗口中导航到HelloWorld文件夹。 生成项目。 使用以下命令在一个窗口中启动silos： dotnet run --project src\\SiloHost silos运行后，使用以下命令在另一个窗口中启动客户端： dotnet run --project src\\OrleansClient silos窗口和客户端窗口将相互显示问候。 Orleans怎么说 在此示例中，客户端与Grains连接，向其发送问候并接收回问候。 客户然后打印该问候，仅此而已。 理论上很简单，但是由于涉及分布，因此还有更多内容。 涉及四个项目-一个用于声明Grain接口，一个用于Grain实现，一个用于客户端，一个用于silos主机。 IHello.cs中有一个Grains接口： public interface IHello : Orleans.IGrainWithIntegerKey { Task<string> SayHello(string greeting); } 这很简单，我们可以看到所有回复都必须表示为一个任务或一个任务 在通信接口中。 在HelloGrain.cs中找到的实现也很简单： public class HelloGrain : Orleans.Grain, HelloWorldInterfaces.IHello { Task<string> HelloWorldInterfaces.IHello.SayHello(string greeting) { return Task.FromResult($\"You said: '{greeting}', I say: Hello!\"); } } 该类从基类继承 grain ，并实现之前定义的通信接口。 由于没有什么需要等待的Grains，因此不会声明该方法async而是使用返回值 Task.FromResult() 。 编排Grains代码并在OrleansClient项目中找到的客户端如下所示： //configure the client with proper cluster options, logging and clustering client = new ClientBuilder() .UseLocalhostClustering() .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"HelloWorldApp\"; }) .ConfigureLogging(logging => logging.AddConsole()) .Build(); //connect the client to the cluster, in this case, which only contains one silo await client.Connect(); ... // example of calling grains from the initialized client var friend = client.GetGrain<IHello>(0); var response = await friend.SayHello(\"Good morning, my friend!\"); Console.WriteLine(\"\\n\\n{0}\\n\\n\", response); // example of calling grains from the initialized client var friend = client.GetGrain<IHello>(0); var response = await friend.SayHello(\"Good morning, my friend!\"); Console.WriteLine(\"\\n\\n{0}\\n\\n\", response); SiloHost项目中的silos主机(用于配置和启动silos)如下所示： //define the cluster configuration var builder = new SiloHostBuilder() //configure the cluster with local host clustering .UseLocalhostClustering() .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"HelloWorldApp\"; }) .Configure<EndpointOptions>(options => options.AdvertisedIPAddress = IPAddress.Loopback) .ConfigureLogging(logging => logging.AddConsole()); //build the silo var host = builder.Build(); //start the silo await host.StartAsync();"
  },
  "docs/tutorials_and_samples/index.html": {
    "href": "docs/tutorials_and_samples/index.html",
    "title": "Samples Overview | Microsoft Orleans Documentation",
    "keywords": "讲解 教程1：Orleans基础知识 教程1指导您完成创建结构并设置第一个Orleans应用程序的包和🚰的步骤。 样品 你需要什么 除非另有说明，否则样品均为自包含的示例。 对于某些示例，您可能需要Azure订阅。 对于基于Azure的示例，您将需要安装SDK。 可以从以下位置下载示例 的GitHub 。 Hello，World 经典的Hello World应用程序的Orleans版本。 这个示例在处理分布式计算时，没有“琐碎”的东西，Orleans使它变得直接明了。 MathGrains 在没有图形用户接口之前，在游戏机和大型多人游戏时代之前，有VT100终端，并且有 巨大的洞穴冒险 。 按照今天的标准，这可能是la脚的，那时候是一个神奇的世界，里面有怪物、,叫的鸟以及可以捡到的东西。 这是此示例的灵感。"
  },
  "docs/tutorials_and_samples/overview_helloworld.html": {
    "href": "docs/tutorials_and_samples/overview_helloworld.html",
    "title": "Tutorial 1 Hello World | Microsoft Orleans Documentation",
    "keywords": "概述：Hello World 此概述与可用的Hello World示例应用程序相关联 这里 。 Orleans的主要概念包括silos，客户和一种或多种Grains。 创建Orleans应用程序涉及配置silos，配置客户端和开发Grain。 配置silos 通过以下方式以编程方式配置silos SiloHostBuilder 和许多追加的选项（option）类。 可以找到所有选项的列表 这里。 [...] [...] private static async Task<ISiloHost> StartSilo() { // define the cluster configuration var builder = new SiloHostBuilder() .UseLocalhostClustering() .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"HelloWorldApp\"; }) .Configure<EndpointOptions>(options => options.AdvertisedIPAddress = IPAddress.Loopback) .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(HelloGrain).Assembly).WithReferences()) .ConfigureLogging(logging => logging.AddConsole()); var host = builder.Build(); await host.StartAsync(); return host; } 选项 用于 .UseLocalhostClustering() 将客户端配置为连接到本地主机上的silos。 集群选项 ClusterId是Orleans群集的名称，对于silos和客户端，名称必须相同，以便彼此对话。 ServiceId是用于应用程序的ID，并且在部署之间不得更改 EndpointOptions 这告诉silos在哪里听。 在此示例中，我们使用了 回送 。 配置应用程序部件 将Grain类和接口程序集作为应用程序部分添加到您的orleans应用程序中。 加载配置后，将构建SiloHost，然后异步启动。 配置客户端 与silos类似，客户端通过以下方式配置 ClientBuilder 以及类似的追加的选项（option）类集合。 private static async Task<IClusterClient> StartClientWithRetries() { attempt = 0; IClusterClient client; client = new ClientBuilder() .UseLocalhostClustering() .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"HelloWorldApp\"; }) .ConfigureLogging(logging => logging.AddConsole()) .Build(); await client.Connect(RetryFilter); Console.WriteLine(\"Client successfully connect to silo host\"); return client; } 选项 用于 .UseLocalhostClustering() 与SiloHost相同 集群选项 与SiloHost相同 可以找到有关配置客户端的更深入的指南 在配置指南的客户端配置部分中。 开发一个grain Grains是Orleans编程模型的关键原语。 Grains是Orleans应用程序的基础，它们是隔离，分布和持久化的原子单位。 Grains是代表应用程序实体的对象。 就像经典的面向对象编程一样，grain封装了实体的状态，并在代码逻辑中对其行为进行了编码。 Grains可以相互保持引用，并可以通过调用彼此通过接口公开的方法进行交互。 您可以在 Orleans文档的“核心概念”部分。 这是Hello World Grain的代码主体： [...] [...] namespace HelloWorld.Grains { public class HelloGrain : Orleans.Grain, IHello { Task<string> IHello.SayHello(string greeting) { logger.LogInformation($\"SayHello message received: greeting = '{greeting}'\"); return Task.FromResult($\"You said: '{greeting}', I say: Hello!\"); } } } 您可以阅读，grain类实现一个或多个grain接口 在这里，在Grains部分。 ) [...] [...] namespace HelloWorld.Interfaces { public interface IHello : Orleans.IGrainWithIntegerKey { Task<string> SayHello(string greeting); } } 组件如何协同工作 建立此编程模型是我们分布式面向对象编程的核心概念的一部分。 SiloHost首先启动。 然后，启动OrleansClient程序。 OrleansClient的Main方法调用启动客户端的方法， StartClientWithRetries()。 客户端被传递给 DoClientWork() 方法。 private static async Task DoClientWork(IClusterClient client) { // example of calling grains from the initialized client var friend = client.GetGrain<IHello>(0); var response = await friend.SayHello(\"Good morning, my friend!\"); Console.WriteLine(\"\\n\\n{0}\\n\\n\", response); } 此时，OrleansClient创建对IHellograins的引用，并通过其接口IHello调用其SayHello()方法。 此调用激活silos中的Grains。 OrleansClient向激活的Grains发送问候语。 Grains返回问候作为对OrleansClient的响应，OrleansClient在控制台上显示该问候。 运行示例应用 要运行示例应用程序，请参阅 自述文件。"
  },
  "docs/tutorials_and_samples/testing.html": {
    "href": "docs/tutorials_and_samples/testing.html",
    "title": "单元测试 | Microsoft Orleans Documentation",
    "keywords": "单元测试 本教程显示如何对Grains进行单元测试，以确保它们的行为正确。 对Grains进行单元测试的主要方法有两种，选择的方法将取决于要测试的功能类型。 这个 Microsoft.Orleans.TestingHost NuGet包可用于为Grains创建测试silos，也可以使用模拟框架，例如 moq 模拟您与之交互的Orleans运行时的各个部分。 使用TestCluster 这个 Microsoft.Orleans.TestingHost NuGet软件包包含 测试集群（TestCluster） 可以用来创建一个内存集群，默认情况下它由两个silos组成，可以用来测试Grains。 using System; using System.Threading.Tasks; using Orleans; using Orleans.TestingHost; using Xunit; namespace Tests { public class HelloGrainTests { [Fact] public async Task SaysHelloCorrectly() { var cluster = new TestCluster(); cluster.Deploy(); var hello = cluster.GrainFactory.GetGrain<IHelloGrain>(Guid.NewGuid()); var greeting = await hello.SayHello(); cluster.StopAllSilos(); Assert.Equal(\"Hello, World\", greeting); } } } 由于启动内存集群的开销，您可能希望创建一个 测试集群 并在多个测试案例中重复使用。 例如，可以使用xUnit的类或集合夹具来完成此操作(请参见 https://xunit.github.io/docs/shared-context.html 更多细节)。 为了共享一个 测试集群 在多个测试用例之间，首先创建一个夹具类型： public class ClusterFixture : IDisposable { public ClusterFixture() { this.Cluster = new TestCluster(); this.Cluster.Deploy(); } public void Dispose() { this.Cluster.StopAllSilos(); } public TestCluster Cluster { get; private set; } } 接下来创建一个集合夹具： [CollectionDefinition(ClusterCollection.Name)] public class ClusterCollection : ICollectionFixture<ClusterFixture> { public const string Name = \"ClusterCollection\"; } 您现在可以重复使用 测试集群 在您的测试用例中： using System; using System.Threading.Tasks; using Orleans; using Xunit; namespace Tests { [Collection(ClusterCollection.Name)] public class HelloGrainTests { private readonly TestCluster _cluster; public HelloGrainTests(ClusterFixture fixture) { _cluster = fixture.Cluster; } [Fact] public async Task SaysHelloCorrectly() { var hello = _cluster.GrainFactory.GetGrain<IHelloGrain>(Guid.NewGuid()); var greeting = await hello.SayHello(); Assert.Equal(\"Hello, World\", greeting); } } } xUnit将调用 ClusterFixture 类型的 Dispose 方法，当所有测试都已完成并且在内存中群集silos将停止时。 测试集群 也有一个接受的构造函数 TestClusterOptions 可用于配置集群中的silos。 如果您在silos中使用依赖注入来使服务可用于Grains，则也可以使用以下模式： public class ClusterFixture : IDisposable { public ClusterFixture() { var builder = new TestClusterBuilder(); builder.AddSiloBuilderConfigurator<TestSiloConfigurations>(); this.Cluster = builder.Build(); this.Cluster.Deploy(); } public void Dispose() { this.Cluster.StopAllSilos(); } public TestCluster Cluster { get; private set; } } public class TestSiloConfigurations : ISiloBuilderConfigurator { public void Configure(ISiloHostBuilder hostBuilder) { hostBuilder.ConfigureServices(services => { services.AddSingleton<T, Impl>(...); }); } } 使用Mocks Orleans还使模拟系统的许多部分成为可能，并且在许多情况下，这是对grains进行单元测试的最简单方法。 这种方法确实有局限性(例如，围绕调度重入和序列化)，并且可能要求Grain包含仅由单元测试使用的代码。 的 OrleansTestKit 提供了一种替代方法，可以绕开许多这些限制。 例如，让我们想象一下我们正在测试的Grains与其他Grains交互。 为了能够模拟其他Grains，我们还需要模拟 grain工厂 被测Grains的成员。 默认 grain工厂 是正常的 protected 属性，但大多数模拟框架要求将属性设置为 public 和 virtual 才能嘲笑他们。 所以我们要做的第一件事就是 grain工厂 都 public 和 virtual 属性： public new virtual IGrainFactory GrainFactory { get { return base.GrainFactory; } } 现在，我们可以在Orleans运行时之外创建Grains，并使用模拟来控制 grain工厂 ： using System; using System.Threading.Tasks; using Orleans; using Xunit; using Moq; namespace Tests { public class WorkerGrainTests { [Fact] public async Task RecordsMessageInJournal() { var data = \"Hello, World\"; var journal = new Mock<IJournalGrain>(); var worker = new Mock<WorkerGrain>(); worker .Setup(x => x.GrainFactory.GetGrain<IJournalGrain>(It.IsAny<Guid>())) .Returns(journal.Object); await worker.DoWork(data) journal.Verify(x => x.Record(data), Times.Once()); } } } 在这里，我们创建受测Grains WorkerGrain ，使用Moq表示我们可以覆盖 grain工厂 以便它返回一个模拟 IJournalGrain 。 然后，我们可以验证我们的 WorkerGrain 与 IJournalGrain 如我们所料。"
  },
  "docs/tutorials_and_samples/tutorial_1.html": {
    "href": "docs/tutorials_and_samples/tutorial_1.html",
    "title": "Tutorial One | Microsoft Orleans Documentation",
    "keywords": "教程一-创建极简的Orleans应用程序 本教程提供有关创建基本运行的Orleans应用程序的逐步说明。 它被设计为自包含且极简的，具有以下特征： 它仅依赖NuGet软件包 已使用Orleans 2.2.0在Visual Studio 2017中进行了测试 它不依赖外部存储 请记住，这只是一个教程，缺少适当的错误处理和其他对生产环境有用的东西。 但是，它可以帮助读者真正了解Orleans的结构，并使他们将继续学习的重点放在与他们最相关的部分上。 项目搭建 在本教程中，我们将创建4个项目： 一个包含Grains接口的库 一个包含Grains类的库 一个控制台应用程序来托管我们的silos 一个控制台应用程序来托管我们的客户端 遵循本教程之后，完整的解决方案应如下所示： 在Visual Studio中创建这样的项目结构 注意：在这些项目的每个项目，您可以使用C#的默认项目类型。 然后您在下面为每个项目提供的代码替换默认代码。 您可能还需要添加 using 语句。 首先在新解决方案中创建一个控制台应用程序(.NET Core)项目。 项目命名为 Silo 并命名解决方案为 Orleans Basics 。 添加另一个控制台应用程序(.NET Core)项目并将其命名 Client 。 添加一个类库(.NET Standard)并命名 GrainInterfaces 。 添加另一个类库(.NET Standard)并命名 Grains 。 删除默认源文件 删除Grains中的Class1.cs 删除GrainInterfaces的Class1.cs 添加项目引用 Grains 引用 GrainInterfaces 。 Silo 引用 GrainInterfaces 和 Grains 。 Clinet 引用 GrainInterfaces 。 添加Orleans相关的NuGet包 Project Nuget Package Silo Microsoft.Orleans.Server Silo Microsoft.Extensions.Logging.Console Client Microsoft.Extensions.Logging.Console Client Microsoft.Orleans.Client Grain Interfaces Microsoft.Orleans.Core.Abstractions Grain Interfaces 在<code>GrainInterfaces 和 Grains 项目中，添加 Microsoft.Orleans.Core.Abstractions 和 Microsoft.Orleans.CodeGenerator.MSBuild 包。 Grains Microsoft.Orleans.CodeGenerator.MSBuild Grains Microsoft.Orleans.Core.Abstractions Grains Microsoft.Extensions.Logging.Abstractions Microsoft.Orleans.Server 和 Microsoft.Orleans.Client 是元软件包，它们带来了在silos和客户端最可能需要的依赖关系。 Microsoft.Orleans.Core.Abstractions 在任何地方都需要。 两者都包含 Microsoft.Orleans.Server 和 Microsoft.Orleans.Client 。 Microsoft.Orleans.CodeGenerator.MSBuild 自动生成调用Grains通过机器边界所需的代码。 所以两者都需要 GrainInterfaces 和 Grains 项目。 定义grains接口 在GrainInterfaces项目中，添加一个 IHello.cs 代码文件，并在其中定义以下IHello接口： using System.Threading.Tasks; namespace OrleansBasics { public interface IHello : Orleans.IGrainWithIntegerKey { Task<string> SayHello(string greeting); } } 定义一个Grains类 在Grains项目中，添加一个 HelloGrain.cs 代码文件，并在其中定义以下类： using Microsoft.Extensions.Logging; using System.Threading.Tasks; namespace OrleansBasics { public class HelloGrain : Orleans.Grain, IHello { private readonly ILogger logger; public HelloGrain(ILogger<HelloGrain> logger) { this.logger = logger; } Task<string> IHello.SayHello(string greeting) { logger.LogInformation($\"\\n SayHello message received: greeting = '{greeting}'\"); return Task.FromResult($\"\\n Client said: '{greeting}', so HelloGrain says: Hello!\"); } } } 创建silos– Program.cs 在这一步，我们添加代码用于初始化一个服务-silos，这个服务将托管和运行我们的Grains。 我们将在此处使用开发群集提供程序，以便我们可以在本地运行所有内容，而无需依赖外部存储系统。 您可以在 本地开发配置 Orleans文档的页面。 我们将在其中运行带有单个silos的集群。 将以下代码添加到Silo项目的Program.cs中： using System; using System.Threading.Tasks; using Microsoft.Extensions.Logging; using Orleans; using Orleans.Configuration; using Orleans.Hosting; namespace OrleansBasics { public class Program { public static int Main(string[] args) { return RunMainAsync().Result; } private static async Task<int> RunMainAsync() { try { var host = await StartSilo(); Console.WriteLine(\"\\n\\n Press Enter to terminate...\\n\\n\"); Console.ReadLine(); await host.StopAsync(); return 0; } catch (Exception ex) { Console.WriteLine(ex); return 1; } } private static async Task<ISiloHost> StartSilo() { // define the cluster configuration var builder = new SiloHostBuilder() .UseLocalhostClustering() .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"OrleansBasics\"; }) .ConfigureApplicationParts(parts => parts.AddApplicationPart(typeof(HelloGrain).Assembly).WithReferences()) .ConfigureLogging(logging => logging.AddConsole()); var host = builder.Build(); await host.StartAsync(); return host; } } } 创建客户端– Program.cs 最后，我们需要配置一个客户端与我们的Grains进行通信，将其连接到集群(其中只有单个silos)，然后调用Grains。 请注意，群集配置必须与我们用于silos的配置匹配。 有关客户端的更多信息，请参见 集群和客户端 Orleans文档中的部分。 using Microsoft.Extensions.Logging; using Orleans; using Orleans.Configuration; using System; using System.Threading.Tasks; namespace OrleansBasics { public class Program { static int Main(string[] args) { return RunMainAsync().Result; } private static async Task<int> RunMainAsync() { try { using (var client = await ConnectClient()) { await DoClientWork(client); Console.ReadKey(); } return 0; } catch (Exception e) { Console.WriteLine($\"\\nException while trying to run client: {e.Message}\"); Console.WriteLine(\"Make sure the silo the client is trying to connect to is running.\"); Console.WriteLine(\"\\nPress any key to exit.\"); Console.ReadKey(); return 1; } } private static async Task<IClusterClient> ConnectClient() { IClusterClient client; client = new ClientBuilder() .UseLocalhostClustering() .Configure<ClusterOptions>(options => { options.ClusterId = \"dev\"; options.ServiceId = \"OrleansBasics\"; }) .ConfigureLogging(logging => logging.AddConsole()) .Build(); await client.Connect(); Console.WriteLine(\"Client successfully connected to silo host \\n\"); return client; } private static async Task DoClientWork(IClusterClient client) { // example of calling grains from the initialized client var friend = client.GetGrain<IHello>(0); var response = await friend.SayHello(\"Good morning, HelloGrain!\"); Console.WriteLine(\"\\n\\n{0}\\n\\n\", response); } } } 运行应用程序 Build the solution and run the Silo. After you get the confirmation message that the Silo is running (\"Press enter to terminate...\"), run the Client. 成功看起来像这样： 进一步阅读 Orleans包清单 Orleans配置指南 Orleans最佳实践"
  },
  "docs/whats_new_in_orleans.html": {
    "href": "docs/whats_new_in_orleans.html",
    "title": "Orleans有什么新功能？ | Microsoft Orleans Documentation",
    "keywords": "Orleans有什么新功能？ v2.3.2版 2019年5月9日 三个错误修复。 v2.3.1版 2019年4月26日 一些改进，一个bug修复，以及批处理流API。 v2.3.0版 2019年3月20日 主要改进 支持ASP.NET Core主机 API (Microsoft.Extensions.Hosting)。 感谢@martinothamar！ 将命名选项的自定义实现替换为Microsoft.Extensions.Options. EventHub流提供程序已升级到EvenHub 2.2.1，并与3.0.0兼容。 集群成员关系表中的旧死条目现在会自动清理，这对于托管使用新IP端点来重新启动silos的环境很有帮助。 默认情况下，允许在思洛进程中有效托管前端代码的托管客户端。 Support for IHostEnvironmentStatistics on Linux, which enables CPU and memory metrics as well as load shedding. 感谢@martinothamar！ v2.3.0-rc2版 2019年3月13日 重构流批处理行为以支持批处理消费。 (5425)是唯一的变化。 While technically it is breaking due to the changes to the batch streaming API, it shouldn't break any working application code because the batching functionality wasn't fully wired previously. 在有线协议或持久化方面没有突破性的变化。 此版本与2.x版本向后兼容。 v2.3.0-rc1版 2019年3月5日 主要改进 支持ASP.NET核心托管API(Microsoft.Extensions.Hosting). 将命名选项的自定义实现替换为Microsoft.Extensions.Options. EventHub流提供程序已升级到EvenHub 2.2.1，并与3.0.0兼容。 集群成员关系表中的旧死条目现在会自动清理，这对于托管使用新IP端点来重新启动silos的环境很有帮助。 默认情况下，允许在思洛进程中有效托管前端代码的托管客户端。 1.5.7版 2019年2月28日 从v2.x后移植的两个修复程序 不间断的错误修复 修复了多群集支持(#3974) 添加GSI缓存维护和测试(#5184) 2.2.0版 2018年12月13日 这个版本主要是为了支持ACID跨Grain事务，以达到生产就绪的质量。 此版本不包含任何重大更改，并且与2.0.*版本向后兼容，允许对正在运行的群集进行就地升级。 v2.1.0版 2018年9月28日 重大变化 新建计划程序( #3792个 ) 托管客户端( #3362个 ) 分布式事务管理器( #3820个 , #4502个 , #4538个 , #4566个 , #4568 , #4591 , #4599 , #4613 , #4609 , #4616 , #4608 , #4628 , #4638 , #4685 , #4714 , #4739 , #4768 , #4799 , #4781 , #4810个 , #4820个 , #4838个 , #4831个 , #4871个 , #4887个 ) 新代码生成器( #4934个 , #5010号 , #5011号 ) 支持交易中的协调转移( #4860个 , #4894个 , #4949个 , #5026个 , ＃5024 ) v1.5.6 2018年9月27日 自1.5.5版以来的改进和错误修复。 不间断的改进 使SocketManager中的MaxSockets可配置 ＃5033 。 v2.1.0-rc2 2018年9月21日 主要变化 新代码生成器( ＃4934 ， ＃5010 ， ＃5011 )。 v2.1.0-rc1 2018年9月14日 主要变化 交易(beta2)( ＃4851 ， ＃4923 ， ＃4951 ， ＃4950 ， ＃4953 ) 支持交易中的协调转移( ＃4860 ， ＃4894 ， ＃4949 ) v1.5.5 2018年9月7日 自1.5.4版以来的改进和错误修复。 不间断的错误修复 修复程序化订阅错误( ＃4943 -- ＃3843 ) 将消息序列化错误传播给访问者( ＃4944 -- ＃4907 ) 漏洞修复 添加StreamSubscriptionHandleFactory以代表功能订阅( ＃4943 -- ＃3843 )。 从技术上来说，这虽然是一项重大突破，但它只会影响通过解决该问题(尝试与该方案一起用于SMS流)的程序化订阅功能的用户。 ＃3843 )。 v2.0.4 2018年8月7日 不间断的错误修复 如果使用dotnet核心msbuild但以完整的.net为目标，则将netcoreapp2.0用于msbuild目标dll。 ＃4895 ) v2.1.0 2018年8月28日 主要变化 新的调度程序( ＃3792 ) 托管客户端( ＃3362 ) 分布式事务管理器(测试版)( ＃3820 ， ＃4502 ， ＃4538 ， ＃4566 ， ＃4568 ， ＃4591 ， ＃4599 ， ＃4613 ， ＃4609 ， ＃4616 ， ＃4608 ， ＃4628 ， ＃4638 ， ＃4685 ， ＃4714 ， ＃4739 ， ＃4768 ， ＃4799 ， ＃4781 ， ＃4810 ， ＃4820 ， ＃4838 ， ＃4831 ， ＃4871 ， ＃4887 ) v2.0.4 2018年8月7日 自2.0.3以来的改进和错误修复。 不间断的错误修复 在.NET Core上运行时CoreFx /＃30781的解决方法( ＃4736 ) 修复.NET Core 2.1构建时代码生成( ＃4673 ) v1.5.4 2018年6月13日 v2.0.3 2018年5月14日 这是具有部分构建的第一个修补程序版本-仅更新了9个NuGet软件包： Microsoft.Orleans.OrleansRuntime Microsoft.Orleans.OrleansServiceBus Microsoft.Orleans.Runtime.Legacy Microsoft.Orleans.OrleansCodeGenerator.Build 微软Orleans核心遗产 微软Orleans交易 Microsoft.Orleans.OrleansCodeGenerator 微软Orleans核心 微软Orleans测试主机 其余软件包均保持在2.0.0不变，除了 Microsoft.Orleans.ServiceFabric 元软件包，版本为2.0.2。 v2.0.0 2018年3月28日 主要更改(自2.0.0-rc2开始) 所有包含的提供程序都从全局ClusterOptions获得ServiceId和ClusterId，并且在其自己的选项类上没有那些属性(＃4235，＃4277、4290) 使用字符串作为ServiceId而不是Guid(＃4262) v2.0.0-rc2 2018年3月12日 主要更改(自2.0.0-rc1开始) 新的“外观” API可简化流提供者各个方面的配置：持久流配置器 v2.0.0-rc1 2018年2月27日 重大更改(自2.0.0-beta3开始) 新的提供者生命周期模型将取代旧的模型 构建器模式和基于选项的组件和扩展配置 v2.0.0-beta3 2017年12月21日 社区虚拟聚会＃15 Orleans2.0与核心团队 2017年12月13日 介绍 v2.0.0-beta2 2017年12月12日 v1.5.3 2017年12月8日 v2.0.0-beta1 2017年10月26日 主要新功能 现在，大多数软件包都针对.NET Standard 2.0(这意味着它们可以在.NET Framework或.NET Core 2.0中使用)以及在非Windows平台上使用。 v1.5.2 2017年10月17日 v1.5.1 2017年8月28日 v1.5.0 2017年7月6日 主要新功能 通过ClientBuilder的非静态Grains客户端可以从同一应用程序域连接到多个Orleans群集，并从一个silos中连接到其他群集。 支持用于非停机升级的grain接口的版本控制。 支持自定义Grains存储策略和导演。 支持基于散列的Grains存储。 v1.4.2 2017年6月9日 v1.4.1 2017年3月27日 社区虚拟聚会＃14 OrleansFSM 与 约翰·阿扎里亚(John Azariah) 2017年3月22日 v1.4.0 2017年2月21日 主要新功能 改进了JournaledGrain，用于事件源，并支持基于地理分布的基于日志的一致性提供程序。 具有固定存储的每仓库应用程序组件的Grain Services的抽象，其工作负载通过集群一致性环进行分区。 支持不均匀分布的可用粮仓的异构silos。 Service Fabric的群集成员资格提供程序。 社区虚拟聚会＃13 升级Orleans应用程序 与 谢尔盖·拜科夫(Sergey Bykov) 和团队2017年2月8日 介绍 v1.4.0-beta 2017年2月1日 主要新功能 改进了JournaledGrain，用于事件源，并支持基于地理分布的基于日志的一致性提供程序。 具有固定存储的每仓库应用程序组件的Grain Services的抽象，其工作负载通过集群一致性环进行分区。 支持不均匀分布的可用粮仓的异构silos。 Service Fabric的群集成员资格提供程序。 社区虚拟聚会＃12 部署Orleans 与 雅库布·科内基(Jakub Konecki) 2016年12月8日 介绍 v1.3.1 2016年11月15日 社区虚拟聚会＃11 监控和可视化展示 与 理查德·阿斯特伯里 ， 丹·范德布姆 和 罗杰·克雷克 2016年10月13日 1.3.0版 2016年10月11日 v1.2.4 2016年10月5日 v1.3.0-beta2 2016年9月27日 显着的新功能 支持地理分布的多集群部署 ＃1108 ＃1109 ＃1800 添加了新的Amazon AWS基本Orleans提供程序 ＃2006 支持Grain方法中的分布式取消令牌 ＃1599 社区虚拟聚会＃10 核心团队与Orleans2.0的路线图 2016年8月25日 v1.2.3 2016年7月11日 1.2.2版 2016年6月15日 v1.2.1 2016年5月19日 v1.2.0 2016年5月4日 v1.2.0-beta 2016年4月18日 重大改进 根据Halo 5中使用的相同代码添加了EventHub流提供程序。 根据情况，吞吐量提高了5％至26％。 将30个功能测试以外的所有功能迁移到GitHub。 Grains状态不必扩展 Grains状态 不再(标记为 [过时] )，并且可以是简单的POCO类。 增加了对每类的支持 和 全局服务器端拦截器。 添加了对将Consul 0.6.0用作成员资格提供程序的支持。 支持C＃6。 切换到xUnit进行测试，以实现CoreCLR兼容性。 v1.1.3 2016年3月9日 社区虚拟聚会＃9 内姆·比拉(Nehme Bilal) 和 鲁本·邦德 谈论部署Orleans 与 山药 和 服务面料 2016年2月26日 社区虚拟聚会＃8.5 网络讨论 由主办 杰森·布拉格 2016年2月11日 社区虚拟聚会＃8 Orleans核心团队介绍路线图 2016年1月21日 v1.1.2 2016年1月20日 v1.1.1 2016年1月11日 社区虚拟聚会＃7 圣诞特辑- 叶文·鲍勃罗夫(Yevhen Bobrov) 上 Orleans卡 2015年12月17日 v1.1.0 2015年12月14日 社区虚拟聚会＃6 地理分布Orleansp的MSR博士 2015年10月23日 v1.0.10 2015年9月22日 v1.0.9 2015年7月15日 v1.0.8 2015年5月26日 社区虚拟聚会＃5 加布里埃尔·克利奥特(Gabriel Kliot) 于新OrleansStreaming API上发表2015年5月22日 v1.0.7 2015年5月15日 社区虚拟聚会＃4 鲁本·邦德 在FreeBay上使用Orleans的机会2015年4月15日 v1.0.5 2015年3月30日 社区虚拟聚会＃3 叶文·鲍勃罗夫(Yevhen Bobrov) 于Orleans的Uniform API上使用2015年3月6日 社区虚拟聚会＃2 Orleans团队现场问答和路线图2015年1月12日 Orleans开源v1.0更新(2015年1月) 社区虚拟聚会＃1 雅库布·科内基(Jakub Konecki) 关于事件来源的Grains2014年12月18日"
  },
  "index.html": {
    "href": "index.html",
    "title": "Orleans是一个跨平台框架，用于构建健壮，可扩展的分布式应用程序 | Microsoft Orleans Documentation",
    "keywords": "Orleans是一个跨平台框架，用于构建健壮，可扩展的分布式应用程序 Orleans建立在.NET开发人员生产力的基础上，并将其带入了分布式应用程序的世界，例如云服务。 Orleans可从单个本地服务器扩展到云中全局分布的高可用性应用程序。 Orleans采用了对象，接口，async/await和try/catch等熟悉的概念，并将其扩展到多服务器环境。 这样，它可以帮助具有单服务器应用程序经验的开发人员过渡到构建弹性，可扩展的云服务和其他分布式应用程序。 因此，Orleans通常被称为“分布式.NET”。 它是由 Microsoft Research 创建的，并介绍了 Virtual Actor Model 作为一种新方法来构建面向云时代的新一代分布式系统。 Orleans的核心贡献是它的编程模型，它在不限制功能，以及对开发人员施加繁重约束的情况下，降低了高并发分布式系统固有的复杂性。 文档位于 此处 。 可以在这里找到文档的中文翻译 在这里"
  }
}